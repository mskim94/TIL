{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML은 통계 기반으로 동작, DL은 ML을 기초로 발전하였다. 딥러닝을 단순 행렬의 곱을 통한 계산하고 최적화를 위해 편미분 & 역전파 알고리즘을 통해 수행된다 정도로 얕은 이해가 아니라, 확률적 관점에서 딥러닝을 보자.\n",
    "\n",
    "# 기초 수학\n",
    "\n",
    "## 2.1 확률 변수 & 확률 분포\n",
    "\n",
    "### 2.1.1 확률 변수\n",
    "\n",
    "랜덤 변수(random variable): 확률을 이야기할 때 랜덤하게 발생하는 어떤 사건을 정의\n",
    "\n",
    "ex) 주사위 던졌을 때(사건 x) 주사위의 숫자가 3이 나왔다면(값 3), 3이 나올 확률은 1/6.\n",
    "\n",
    "$\\to P(x=3) = \\frac{1}{6}$\n",
    "\n",
    "'주사위를 던져 3이 나올 확률은 1/6' \n",
    "\n",
    "확률 변수 x가 값 $x$가 나올 확률값 $p$ $\\to P(X=x)=P(x) = P where 0 <= p <= 1$\n",
    "\n",
    "$\\sum_{i=1}^N P(X=x_i) = \\sum_{i=1}^N P(x_i) = 1$\n",
    "\n",
    "#### 이산 확률 변수 & 이산 확률 분포\n",
    "\n",
    "랜덤 변수는 불연속적인 이산(discrete)값인 경우가 많다.\n",
    "\n",
    "불연속적인 이산 확률 변수(discrete random variable)에 대한 확률 함수를 **확률 질량 함수(probability mass function)** 이라고 한다.\n",
    "\n",
    "이산적인 확률 분포를 갖는 확률 분포\n",
    "\n",
    "- 베르누이 분포(Bernoulli distribution): 0과 1 두 개의 값만 가질 수 있다.\n",
    "\n",
    "- 멀티눌리 분포(Multinoulli distribution): 주사위 같이 여러 개의 이산적인 값을 가질 수 있다.\n",
    "\n",
    "베르누이, 멀티눌리 확률 분포를 더 일반화하여 여러 번 일어날 수 있는 확률에 대해 이야기 할 때 각각\n",
    "\n",
    "- 이항 분포(binomial distribution)\n",
    "\n",
    "- 다항 분포(multinomial distribution)\n",
    "\n",
    "\n",
    "#### 연속 확률 변수 & 연속 확률 분포\n",
    "\n",
    "연속 확률 분포(continuous probability distribution): 연속적인 값을 다루는 연속 확률 변수(continuous probability variable)를 가지는 확률 분포\n",
    "\n",
    "연속 확률 분포는 확률 질량이 아닌 확률 밀도 함수를 통해 확률 변수로 정의된 공간에 대해 확률값이 아닌 확률 밀도를 정의할 수 있다.\n",
    "\n",
    "$\\forall x \\in X, P(x) \\geq 0 \\\\\n",
    "It\\ is\\ not\\ necessary\\ that\\ p(x) \\leq 1 \\\\\n",
    "\\int^{\\infty}_{-\\infty}P(x)dx = 1$\n",
    "\n",
    "P(x)는 꼭 1보다 작을 필요는 없으며, P(x)를 적분한 값을 항상 1이다. \n",
    "\n",
    "연속 확률 변수에 대한 확률 함수를 **확률 밀도 함수(probability density function, PDF)** 라고 한다.\n",
    "\n",
    "정규 분포(normal distribution)라고도 불리는 가우시안 분포(Gaussian distribution)함수가 가장 좋은 예\n",
    "\n",
    "연속적인 확률 분포 함수에서 확률값은 어떤 구간의 넓이를 의미 $\\to$ 특정 값 x가 주어지면 확률값을 구할 수 없고 확률 밀도 값만 구할 수 있다. (확률값을 구하기 위해서는 구간이 주어져야 한다.)\n",
    "\n",
    "### 2.1.2 결합 확률\n",
    "\n",
    "**결합 확률(Joint Probability)**: 두 개 이상의 사건이 동시에 일어날 확률을 말한다. (두 개 이상의 확률 변수를 가진다.)\n",
    "\n",
    "ex) 2개의 주사위(A, B를 던질 때의 확률$\\to$ P(A, B), A가 3이 나오고, B가 2가 나올 확률 $\\to$ P(A=3, B=2)\n",
    "\n",
    "\n",
    "독립(independent): 사건이 서로에게 영향을 미치지 않는 것\n",
    "\n",
    "독립이면 아래 조건을 항상 만족한다.\n",
    "\n",
    "P(A,B) = P(A)P(B)\n",
    "\n",
    "\n",
    "### 2.1.3 조건부 확률\n",
    "\n",
    "**조건부 확률(conditional probability)**: 하나의 확률 변수가 주어졌을 때 다른 확률 변수에 대한 확률 분포\n",
    "\n",
    "'사건 B가 주어졌을 때, 사건 A에 관한 확률 분포'\n",
    "\n",
    "$P(A|B) = \\frac{P(A,B)}{P(B)}\\ or \\\\\n",
    "P(A,B) = P(A|B)P(B)$\n",
    "\n",
    "P(A=3|B=2) 'B가 2가 나왔을 때, A의 값이 3이 나올 확률값'\n",
    "\n",
    "P(A|B=2) 'B가 2가 나왔을 때 A가 얻을 수 있는 값을 확률 분포'\n",
    "\n",
    "$\\to$ A의 값이 주어지지 않았기 때문에, 확률값을 반환하는 것이 아닌 확률 분포 함수를 반환한다.\n",
    "\n",
    "#### 베이즈 정리\n",
    "\n",
    "베이즈 정리(Bayes theorem): $P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$\n",
    "\n",
    "### 2.1.4 주변 확률 분포\n",
    "\n",
    "**주변 확류 분포(marginal probability distribution):** 두 개 이상의 확률 변수의 결합 확률 분포(joint probability distribution)가 있을 때, 하나의 확률 변수에 대해 적분을 수행한 결과\n",
    "\n",
    "$P(x) = \\sum_{y\\in Y} P(x,y) = \\sum_{y\\in Y} P(x|y)P(y)$ (이산확률변수)\n",
    "\n",
    "$P(x) = \\int P(x,y)dy = \\int P(x|y)P(y)dy$ (연속확률변수)\n",
    "\n",
    "\n",
    "## 2.3 기댓값 & 샘플링\n",
    "\n",
    "### 2.3.1 기댓값\n",
    "\n",
    "**기댓값(expectation)은 보상(reward)과 그 보상을 받을 확률을 곱한 값의 총합으로 얻는다**. 즉, 보상에 대한 가중평균(weighted average)\n",
    "\n",
    "$expected\\ reward\\ from\\ dice = \\sum^{6}_{i=1}P(X=x) \\times reward(x) \\\\\n",
    "where\\ P(x)=\\frac{1}{6}, \\forall x and\\ reward(x) = x$\n",
    "\n",
    "실제 주사위 보상의 기댓값: $\\frac{1}{6}\\times (1+2+3+4+5+6) = 3.5$\n",
    "\n",
    "**기댓값은 특정 함수에 대한 P(x) 분포에 대한 가중평균이다**\n",
    "\n",
    "다음과 같이 표현도 가능\n",
    "\n",
    "$\\mathbb{E}_{x~P(x)}[reward(x)] = \\sum^6_{x=1}\\times\\ reward(x) = 3.5$ (주사위의 경우라서 불연속적인 확률 변수 분포)\n",
    "\n",
    "$\\mathbb{E}_{x~P}[reward(x)] = \\int{p(x)}\\cdot reward(x)dx$ (연속적인 확률 변수 분포)\n",
    "\n",
    "### 2.3.2 몬테카를로 샘플링\n",
    "\n",
    "몬테카를로 샘플링(Monte-Carlo sampling): 랜덤 성질을 이용, 임의의 함수 적분을 근사(aapproximation)하는 방법\n",
    "\n",
    "ex) 한반도 넓이를 근사가 목적. 한번도를 포함하는 큰 도형(사각형 or 원)을 그린 후 임의로 점을 흩뿌렸을 때, 한번도 안에 떨어진 점과 밖에 떨어진 점의 비율을 통해 우리는 도형의 넓이에서 한반도가 차지하는 비율을 알 수 있다. 더 많은 점을 흩뿌리면 더 정확한 넓이를 근사할 수 있다. \n",
    "\n",
    "$\\mathbb{E}_{x~P(x)}[f(x)] = \\sum_{x\\in X} P(x)\\cdot f(x) \\approx \\frac{1}{K}\\sum^K_{i=1} f(x_i)\\ where\\ x_i \\sim P(x)$ (분연속)\n",
    "\n",
    "$\\mathbb{E}_{x~p}[f(x)] = \\int p(x)\\cdot f(x) \\approx \\frac{1}{K}\\sum^K_{i=1} f(x_i)\\ where\\ x_i \\sim p(x)$ (연속)\n",
    "\n",
    "K번 샘플링한 값을 균등 분포(uniform distribution) 처럼 다루어 가중평균 말고 단순 1/K, 산술 평균을 취함\n",
    "\n",
    "- Monte Carlo 참고 자료: https://angeloyeo.github.io/2020/09/17/MCMC.html\n",
    "\n",
    "## 2.4 MLE\n",
    "\n",
    "ML의 목표: 미지 데이터(unseen data)에 대해 좋은 예측(prediction)을 하는 것, 결국 일반화(generalization) 성능이 좋아야 한다.\n",
    "\n",
    "좋은 일반화 성능을 얻기 위해서는 실제(Ground truth) 확률 분포로부터 데이터를 샘플링하고, 수집된 데이터를 가장 잘 일반화하는 확률 분포 모델을 추정해서 실제 확률 분포를 근사한다.\n",
    "\n",
    "ex) 압정을 던져 바닥으로 떨어지면 20원 받고, 반대 -10원. 100번 던진다. 바닥으로 30번 떨어졌다.\n",
    "\n",
    "$\\mathbb{E}_{x\\sim p}[reward(x)] = P(x=bottom)\\times 20 + P(x=sharp)\\times (-10) \\\\\n",
    "\\approx \\frac{30}{100} \\times 20 - (1-\\frac{30}{100})\\times 10 = 6 - 7 = -1$\n",
    "\n",
    "기댓값은 -1 손해다. 게임을 하면 안된다.\n",
    "\n",
    "위 게임을 통해 최대가능도 추정(Maximum likelihood estimation, MLE)를 수행한 것이다.\n",
    "\n",
    "압정을 던지는 사건은 0, 1로 결과가 2가지 밖에 없는 사건이기에 **베르누이 분포**를 따른다. 이를 반복 시행했을 때 이것은 이항 분포를 가진다.\n",
    "이항 분포는 아래와 같이 정의할 수 있다.\n",
    "\n",
    "$\\mathcal{K} \\sim \\mathcal{B}(n, \\theta)$\n",
    "\n",
    "이항 분포 parameter $\\theta$가 있을 때, n번 압정을 던져 바닥이 k번 바닥으로 떨어지는 확률은\n",
    "\n",
    "$P(\\mathcal{K}=k)=\\begin{pmatrix}\n",
    "n\\\\ \n",
    "k \n",
    "\\end{pmatrix} \\theta^k(1-\\theta)^{n-k}\\\\\n",
    "= \\frac{n!}{k!(n-k)!}\\cdot \\theta^k(1-\\theta)^{n-k}$\n",
    "\n",
    "$J(\\theta) = \\frac{100!}{30!(100-30)!}\\cdot \\theta^{30}(1-\\theta)^{100-30}$\n",
    "\n",
    "위 함수에 $\\theta$를 넣어 얻은 결과값을 **가능도(우도, likelihood)** 라고 한다. \n",
    "\n",
    "parameter $\\theta$를 가진 이항 분포의 확률값은 아래와 같다. 이 함수를 **가능도 함수(likelihood function)** 라고 한다. \n",
    "\n",
    "$J(\\theta) = P(n=100, k=30|\\theta)$\n",
    "\n",
    "$J(\\theta)$는 $\\theta$에 따른 가능도이다. 주어진 데이터를 가장 잘 설명하는 즉 가능도를 최대화(maximize) 하도록 $\\theta$를 추정하므로 **최대가능도 추정(MLE)** 라고 부른다. \n",
    "\n",
    "가능도는 주어진 데이터 $x_{1:n} = \\{x_1, x_2, ..., x_n\\}$를 설명하는 확률 분포 파라미터($\\theta$)에 대한 함수로, 아래와 같이 표현\n",
    "\n",
    "$P(X=x_{1:n};\\theta)$\n",
    "\n",
    "이산 확률 변수를 갖는 확률 분포에서는 확률값 자체가 가능도로 표현될 수 있다.(확률과 가능도가 같다) 연속 확률 변수 확률 분포에서는 확률 밀도 값이 가능도를 나타낸다. \n",
    "\n",
    "서로 독립인 n번 시행을 거쳐 얻은 데이터 $(x_1, x_2, ..., x_n)$에 대한 가능도는 아래와 같다.\n",
    "\n",
    "\n",
    "$P(x_1, x_2,..., x_n|\\theta) = P(x_1;\\theta)P(x_2;\\theta)\\cdots P(x_n;\\theta) = \\Pi^{n}_{i=1}P(x_i;\\theta)$\n",
    "\n",
    "로그를 취하면 \n",
    "\n",
    "$logP(x_1, x_2, ..., x_n|\\theta) = \\sum^{n}_{i=1}logP(x_i;\\theta)$\n",
    "\n",
    "로그를 취하는 이유?\n",
    "\n",
    "- 언더플로(underflow) 방지\n",
    "\n",
    "- 곱셈 보다 덧셈 연산이 빠름\n",
    "\n",
    "- Gaussian Distribution에서 지수(exponent) 제거 가능\n",
    "\n",
    "가능도에 log를 취한 **로그 가능도(log-likelihood)** 를 최대화 해야한다. 여기에 -1을 곱하면 **최소화 문제로 치환할 수 있고** 이것을 **음의 로그 가능도(negative log-likelihood, NLL)** 이라고 한다. \n",
    "\n",
    "### 2.4.1 확률 분포 함수로서의 신경망\n",
    "\n",
    "MNIST 분류 문제는 이산 확률 변수를 다루는 멀티눌리 분포이다. 따라서 신경망 마지막 층의 softmax 연산 y의 결과값은 클래스별 확률값에 대한 분포 $\\hat{y}$를 반환한다. 신경망 weight parameter $\\theta$가 훈련 데이터를 잘 설명하도록 gradient descent를 통해 MLE를 수행 학습한다.\n",
    "\n",
    "## 2.5 정보 이론\n",
    "\n",
    "정보 이론, 정보량, 정보량의 평균값인 엔트로피에 대해 알아보자.\n",
    "\n",
    "### 2.5.1 정보량\n",
    "\n",
    "**정보 이론(information theory):** 데이터를 정량화하기 위한 응용 수학 분야\n",
    "\n",
    "**정보량(information content)**: 불확실성 또는 놀람의 정도\n",
    "\n",
    "확률이 낮다면 정보량이 높다. (정보량이 높다면 확률이 낮다)\n",
    "\n",
    "수식 표현: $I(x) = -logP(x)$\n",
    "\n",
    "### 2.5.2 엔트로피\n",
    "\n",
    "**엔트로피(entropy):** 정보량의 평균(기댓값)\n",
    "\n",
    "$H(P) = -\\mathbb{E}_{x\\sim P(x)}[logP(x)] = -\\sum_{x\\in \\mathcal{X}}P(x)logP(x)$\n",
    "\n",
    "엔트로피는 분포의 대략적인 모양이 얼마나 퍼져(flat) or 뾰족(sharp)한지 가늠해볼 수 있는 척도\n",
    "- 엔트로피가 작으면 그 분포는 뾰족한 모양 가짐\n",
    "- 뾰족한 확률 분포일수록 특정 값에 대한 확률이 높다는 의미\n",
    "\n",
    "**교차 엔트로피(cross entropy):** 분포 함수 P에서 샘플링한 x를 통해 분포 함수 Q의 평균 정보량을 나타낸 것(분류 문제에서 사용)\n",
    "\n",
    "- 교차: 다른 분포 P를 사용해 대상 분포 Q의 엔트로피를 측정\n",
    "\n",
    "$H(P, Q) = -\\mathbb{E}_{x\\sim P(x)}[logQ(x)]=-\\sum_{x\\in \\mathcal{X}}P(x)logQ(x)$\n",
    "\n",
    "**-log를 취했으므로, 분포 P와 Q가 비슷한 모양이면 교차 엔트로피 H(P,Q)는 더 작은 값을 갖는다.**\n",
    "\n",
    "**이산 확률 변수를 다루는 확률 분포는 Cross Entropy를 사용했지만, 연속 확률 분포는 평균제곱오차(Mean Square Error, MSE)** 손실 함수를 통해 훈련\n",
    "\n",
    "연속 확률 분포에서 Cross Entropy를 사용해도 되지만, 샘플에 대한 확률값을 구하는 것이 불가능하기에, 이산 확류 분포에서만 Cross Entropy를 사용\n",
    "\n",
    "#### 쿨백-라이블러 발산(Kullback-Leibler Divergence, KLD)\n",
    "$KL(P||Q) = -\\mathbb{E}_{x\\sim P(x)}[log\\frac{Q(x)}{P(x)}]\\\\\n",
    "= -\\sum_{x\\in \\mathcal{X}}P(x)log\\frac{Q(x)}{P(x)}\\\\\n",
    "= -\\sum_{x\\in \\mathcal{X}}P(x)logQ(x) - \\sum_{x\\in \\mathcal{X}}P(x)logP(x)\\\\\n",
    "= H(P,Q) - H(P)$\n",
    "\n",
    "KLD는 두 분포 사이의 차이(괴리)를 보여준다. \n",
    "\n",
    "위 수식에서 분포 P와 분포 Q의 위치에 따라 KLD 값은 달라질 수 있기에, 거리라고 표현하지 않는다. 두 분포의 차이를 줄이려면 KLD 최소화 하는 것이 좋은 전략이다. Cross Entropy 대신 KLD를 사용하면 더 좋을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
