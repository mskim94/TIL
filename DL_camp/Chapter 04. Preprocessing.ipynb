{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter 04. Preprocessing.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1izokb2VtqE8hFN7eD79_2nrILKchb5Yc","authorship_tag":"ABX9TyOgvF+dHNQ2/QleBsvd/g6m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"R6O_pZwYbsVE"},"source":["# Chapter 04. 전처리\n","## INDEX\n","### 4.1 전처리\n","\n","### 4.2 코퍼스 수집\n","\n","### 4.3 정제\n","\n","### 4.4 문장 단위 분절\n","\n","### 4.5 분절\n","\n","### 4.6 병렬 코퍼스 정렬\n","\n","### 4.7 서브워드 분절\n","\n","### 4.8 분절 복원\n","\n","### 4.9 Torchtext\n","\n","자연어 처리에서 가장 중요한 부분은 **전처리 과정** 이다. \n","\n","\n","## 4.1 Preprocessing\n","\n","### 4.1.1 Corpus?\n","\n","'말뭉치' == corpus(코퍼스): 여러 단어들로 이뤄진 문장.\n","\n","- monolingual corpus(단일 언어 코퍼스): 한 가지 언어로 구성된 코퍼스\n","\n","- bilingual corpus(이중 언어 코퍼스): 두 개의 언어로 구성된 코퍼스\n","\n","- multilingual corpus(다중 언어 코퍼스): 다수의 언어로 구성된 코퍼스\n","\n","- parallel corpus(병렬 코퍼스): 언어 간의 쌍으로 구성된 코퍼스\n","\n","코스가 많고 오류가 적을수록 자연어 처리 머신러닝 모델은 더 정교하고 정확도가 높아진다.\n","\n","### 4.1.2 전처리 과정 개요\n","\n","1. 코퍼스 수집\n","\n","2. 정제\n","\n","3. 문장 단위 분절\n","\n","4. 분절\n","\n","5. 병렬 코퍼스 정렬(생략 가능)\n","\n","6. 서브 워드 분절\n","\n","\n","## 4.2 코퍼스 수집\n","\n","코퍼스 수집 방법 다양하다. 특정 도메인을 위한 자연어 처리 문제가 아니라면 특정 도메인에 편향되지 않도록 다양한 도메인에서 코퍼스를 수집하는 것이 중요하다.\n","\n","웹에서 크롤링을 통해 코퍼스를 수집하는 방법은 법적인(저작권) 문제가 생길 수 있으므로, 해당 웹사이트 크롤링 허용 여부는 사이트 robot.txt를 확인하자.\n","\n","크롤링 시 selenium package를 사용하면 동적으로 크롤링이 가능하다. 이후 beautiful-soup(bs4)를 사용해 HTML 코드를 쉽고 간단하게 파싱한다.\n","\n","### 4.2.1 단일 언어 코퍼스 수집\n","\n","monolingual corpus는 가장 쉽게 구할 수 있는 코퍼스. \n","\n","### 4.2.2 다중 언어 코퍼스 수집\n","\n","MT(기계번역)을 위한 병렬 코퍼스 수집은 상당히 어려움.\n","\n","자막을 병렬 코퍼스로 사용할 경우 몇 가지 문제점\n","\n","- 번역 품질 저하로 인한 문제\n","\n","- 대명사('he', 'she', etc..)가 사람 이름 등의 고유명사로 표현될 때도 많다.\n","\n","## 4.3 정제(Normalization)\n","\n","텍스트를 사용하기에 앞서 필수적인 과정\n","\n","### 4.3.1 전각 문자 제거\n","\n","- 전각문자: 문자의 폭이 일반적인 영문자의 고정 폭의 두 배 정도의 폭을 가지는 문자\n","- 반각문자: 전각 문자 폭의 절반을 폭으로 하는 문자\n","\n","\n","대부분의 중국어, 일본어, 한국어 문서의 숫자, 영자, 기호가 전각문자 일때가 있다. 이 경우 일반적으로 사용하는 **반각 문자**로 변환 작업이 필요하다.\n","\n","### 4.3.2 대소문자 통일\n","\n","일부 영어 코퍼스에서 약자 등에서의 대소문자 표현이 통일되지 않을 때가 있다.\n","\n","ex) New York City $\\to$ NYC, nyc, N.Y.C, N.Y.C.\n","\n","다양한 표현의 일원화: 하나의 의미를 지니는 여러 단어를 하나의 형태로 통일해 **희소성(sparsity)**를 줄이는 효과\n","\n","### 4.3.3 정규 표현식을 사용한 정제\n","\n","크롤링을 통해 수집된 코퍼스는 노이즈(특수 문자, 기호)가 섞일 때가 많다.\n","\n","- '2 or 3 or 4 or 5 or c or d or e' $\\to$ [2345cde] or [2|3|4|5|c|d|e]\n","\n","- '-': 연속된 숫자 or 알파벳 표현\n","\n","- '^': Not\n","\n","- (): 그룹을 만든다. \n","\n","\n","## 4.4 문장 단위 분절\n","\n","보통은 다루려는 문제들은 입력 단위가 문장 단위인 경우가 많다. \n","\n","대부분의 경우 한 라인에 한 문장만 있어야 한다. 여러 문장이 한 라인에 있거나 한 문장이 여러 라인에 걸쳐 있으면 **문장 단위 분절이 필요한다.**\n","\n","단순 마침표 기준으로 문장 분절을 수행시 영여 약자 or 소수점 등 여러 문제가 생길 수 있다. \n","\n","NLTK의 분절 모듈을 사용하면 편하다. 하지만 완벽히 처리되는 것은 아님, 추가적인 전/후 처리가 필요할 수 있다.\n","\n","## 4.5 분절\n","\n","풀고자 하는 문제에 따라 **형태소 분석** or 단순한 분절 통해 정규화를 수행\n","\n","### 4.5.1 한국어 분절\n","\n","- Mecab: 한국어 분절에 가장 많이 사용됨. \n","\n","- KoNLPy: Python으로 구성된 라이브러리를 제공, Mecab에 비해 느려 대용량의 코퍼스를 처리할 때 불리. 설치 및 사용이 쉽고 다양한 라이브러리 모음.\n","\n","### 4.5.2 영어 분절\n","\n","- Moses: 쉼표(comma), 마침표(period), 인용부호(quotation) 띄어주어야 한다. Mosese 분절 기능을 통해 이를 처리.\n","\n","\n","### 4.5.3 중국어 분절\n","\n","- Stanford Parser: 스탠포드 대학에서 제작한 중국어 파서\n","\n","- JIEBA: 파이썬으로 구현 됨\n","\n","\n","## 4.6 병렬 코퍼스 정렬\n","\n","대부분의 병렬 코퍼스들은 여러 문장 단위로 정렬됨. \n","\n","ex) 영자 신문에서 크롤링한 영문 뉴스 기사는 한글 뉴스 기사에 매핑 됨, but 문서와 문서 단위의 매핑이지 **문장과 문장에 관한 정렬을 이뤄지지 않음.**\n","$\\to$ 각각의 문장에 대해 정렬 필요 (과정에서 일부 불필요한 문장 제거, 문장 간 정렬이 안맞다면 정렬을 재정비 or 제거)\n","\n","### 4.6.1 병렬 코퍼스 제작 프로세스 개요\n","\n","**정렬(Alignment)** 과정\n","\n","1. Source language 와 target language 사이의 단어 사전을 준비\n","\n","2. 준비된 사전이 없다면, 3 ~ 6. 과정을 진행\n","\n","3. 각 언어에 대해 코퍼스 수집 및 정제\n","\n","4. 각 언어에 대해 단어 임베딩 벡터를 구한다. \n","\n","5. MUSE를 통해 단어 레벨 번역기를 훈련\n","\n","6. 훈련된 단어 레벨 번역기를 통해 두 언어 사이의 사전을 생성\n","\n","7. 생성된 단어 사전을 넣어 Champollion을 통해 기존에 수집된 다중 언어 코퍼스를 정렬\n","\n","8. 각 언어에 대해 단어 사전을 적용하기 위해 알맞은 수준의 분절을 수행\n","\n","9. 각 언어에 대해 정제를 수행\n","\n","10. Champollion을 사용해 병렬 코퍼스를 생성\n","\n","\n","### 4.6.2 사전 생성\n","\n","Facebook의 MUSE는 병렬 코퍼스가 없는 상황에서 사전을 구축하는 방법과 코드를 제공\n","\n","각 단일 언어 코퍼스를 통해 구축한 언어별 단어 임베딩 벡터에 대해 다른 언어의 임베딩 벡터와 맵핑(mapping)시켜 단어 간 번역을 수행\n","(각 언어별 코퍼스가 많고, 임베딩 벡터가 많을수록 정확도가 높아진다.)\n","\n","즉, MUSE는 병렬 코퍼스가 없는 상황에서 수행할 수 있는 Unsupervised Learning이라고 할 수 있다.\n","\n","\n","### 4.6.3 CTK 활용한 정렬\n","\n","**CTK(Champollion ToolKit)**: 이중 언어 코퍼스의 문장 정렬을 수행하는 opensource. 위 MUSE를 통한 결과를 CTK의 입력으로 넣는다.\n","\n","결과는 문장이 버려지거나(omitted) 일대일 맵핑, 일대다, 다대일 맵핑으로 나올 수 있다.\n","\n","## 4.7 서브워드 분절\n","\n","**BPE(Byte Pair Encoding)** \n","\n","- BPE Algorithm을 통한 서브워드 단위 분절은 필수 전처리 방법으로 자리잡음\n","\n","서브워드 분절 기법?\n","\n","가정: 단어는 의미를 가진 더 작은 서브워드들의 조합으로 이뤄진다.\n","\n","ex)\n","\n","<영어>\n","\n","- concentrate: con(together) + centr(center) + ate(make)\n","\n","<한국어>\n","\n","- 집중: (모을)집 + (가운데) 중\n","\n","\n","장점:\n","\n","- 희소성 감소\n","\n","- UNK(UNKnown) 토큰에 대해 효율적 대처 가능\n",": UNK은 언어 모델의 확률을 크게 망치고 적절한 문장의 임베딩(인코딩) 생성이 어렵다.\n","\n","서브워드 단위 분절을 통해 신조어 or 오탈자 같은 UNK 대해 서브워드 단위 문자(character) 단위로 쪼개 토큰 조합으로 만들 수 있다.\n","\n","\n","## 4.8 분절 복원(Detokenization)\n","\n","분절 복원 왜 필요?\n","\n","분절까지 전처리 과정이 끝나면 분절된 문장이 결과로 나온다. 이때 이 문장들을 학습에 사용하게 되면 결과도 분절된 문장으로 나오게 된다. 따라서 문장을 **분절 복원**하여 사람이 읽기 좋은 형태로 만들어야 한다.\n","\n","\n","## 4.9 토치텍스트\n","\n","**torchText**: 자연어 처리 문제 or 텍스트 관한 ML, DL을 수행하는 **데이터를 읽고 전처리 하는 코드 모음 라이브러리**\n","\n","- Field Class: 읽고자 하는 텍스트 파일 내의 필드를 먼저 정의\n","\n","정의된 각 필드를 Dataset Class를 이용해 읽는다. \n","\n","읽어들인 코퍼스를 미니배치 크기에 따라 나뉠 수 있도록 iterator에 들어간다. 매니배치 구성 과정에서 미니배치 내에 문장 길이가 다를 경우 **패딩(padding, PAD)**를 삽입\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"8ONuNrdl0XQT"},"source":[""],"execution_count":null,"outputs":[]}]}