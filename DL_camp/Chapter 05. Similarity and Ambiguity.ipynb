{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter 05. Similarity and Ambiguity.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNnxrc15/ZJnXqcLA2kJeJM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"u7_ydyQf3zRG"},"source":["# Chapter 05. 유사성 & 모호성\n","\n","## INDEX\n","\n","### 5.1 단어의 의미\n","\n","### 5.2 One-hot Encoding\n","\n","### 5.3 시소러스를 활용한 단어 의미 파악\n","\n","### 5.4 특징\n","\n","### 5.5 특징 추출하기: TF-IDF\n","\n","### 5.6 특징 벡터 만들기\n","\n","### 5.7 벡터 유사도 구하기\n","\n","### 5.8 단어 중의성 해소\n","\n","### 5.9 선택 선호도\n","\n","\n","## 5.1 단어의 의미\n","\n","**단어의 의미(word sense)**: 단어는 겉으로 보이는 형태 내에 의미를 갖고 효율성을 추구(당연한 정보들은 생략)하기에 모호성이 나타남.\n","\n","### 5.1.1 단어와 의미의 관계\n","\n","**표제어(lemma)**: 단어가 겉으로 보이는 형태\n","\n","일상 대화에서 **주변 정보(context)** 를 활용해 숨겨진 의미를 파악, 이해\n","\n","주변 정보가 부족시 모호성 증가\n","\n","단어는 형태를 공유하면서 서로 다른 뜻을 가진 의미로 구성될 수 있다. (서로 비슷 or 다른 의미로 사용될 수 있다.) \n","\n","**중의성**: 한 가지 형태에 여러 의미가 포함\n","\n","정리) 단어는 표제어라고 하는 겉으로 보이는 형태가 같지만 상황에 따라 의미가 다를 수 있다. 같은 형태의 단어가 서로 의미를 가질 때 발생하는 문제를 **중의성 문제**라고 한다. 이것을 해결하기 위해 **주변 정보(context)**를 잘 활용해야 한다. \n","\n","인공 지능(ML, DL)에서는 단어는 형태를 잘 이해하고 의미를 잘 파악해서 되어 사용되야 한다.\n","\n","\n","### 5.1.2 동형어 & 다의어\n","\n","**동형어(homonym)**: 형태는 같고 서로 뜻이 서로 다른 단어, 의미들이 서로 다른 의미(관련)을 가진다. \n","\n","ex) 다리 $\\to$ 사람 다리, 책상 다리\n","\n","**다의어(polysemy)**: 한 형태의 단어가 여러 의미를 지니고 그 의미들이 서로 관련되어 있는 뜻을 가지는 단어\n","\n","ex) 차 $\\to$ 마시는 차(tea), 달리는 차(car)\n","\n","단어가 동형어 or 다의어이라면 **단어 중의성 해소(Word Senese Disambiguation, WSD)** 방법을 통해 의미를 명확히 파악하는 과정이 필요\n","\n","DL 이전의 전통적인 NLP 과정에서는 중의성 해소를 위해 **주변 문맥** 통해 단어의 의미를 파악하는 방법 가장 많이 사용되었다. \n","\n","DL의 end-to-end 방법이 선호되고 모델 구조가 RNN으로 넘어오면서 단어 중의성 해소에 대한 필요성이 낮아졌다. BUT, 여전히 단어의 모호한 의미로 인한 문제 해결이 어려운 경우가 많다. \n","\n","### 5.1.3 동의어\n","\n","**동의어(Synonym)**: 다른 형태지만 의미가 같은 단어 (어느 정도 비슷한 의미를 가진다면 동의어라고 칭한다.) \n","\n","**동의어 집합(synset)**: 동의어가 여러 개 존재할 때 이들의 집합\n","\n","ex) 동의어 집합:{dwelling, domicile, abode, habitation} $\\to$ 의미: home\n","\n","### 5.1.4 상위어 & 하위어\n","\n","사람이 사용하는 단어는 하나의 추상적 개념을 나타냄.\n","\n","- 상위어 개념: 개념들을 포함하는 상위 개념을 가리키는 단어\n","\n","- 하위어 개념: 개념들을 포함하는 하위 개념을 가리키는 단어\n","\n","ex) \n","- 상위어: 동물 / 하위어: 포유류\n","- 상위어: 포유류 / 하위어: 코끼리\n","- 상위어: 코끼리 / 하위어: 아프리카 코끼리\n","\n","상, 하위어는 **어휘 분류(taxonomy)** 에 따라 단어 간 관계를 계층화 가능\n","\n","### 5.1.5 모호성 해소\n","\n","사람의 언어는 불연속적 심볼이며 내부 의미를 지닌다. 컴퓨터는 사람의 언어를 텍스트로 받아 처리를 하는데 텍스트가 가진 내부 의미를 파악하는 과정이 필요하다.\n","\n","결국 텍스트의 겉 형태만 파악하는 것이 아닌 내포된 의미를 파악하여 모호성을 제거하여 성능을 높인다. \n","\n","**단어 중의성 해소(Word-Sense Disambiguation, WSD)**: 단어가 가지는 모호성을 제거하는 과정\n","\n","\n","## 5.2 One-hot Encoding\n","\n","- 동형어: 같은 형태, 관련 없는 다른 의미들을 지닌 단어\n","\n","- 다의어: 같은 형태, 관련된 의미들을 갖는 단어\n","\n","- 동의어: 다른 형태, 비슷한 의미를 갖는 단어들\n","\n","단어는 불연속적 심볼, 동형어를 제외한 단어는 내부 의미는 유사, 겉 형태는 다른 경우가 많다.\n","\n","사람이 상식을 이용해 유사한 단어들로 부터 부족한 정보를 보완하는 것 처럼 불연속적인 단어 간 유사도를 효과적으로 구하는 것을 연구되어왔다. DL에서는 유사도를 효율적으로 구하기 위해 다양한 임베딩 방법들을 사용한다.\n","\n","컴퓨터가 단어(텍스트)를 인식하기 위해서는 데이터를 숫자로 변형시켜야 한다. 즉, 벡터로 표현을 해야 한다. 가장 쉬운 방법은 one-hot encoding 방식이다. \n","\n","#### one-hot encoding 표현\n","- 0, 1로만 구성된 벡터로 단어를 표현\n","\n","- 벡터의 차원: 전체 어휘(vocabulary)의 개수\n","\n","\n","단어는 불연속적인 심볼 $\\to$ 이산 확률 변수로 표현.\n","\n","one-hot vector는 이산 확률 분포로 부터 뽑아낸 샘플이라고 할 수 있다. 멀티눌리 확률 분포가 된다.\n","\n","사전(dictionary) 내의 각 단어를 one-hot encoding으로 나타낼 시 \n","- 벡터의 차원이 너무 커진다.\n","- 해당하는 단어는 1로 나머지는 0으로 표현되기에 많은 부분이 0으로 채워진 희소 벡터(sparse vector)이다.\n","- **희소 벡터를 통해 유사도를 구할 시 결과값이 0이다.** $\\to$ 선형대수의 관점으로 볼때 내적의 결과값이 0이므로 두 벡터는 **직교(orthogonal)**이다. \n","($[0,0,...,1,0] \\times [0,1,0,...,0]^T = 0$)\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"PGc7nC2k3Ges"},"source":[""],"execution_count":null,"outputs":[]}]}