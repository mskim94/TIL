{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 04. 신경망 학습\n",
    "\n",
    "신경망 학습에 대해 배운다.\n",
    "\n",
    "학습이란? 데이터로부터 가중치 매개변수의 최적값을 자동으로 얻는것\n",
    "\n",
    "신경망이 학습할 수 있도록 하는 **지표** 인 **손실 함수(Loss Function)** 소개한다.\n",
    "\n",
    "학습 목표: 손실함수의 결괏값을 가장 작게하는 가중치 매개변수를 찾는 것\n",
    "\n",
    "손실 함수의 값을 작게 만드는 기법으로 **경사 하강법(Gradient Descent)** 가 있다.\n",
    "\n",
    "## 4.1 데이터에서 학습한다!\n",
    "\n",
    "신경망의 특징: 데이터를 보고 학습한다. $\\rightarrow$ 가중치 매개변수의 값을 데이터를 보고 자동으로 결정한다.\n",
    "\n",
    "### 4.1.1 데이터 주도 학습\n",
    "기계학습에서 **데이터**는 매우 중요\n",
    "\n",
    "문제를 풀때, 특히 패턴을 찾을 때, \n",
    "- **사람**은 경험, 직관을 이용하여 시행착오를 거듭하면서 문제 해결을 진행\n",
    "- **기계학습**은 사람 개입을 최소화, 수집한 데이터로 부터 패턴을 찾으려 시도\n",
    "- **신경망, 딥러닝**은 기계학습 보다 더 사랑ㅁ의 개입을 배제\n",
    "\n",
    "e.g) MNIST 문제를 풀때 Algorithm or program을 처음부터 만들기 어려워 $\\rightarrow$ image에서 **특징** 추출, 그 특징의 패턴을 기계학습 기술로 학습하는 방법이 있다.\n",
    "\n",
    "- 특징(feature): 입력 데이터에서 본질적인 데이터(중요한 데이터) 추출하는 **변환기**, 이 특징은 **벡터(vector)** 로 기술\n",
    "    - Computer Vision 분야에서는 SIFT, SURF, HOG 등 특징 활용\n",
    "\n",
    "특징을 사용해 데이터를 벡터로 변환, 이 변환된 데이터를 지도학습 대표 기법인 SVM, KNN 등으로 학습 가능하다.\n",
    "\n",
    "모아진 데이터를 기계가 규칙을 찾는다. 처음부터 Algorithm을 설계하는 것보다 효율이 좋지만, 이 **특징** 을 **사람이 설계(개입)**, 문제에 따라 사람이 특징을 생각해야 한다.\n",
    "\n",
    "문제 $\\rightarrow$ 사람이 생각한 Algorithm $\\rightarrow$ 결과\n",
    "\n",
    "$(개선)\\Rightarrow$ 문제 $\\rightarrow$ 사람이 생각한 특징(SIFT, SURF, HOG etc...) $\\rightarrow$ 기계학습(SVM, KNN) $\\rightarrow$ 결과\n",
    "\n",
    "$(개선)\\Rightarrow$ 문제 $\\rightarrow$ 신경망(딥러닝) $\\rightarrow$ 결과\n",
    "\n",
    "신경망(딥러닝)에서는 이미지를 '있는 그대로' 학습, 특징까지 기계가 스스로 학습(기계학습, 신경망(딥러닝) 과정에서는 사람의 개입이 없다.)\n",
    "\n",
    "cf) 딥러닝을 **종단간 기계학습(end-to-end machine learning)** 이라고도 함 $\\Rightarrow$ 데이터(입력)부터 결과(출력)까지 사람의 개입이 없다.\n",
    "\n",
    "**신경망의 이점**: 모든 문제 같은 맥락에서 푼다 $\\Rightarrow$ 모든 문제를 주어진 데이터 그대로 사용, 입력 데이터 활용 'end-to-end'로 학습 가능\n",
    "\n",
    "### 4.1.2 훈련 데이터와 시험 데이터\n",
    "\n",
    "기계학습에서는 데이터를 훈련 데이터와 시험 데이터로 나눈다. \n",
    "\n",
    "Why Split? **범용 능력** 평가를 위해 \n",
    "- 범용 능력: 아직 보지 못한 data(training data에 없는)로 문제를 옳바르게 풀어내는 능력\n",
    "\n",
    "한 데이터에만 지나치게  최적화 된 상태: **오버피팅(overfitting)**\n",
    "\n",
    "## 4.2 손실 함수(Loss Function)\n",
    "\n",
    "신경망 학습에서 현재 상태를 '하나의 지표'로 표현, 이 지표를 가장 좋게 하는 가중치 매개변수 값을 탐색하는 것이 목적\n",
    "\n",
    "**손실 함수**: 신경망 학습에 사용되는 지표\n",
    "\n",
    "일반적으로 손실함수로 \"오차제곱합\", \"교차 엔트로피 오차\" 를 사용\n",
    "\n",
    "### 4.2.1 오차제곱합(Sum of Squares Error, SSE)\n",
    "\n",
    "가장 많이 사용하는 손실 함수 오차제곱합(Sum of Squares Error, SSE)\n",
    "\n",
    "각 원소의 출력(추정값)과 정답 레이블(참 값)의 차($y_k - t_k$)를 제곱(Squares) 후, 그 총합($\\sum$)\n",
    "\n",
    "- $E = \\frac{1}{2} \\sum_{k}(y_k - t_k)^2$\n",
    "    - $y_k$: 신경망의 출력(신경망이 추정한 값)\n",
    "    - $t_k$: 정답 레이블(One-hot-encoding)\n",
    "    - $k$: 데이터의 차원 수\n",
    "    - 신경망 출력 $y$는 Softmax function의 출력(확률로 해석 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0f5a1e8dadf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_squares_error(y, t):\n",
    "    return 0.5 * np.sum((y - t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sum_squares_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6deda4ebb487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum_squares_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sum_squares_error' is not defined"
     ]
    }
   ],
   "source": [
    "sum_squares_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sum_squares_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f4d3d5857ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msum_squares_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sum_squares_error' is not defined"
     ]
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "sum_squares_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오차가 작은 0.097이 정답에 더 가깝다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 교차 엔트로피 오차(Cross-Entropy Error, CEE)\n",
    "\n",
    "CEE도 자주 사용\n",
    "\n",
    "- $E = -\\sum_k t_k \\log{y_k}$\n",
    "    - $y_k$: 신경망의 출력\n",
    "    - $t_k$: 정답 레이블(One-Hot-Encoding)\n",
    "\n",
    "$\\Rightarrow$ 실질적으로 정답 시의 추정($t_k = 1$일때의 $y_k$) (y_k는 확률적인 값이고 그 값들의 총합은 1이다 (Softmax function의 출력이기때문에) $t_k$는 one-hot-encoding되어 정답 레이블인데 정답은 1 나머지는 0으로 수식에서 계산되면 정답 외의 값들은 0으로 처리된다.)\n",
    "\n",
    "$\\Rightarrow$ 교차 엔트로피 오차는 정답일때 **출력이 전체 값을 정한다.**\n",
    "($y_k$의 값이 작다(확률이 작다)면 log가 취해서 전체 CEE의 값 자체가 커진다  $\\rightarrow$ 오차가 커진다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e47f3d2f8152>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  y = np.log(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0.0, 1.0, 0.001)\n",
    "y = np.log(x)\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-5.1, 0.1)  # y축의 범위를 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답일 때의 출력(확률로 해석)이 작아질수록 오차는 커진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7  # log 0은 -inf로 발산하게 되므로 아주 작은 값을 더했다.\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n",
      "2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "print(cross_entropy_error(np.array(y), np.array(t)))\n",
    "\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "print(cross_entropy_error(np.array(y), np.array(t)))\n",
    "# 첫번째 결괏값이 더 작다(오차가 작다). 정답일 가능성이 높다고 판단."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 미니배치 학습\n",
    "\n",
    "기계학습 문제는 훈련 데이터에 대한 손실 함수의 값을 구하고 그 값을 최소화하는 매개변수를 찾는다. $\\rightarrow$ 결국, 모든 훈련 데이터에 대한 손실 함수를 구해야한다.\n",
    "\n",
    "- $E = -\\sum_k t_k \\log{y_k}$ (데이터 1개에 대한 Loss Function)\n",
    "    - $y_k$: 신경망의 출력\n",
    "    - $t_k$: 정답 레이블(One-Hot-Encoding)\n",
    "\n",
    "(N개의 데이터로 확장, N으로 나누어 정규화) $\\Rightarrow$\n",
    "\n",
    "- $E = -\\frac{1}{N}\\sum_{n} \\sum_k t_k \\log{y_k}$ \n",
    "    - $y_k$: 신경망의 출력\n",
    "    - $t_k$: 정답 레이블(One-Hot-Encoding)\n",
    "\n",
    "N으로 나눠 **평균 손실 함수** 구해, But! 데이터가 커지면 시간 오래 걸린다.\n",
    "\n",
    "$\\Rightarrow$ 데이터 일부 추려 **근사치**를 이용 (일부: 미니배치(Mini-batch))\n",
    "\n",
    "**미니배치 학습**: Training data 중 무작위로 뽑아 학습하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "import pickle\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)  # 훈련 데이터 60,000개, 입력 데이터 784(28 x 28)\n",
    "print(t_train.shape)  # 정답 레이블 (0 ~ 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size) # 0 ~ train_size(60,000)에서 무작위로 batch_size(10)개를 뽑음\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3",
   "language": "python",
   "name": "python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
