{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Inner Product, Length, and Orthogonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 용어 정리\n",
    "- Inner Product: $u$ $\\cdot$ $v$ = ${u}^{T} \\cdot v$\n",
    "- unit vector: $\\left\\lVert{u}\\right\\rVert$ = 1\n",
    "- normalizing:  $u$ = $\\frac{1}{\\left\\lVert{v}\\right\\rVert}v$\n",
    "- Orthogonal Vector: 직교 vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Theorem 1.\n",
    "Let $u$, $v$ and $w$ be vectors in $\\mathbb{R}^{n}$, and let $c$ be a scalar.\n",
    "- a. $u$ $\\cdot$ $v$ = $v$ $\\cdot$ $u$\n",
    "- b. ($u$ + $v$) $\\cdot$ $w$ = $u \\cdot w$ + $v \\cdot w$\n",
    "- c. ($cu$) $\\cdot$ $v$ = $c$ ($u \\cdot v$)\n",
    "- d. $u \\cdot u$ $\\geq 0$ and $u \\cdot u$ = 0 $\\Longleftrightarrow$ $u$ = 0\n",
    "\n",
    "#### Length of a Vector\n",
    "The **length** (or **norm**) of $v$ in $\\mathbb{R}^{n}$ is the nonnegative scalar $\\left\\lVert{v}\\right\\rVert$ defined by \n",
    "$\\left\\lVert{v}\\right\\rVert$ = $\\sqrt{v \\cdot v}$ = $\\sqrt{{v}_1^{2} + {v}_2^{2} + \\dots + {v}_n^{2}}$\n",
    "\n",
    "#### Distance in $\\mathbb{R}^n$\n",
    "$u$ 와 $v$가 $\\mathbb{R}^{n}$ 에 있고 $u$와 $v$사이의 거리는 **dist(u,v)** 쓰고 $u-v$의 **length**이다.\n",
    "- dist(u, v) = $\\left\\lVert{u - v}\\right\\rVert$\n",
    "$\\Longrightarrow$\n",
    "$u$ 와 $v$의 거리 = $u - v$의 length\n",
    "\n",
    "#### Orthogonal Vectors\n",
    "- Two vectors $u$ and $v$ in $\\mathbb{R}^{n}$ are **orthogonal** if $u \\cdot v = 0$\n",
    "- The **zero vector** is **orthogonal to every vector** in $\\mathbb{R}^{n}$\n",
    "\n",
    "### Theorem 2. Pythagorean Theorem\n",
    "Two vectors $u$ and $v$ are **orthogonal** $\\Longleftrightarrow$ ${\\left\\lVert{u+v}\\right\\rVert}^2$ = ${\\left\\lVert{u}\\right\\rVert}^2$ + ${\\left\\lVert{v}\\right\\rVert}^2$\n",
    "\n",
    "#### Orthogonal Complements\n",
    "- $W$를 공간 $\\mathbb{R}^{3}$안의 원점을 지나는 평면이라고 하고, $L$을 $W$와 직교하하고 원점을 지나는 직선이라고 하면,\n",
    "if vector $z$는 공간 $\\mathbb{R}^{3}$ 안의 subspace $W$의 모든 vector에 대해 orthogonal하고, $z$는 orthogonal to $W$라고 한다.\n",
    "- $W$에 orthogonal한 vector z의 set인 set fof all vectors $z$는 **orthogonal complement of $W$** 라고 하고 ${W}^{\\perp}$로 표기한다. \n",
    "\n",
    "\n",
    "### Theorem 3.\n",
    "${(Row A)}^{\\perp}$ = $Nul A$ and ${(Col A)}^{\\perp}$ = $Nul {A}^{T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Orthogonal Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 용어 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "#### Orthogonal Set\n",
    ": 공간 $\\mathbb{R}^{n}$의 orthogonal한 vector들의 set, set안의 모든 vector들이 orthogonal하다.\n",
    "\n",
    "\n",
    "### Theorem 4.\n",
    "$S$ = \\{${u}_1,...,{u}_p$\\}가 $\\mathbb{R}^n$안의 **nonzero vectors**의 orthogonal set이라면, S는 linearly independent이고 S에 의해 span되는 subspace의 **basis**이다.\n",
    "\n",
    "#### Orthogonal Basis\n",
    "공간 $\\mathbb{R}^n$의 subspace $W$에 **Orthogonal basis**는 $W$의 basis이고 orthogonal set이다.\n",
    "\n",
    "### Theorem 5.\n",
    "\\{${u}_1,...,{u}_p$\\}가 $\\mathbb{R}^n$의 subspace $W$에 대한 orthogonal basis 라 하자. $W$ 안의 $y$ 는 linear combination으로 표현할 수 있다.\n",
    "- $y = {c}_1{u}_1 + \\dots + {c}_p{u}_p$, ${c}_{j} = \\frac{y \\cdot {u}_{j}}{{u}_j \\cdot {u}_j}$\n",
    "- Orthogonal basis면 ${c}_j$(weight)가 주어져서 nice하다.\n",
    "\n",
    "#### Orthogonal Projection\n",
    "$B$ = \\{${u}_1,...,{u}_n$\\}이 공간 $\\mathbb{R}^n$의 orthogonal basis라 하자. \n",
    "- $y = {c}_1{u}_1 + \\dots + {c}_n{u}_n$으로 표현할수 있고\n",
    "$\\hat{y} = {proj}_Ly = \\frac{y \\cdot {u}_1}{{u}_1 \\cdot {u}_1}{u}_1$, $y = \\hat{y} + z$ ($z$: the component of y orthogonal to ${u}_1$)\n",
    "\n",
    "#### Orthonormal Sets\n",
    "$A$ = \\{${u}_1,...,{u}_n$\\}이 unit vectors의 orthogonal set이면, A를 **orthonormal set** 이라고 한다.\n",
    "\n",
    "### Theorem 6.\n",
    "m x n matrix $U$ 가 orthonormal columns을 가진다. $\\Longleftrightarrow$ ${U}^{T}U = I$\n",
    "\n",
    "### Theorem 7.\n",
    "Let $U$ be an m x n matrix with **orthonormal columns** , and let $x$ and $y$ be in $\\mathbb{R}^n$ 하면.\n",
    "- a. ${\\left\\lVert{Ux}\\right\\rVert}$ = ${\\left\\lVert{x}\\right\\rVert}$\n",
    "- b. ($Ux$) $\\cdot$ ($Uy$) = $x$ $\\cdot$ $y$\n",
    "- c. ($Ux$) $\\cdot$ ($Uy$) = 0 $\\Longleftrightarrow$ $x$ $\\cdot$ $y$ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Orthogonal Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 용어 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Theorem 8. The Orthogonal Decomposition Theorem\n",
    "$W$를 공간 $\\mathbb{R}^n$의 subspace라고 하자. 공간 $\\mathbb{R}^n$의 each $y$는 **uniquely**하게 $y = \\hat{y} + z$의 형태로 쓸 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
