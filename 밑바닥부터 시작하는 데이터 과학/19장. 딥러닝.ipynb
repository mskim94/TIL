{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝\n",
    "**딥러닝(deep learning)** 은 (한 개 이상의 은닉층을 지닌) '깊은' 신경망을 의미한다. \n",
    "\n",
    "요즘에는 다양한 신경망 구조를 모두 아우르는 용어가 되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.1 텐서\n",
    "1차원 배열은 벡터, 2차원 배열은 행렬으로 명명하였다. 복잡한 신경망 구조에서는 더 고차원 배열이 필요한데 대부분의 신경망 라이브러리의 명칭을 따라서 n차원 배열을 **텐서(tensor)**라고 하겠다.\n",
    "\n",
    "텐서를 리스트로 정의해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 텐서의 크기를 반환해 주는 도우미 함수(helper function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def shape(tensor: Tensor) -> List[int]:\n",
    "    sizes: List[int] = []\n",
    "    while isinstance(tensor, list):\n",
    "        sizes.append(len(tensor))\n",
    "        tensor = tensor[0]\n",
    "    return sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert shape([1, 2, 3]) == [3]\n",
    "assert shape([[1, 2], [3, 4], [5, 6]]) == [3, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서마다 차원의 수가 다양하기  때문에 재귀적으로 텐서를 살펴봐야 한다. \n",
    "\n",
    "밑의 함수는 1차원 벡터부터 재귀적으로 고차원의 텐서까지 살펴볼 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_1d(tensor: Tensor) -> bool:\n",
    "    \"\"\"\n",
    "    만약 tensor[0]이 리스트라면 고차원 텐서를 의미\n",
    "    그러지 않으면 1차원 벡터를 의미\n",
    "    \"\"\"\n",
    "    return not isinstance(tensor[0], list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_1d([1, 2, 3])\n",
    "assert not is_1d([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 함수를 사용해 텐서 안의 모든 값의 합을 반환해주는 tensor_sum 함수를 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_sum(tensor: Tensor) -> float:\n",
    "    \"\"\"텐서 안의 모든 값의 합을 반환\"\"\"\n",
    "    if is_1d(tensor):\n",
    "        return sum(tensor)  # 벡터의 경우, 파이썬 기본 함수인 sum을 사용\n",
    "    else:\n",
    "        return sum(tensor_sum(tensor_i)  # 벡터가 아닌 경우, 각 행별 tensor_sum을 호출하고\n",
    "                  for tensor_i in tensor)  # 결과값을 더해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tensor_sum([1,2,3]) == 6\n",
    "assert tensor_sum([[1,2], [3,4]]) == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 else statement에 tensor_sum이 재귀적으로 사용되었다. \n",
    "\n",
    "매번 이렇게 재귀적으로 구현하는 것은 번거로우니 이러한 기능을 대신해 주는 도우미 함수를 만들자. 먼저 텐서 안의 모든 값에 일괄적으로 함수를 적용할 수 있게 해주는 함수를 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def tensor_apply(f: Callable[[float], float], tensor: Tensor) -> Tensor:\n",
    "    \"\"\"텐서 안의 모든 값에 f를 적용\"\"\"\n",
    "    if is_1d(tensor):\n",
    "        return [f(x) for x in tensor]\n",
    "    else:\n",
    "        return [tensor_apply(f, tensor_i) for tensor_i in tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tensor_apply(lambda x: x + 1, [1, 2, 3]) == [2, 3, 4]\n",
    "assert tensor_apply(lambda x: 2 * x, [[1, 2], [3, 4]]) == [[2, 4], [6, 8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 도우미 함수를 사용하면 주어진 크기와 동일한 0 텐서를 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros_like(tensor: Tensor) -> Tensor:\n",
    "    return tensor_apply(lambda _: 0.0, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert zeros_like([1,2,3]) == [0, 0, 0]\n",
    "assert zeros_like([[1,2], [3, 4]]) == [[0, 0], [0, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 두 텐서의 대칭되는 값에 일괄적으로 함수를 적용할 수 있게 해주는 함수를 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_combine(f: Callable[[float, float], float],\n",
    "                  t1: Tensor,\n",
    "                  t2: Tensor) -> Tensor:\n",
    "    \"\"\"두 텐서의 대칭되는 t1과 t2에 일괄적으로 함수를 적용\"\"\"\n",
    "    if is_1d(t1):\n",
    "        return [f(x, y) for x, y in zip(t1, t2)]\n",
    "    else:\n",
    "        return [tensor_combine(f, t1_i, t2_i)\n",
    "               for t1_i, t2_i in zip(t1, t2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "assert tensor_combine(operator.add, [1,2,3], [4,5,6]) == [5,7,9]\n",
    "assert tensor_combine(operator.mul, [1,2,3], [4,5,6]) == [4,10,18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.2 층 추상화\n",
    "18장에서는 각각 sigmoid(dot(weights, inputs))를 계산해 주는 두 층으로 구성된 단순한 신경망을 만들어 보았다.\n",
    "\n",
    "이러한 구조는 실제 뉴런이 작동하는 방식과 비슷하지만, 딥러닝에서는 다양한 신경망 구조를 사용할 것이다. 가령 각 뉴런이 이전 입력값을 기억하도록 만들거나 시그모이드 대신 다른 활성화 함수(activation function)를 사용할 것이다. 또한 두 층보다 더 깊은 신경망을 만들 것이다. (feed_forward 함수로 두 층 이상의 신경망을 만드는 것은 구현했지만 그래디언트를 계산하는 것은 아직 구현하지 않았다.)\n",
    "\n",
    "이번 장에서는 이러한 다양한 신경망을 구현해 볼 것이다. 가장 핵심적인 **추상화** 는 신경망의 각 층을 나타내는 Layer이다. Layer에서는 입력값에 특정 함수를 적용하거나 역전파를 할 수 있어야 한다. 18장에서 구현한 신경망은 '선형'층 위에 '시그모이드' 층으로 구성된 신경망이라고 볼 수 있다.\n",
    "\n",
    "새로운 용어라 어색할 수도 있지만 이렇게 받아들이는 것이 다양한 신경망 구조를 이해하는 데 도움이 될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    딥러닝 신경망은 Layer들로 구성되어 있다.\n",
    "    각 Layer별로 순방향으로 입력값에 어떤 계산을 하고\n",
    "    역방향으로 그래디언트를 전파해야 한다.\n",
    "    \"\"\"\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        타입이 명시되어 있지 않은 것을 유의하자.\n",
    "        입력층과 출력값의 타입의 제한하지 않을 것이다.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "            \n",
    "    def backward(self, gradient):\n",
    "        \"\"\"\n",
    "        역방향에서도 그래디언트의 타입을 제한하지 않을 것이다.\n",
    "        메서드를 호출할 때 유의하자.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def params(self) -> Iterable[Tensor]:\n",
    "        \"\"\"\n",
    "        해당 층의 파라미터를 반환\n",
    "        기본적으로 아무것도 반환하지 않을 것이다.\n",
    "        만약 특정 층에서 반환할 파라미터가 없다면 구현할 필요가 없다.\n",
    "        \"\"\"\n",
    "        return ()\n",
    "    \n",
    "    def grads(self) -> Iterable[Tensor]:\n",
    "        \"\"\"\n",
    "        params()처럼 그래디언트를 반환\n",
    "        \"\"\"\n",
    "        return ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward, backward 메서드는 곧 구현할 것이다. 그리고 경사 하강법으로 신경망의 파라미터를 학습하기 위해 각 층의 파라미터와 그래디언트를 반환해 줄 수 있어야 한다. \n",
    "\n",
    "시그모이드 층과 비슷한 층에서는 파라미터를 업데이트할 필요가 없기 때문에 이러한 경우를 위해 기본값 설정 또한 해주었다.\n",
    "\n",
    "먼저 시그모이드 층을 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(t: float) -> float:\n",
    "    return 1 / (1 + math.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Layer):\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        입력된 Tensor의 모든 값에 sigmoid를 계산\n",
    "        backpropagation을 위해 결괏값을 저장\n",
    "        \"\"\"\n",
    "        self.sigmoids = tensor_apply(sigmoid, input)\n",
    "        return self.sigmoids\n",
    "    \n",
    "    def backward(self, gradient: Tensor) -> Tensor:\n",
    "        return tensor_combine(lambda sig, grad: sig * (1 - sig) * grad, self.sigmoids, gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "몇 가지 유의할 점이 있다. 역전파를 위해 순방향에서 계산되는 시그모이드 값을 모두 저장할 것이다. 앞으로 층의 순방향에서 계산되는 값은 대부분 저장할 것이다. \n",
    "\n",
    "두 번째로 sig * (1 - sig) * grad가 어디서 나왔는지 궁금할 것이다. 이 값은 18장에서 다룬 미적분과 연쇄법칙으로 계산된 output * (1 - output) * (output - target)이다.]\n",
    "\n",
    "마지막으로 tensor_apply와 tensor_combine 함수를 사용했다. 앞으로 구현할 모든 층에서는 기본적으로 두 함수를 사용할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.3 선형 층\n",
    "18장에서 구현한 신경망을 기반으로 뉴런의 dot(weights, inputs)를 나타내는 선형 층(linear layer)을 구현할 수 있다.\n",
    "\n",
    "선형 층의 초깃값은 임의로 생성할 것이다.\n",
    "\n",
    "사실 임의로 파라미터의 초깃값을 설정하는 것은 매우 중요하다. 파라미터의 초깃값에 따라 신경망의 학습 속도가 (혹은 학습 여부 자체가) 결정된다. 만약 초깃값이 너무 크면 활성화 함수의 그래디언트는 0에 가깝게 된다. 그래디언트가 0에 가까운 파라미터는 경사 하강법으로 학습을 할 수 없게 된다.\n",
    "\n",
    "따라서 파라미터를 임의로 생성해 주는 세 가지 방법을 구현할 것이다. 먼저 random.random()으로 균등 분포를 구현하여, 파라미터의 초깃값을 0과 1 사이 임의의 값으로 설정할 것이다. 두 번째 방법으로 표준정규분표에서 임의의 초깃값을 생성할 것이다. 마지막으로 딥러닝에서 자주 쓰이는 Xavier 초기화에서는 평균이 0이고 편차가 2 / (입력 값의 개수 + 출력 값의 개수)인 정규분포에서 임의의 초깃값을 생성할 것이다. 세 가지 방법 모두 random_uniform과 random_normal 함수로 구현할 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def normal_cdf(x: float, mu: float = 0, sigma: float = 1) -> float:\n",
    "    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2\n",
    "\n",
    "def inverse_normal_cdf(p: float,\n",
    "                      mu: float = 0,\n",
    "                      sigma: float = 1,\n",
    "                      tolerance: float = 0.00001) -> float:\n",
    "    \"\"\"이진 검색을 사용해 역함수를 근사\"\"\"\n",
    "    # 표준정규분포가 아니라면 표준정규분포로 변환\n",
    "    if mu != 0 or sigma != 1:\n",
    "        return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)\n",
    "    \n",
    "    low_z = -10.0  # normal_cdf(-10)은 0에 근접\n",
    "    hi_z = 10.0  # normal_cdf(10)은 1에 근접\n",
    "    while hi_z - low_z > tolerance:\n",
    "        mid_z = (low_z + hi_z) / 2  # 중간 값\n",
    "        mid_p = normal_cdf(mid_z)  # 중간 값의 누적분포 값을 계산\n",
    "        if mid_p < p:\n",
    "            low_z = mid_z  # 중간 값이 너무 작다면 더 큰 값들을 검색\n",
    "        else:\n",
    "            hi_z = mid_z  # 중간 값이 너무 크다면 더 작은 값들을 검색\n",
    "    \n",
    "    return mid_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_uniform(*dims: int) -> Tensor:\n",
    "    if len(dims) == 1:\n",
    "        return [random.random() for _ in range(dims[0])]\n",
    "    else:\n",
    "        return [random_uniform(*dims[1:]) for _ in range(dims[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_normal(*dims: int, \n",
    "                 mean: float = 0.0,\n",
    "                 variance: float = 1.0) -> Tensor:\n",
    "    if len(dims) == 1:\n",
    "        return [mean + variance * inverse_normal_cdf(random.random())\n",
    "               for _ in range(dims[0])]\n",
    "    else:\n",
    "        return [random_normal(*dims[1:], mean=mean, variance=variance)\n",
    "               for _ in range(dims[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert shape(random_uniform(2, 3, 4)) == [2, 3, 4]\n",
    "assert shape(random_normal(5, 6, mean=10)) == [5, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 random_tensor 함수로 감싸주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_tensor(*dims: int, init: str = 'normal') -> Tensor:\n",
    "    if init == 'normal':\n",
    "        return random_normal(*dims)\n",
    "    elif init == 'uniform':\n",
    "        return random_uniform(*dims)\n",
    "    elif init == 'xavier':\n",
    "        variance = len(dims) / sum(dims)\n",
    "        return random_normal(*dims, variance=variance)\n",
    "    else:\n",
    "        raise ValueError(f\"unkown init: {init}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 선형 층을 구현할 준비가 끝났다. 먼저 입력값의 차원 수(각 뉴런별 파라미터 개수), 출력값의 차원 수(뉴런의 개수), 초기화 방법을 명시해 줘야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vector = List[float]\n",
    "\n",
    "def dot(v: Vector, w: Vector) -> float:\n",
    "    \"\"\"v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    assert len(v) == len(w),  \"vectors must be same length\"\n",
    "    \n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self,\n",
    "                input_dim: int,\n",
    "                output_dim: int,\n",
    "                init: str = 'xavier') -> None:\n",
    "        \"\"\"\n",
    "        output_dim개의 뉴런과 각 뉴런별 input_dim개의 파라미터로 (편향 제외)\n",
    "        구성된 층\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # self.w[o]는 o번째 뉴런의 파라미터\n",
    "        self.w = random_tensor(output_dim, input_dim, init=init)\n",
    "        \n",
    "        # self.b[o]는 o번째 뉴런의 편향\n",
    "        self.b = random_tensor(output_dim, init=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 층의 forward 메서드는 쉽게 구현할 수 있다. 뉴런별 한 개의 값을 벡터로 저장할 것이다. 각 뉴런의 입력값과 파라미터를 곱하고 편향을 더해주면 출력값이 계산된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, input: Tensor) -> Tensor:\n",
    "    # 역방향을 위해 input을 저장\n",
    "    self.input = input\n",
    "    \n",
    "    # 뉴런의 결괏값을 벡터로 반환\n",
    "    return [dot(input, self.w[o]) + self.b[o]\n",
    "           for o in range(self.output_dim)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backward 메서드는 조금 더 복잡하지만, 미적분을 알고 있다면 금방 이해할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, gradient: Tensor) -> Tensor:\n",
    "    # 각 b[o]는 output[o]에 더해진다.\n",
    "    # 즉, b의 그래디언트는 output의 그래디언트과 동일하다는 것을 의미\n",
    "    self.b_grad = gradient\n",
    "    \n",
    "    # 각 w[o][i]를 input[i]에 곱하고 output[o]에다 더해 준다.\n",
    "    # 즉, 그래디언트는 input[i] * gradient[o]\n",
    "    self.w_grad = [[self.input[i] * gradient[o]\n",
    "                   for i in range(self.input_dim)]\n",
    "                   for o in range(self.output_dim)]\n",
    "    # input[i]에 각 w[o][i]를 곱하고\n",
    "    # output[o]에 더해 주기 때문에 그래디언트는 w[o][i] * gradient[o]를\n",
    "    # 모두 더해 준 값\n",
    "    return [sum(self.w[o][i] * gradien[o] for o in range(self.output_dim))\n",
    "           for i in range(self.input_dim)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 params와 grads 메서드를 만들어 보자. 선형 층에는 두 개의 파라미터와 그래디언트가 있다는 것을 기억하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params(self) -> Iterable[Tensor]:\n",
    "    return [self.w, self.b]\n",
    "\n",
    "def grads(self) -> Iterable[Tensor]:\n",
    "    return [self.w_grad, self.b_grad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.4 순차적인 층으로 구성된 신경망\n",
    "신경망을 순차적인 층으로 구성되어 있다고 생각해 볼 수 있다. 그렇다면 여러층을 하나의 층으로 표현할 수도 있을 것이다. 즉, 하나의 신경망 자체를 Layer의 메서드를 활용해서 하나의 층으로 표현해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class Sequential(Layer):\n",
    "    \"\"\"\n",
    "    하나의 Layer에는 실제 여러 층이 포함되어 있다. \n",
    "    각 층의 출력값이 \n",
    "    다음 층의 입력값이 된다는 것을 꼭 이해하고 넘어가자\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers: List[Layer]) -> None:\n",
    "        self.layers = layers\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"순차적으로 각 층의 입력값을 전파\"\"\"\n",
    "        for layer in self.layers:\n",
    "            input = layer.forward(input)\n",
    "        return input\n",
    "    \n",
    "    def backward(self, gradient):\n",
    "        \"\"\"역방향으로 각 층의 그래디언트를 전파\"\"\"\n",
    "        for layer in reversed(self.layers):\n",
    "            gradient = layer.backward(gradient)\n",
    "        return gradient\n",
    "    \n",
    "    def params(self) -> Iterable[Tensor]:\n",
    "        \"\"\"각 층별 파라미터를 반환\"\"\"\n",
    "        return (param for layer in self.layers for param in layer.params())\n",
    "    \n",
    "    def grads(self) -> Iterable[Tensor]:\n",
    "        \"\"\"각 층별 그래디언트를 반환\"\"\"\n",
    "        return (grad for layer in self.layers for grad in layer.grads())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18장에서 XOR 게이트를 위해 만들었던 신경망을 다음과 같이 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_net = Sequential([\n",
    "    Linear(input_dim=2, output_dim=2),\n",
    "    Sigmoid(),\n",
    "    Linear(input_dim=2, output_dim=1),\n",
    "    Sigmoid()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.5 손실 함수와 최적화\n",
    "지금까지는 손실함수(loss function)와 그래디언트 함수를 직접 명시하였다. 이번에는 다양한 손실 함수를 살펴볼 것이며, 손실 함수와 그래디언트 계산을 loss라는 클래스로 추상화할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def loss(self, predicted: Tensor, actual: Tensor) -> float:\n",
    "        \"\"\"예측값이 얼마나 정확한가? (손실값이 크면 클수록 좋지 않은 예측값이다.)\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def gradient(self, predicted: Tensor, actual: Tensor) -> Tensor:\n",
    "        \"\"\"예측값이 변하면 손실은 얼마나 변하는가?\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평균제곱오차를 손실 함수로 여러 번 사용했기에 금방 만들 수 있을 것이다. tensor_combine을 사용해야 하는 것만 기억하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSE(Loss):\n",
    "    \"\"\"평균제곱오차를 계산해 주는 손실 함수\"\"\"\n",
    "    def loss(self, predicted: Tensor, actual: Tensor) -> float:\n",
    "        # 각 예측값의 제곱오차를 계산한 후 텐서로 표현\n",
    "        squared_errors = tensor_combine(\n",
    "        lambda predicted, actual: (predicted - actual) ** 2,\n",
    "        predicted,\n",
    "        actual)\n",
    "        \n",
    "        # 모든 제곱오차를 더한다.\n",
    "        return tensor_sum(squared_errors)\n",
    "    \n",
    "    def gradient(self, predicted: Tensor, actual: Tensor) -> Tensor:\n",
    "        return tensor_combine(\n",
    "        lambda predicted, actual: 2 * (predicted - actual),\n",
    "        predicted, \n",
    "        actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사 하강법을 구현해 보자. 지금까지는 다음의 코드처럼 에폭마다 파라미터별로 경사 하강법을 수행하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def add(v: Vector, w: Vector) -> Vector:\n",
    "    \"\"\"각 성분끼리 더한다.\"\"\"\n",
    "    assert len(v) == len(w), \"vector must be the same length\"\n",
    "    \n",
    "    return [v_i + w_i for v_i, w_i in zip(v, w)]\n",
    "\n",
    "def scalar_multiply(c: float, v: Vector) -> Vector:\n",
    "    \"\"\"모든 성분을 c로 곱하기\"\"\"\n",
    "    return [c * v_i for v_i in v]\n",
    "\n",
    "def gradient_step(v: Vector, gradient: Vector, step_size: float) -> Vector:\n",
    "    \"\"\"v에서 step_size만큼 이동하기\"\"\"\n",
    "    assert len(v) == len(gradient)\n",
    "    step = scalar_multiply(step_size, gradient)\n",
    "    return add(v, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-736c5d8fd28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'theta' is not defined"
     ]
    }
   ],
   "source": [
    "theta = gradient_step(theta, grad, -learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 이제는 다른 방법으로 경사 하강법을 구현해야 한다. 이번 장에서 다루는 신경망들은 수많은 파라미터로 구성되어 있으며, 이를 모두 동시에 학습시켜야 하기 때문이다. 또한 더욱 효과적으로 변형시킨, 다양한 종류의 경사 하강법을 매번 구현해서 사용하기에는 너무 번거롭다.\n",
    "\n",
    "이러한 문제들을 해결하기 위해 Optimizer 클래스를 만들 것이다. 기존의 경사 하강법은 Optimizer 클래스의 인스턴스가 될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    \"\"\"\n",
    "    주어진 입력값이나 층에 대한 정보(혹은 둘 다)를 사용하여\n",
    "    해당 층의 파라미터를 업데이트\n",
    "    \"\"\"\n",
    "    def step(self, layer: Layer) -> None:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 tensor_combine을 사용하면 손쉽게 경사 하강법을 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(Optimizer):\n",
    "    def __init__(self, learning_rate: float = 0.1) -> None:\n",
    "        self.lr = learning_rate\n",
    "    def step(self, layer: Layer) -> None:\n",
    "        for param, grad in zip(layer.params(), layer.grads()):\n",
    "            # 그래디언트만큼 param을 업데이트\n",
    "            param[:] = tensor_combine(\n",
    "            lambda param, grad: param - grad * self.lr,\n",
    "            param,\n",
    "            grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드에서 리스트를 나눈 후 선언하는 부분이 신기할 수도 있다. 리스트를 재선언하면 리스트의 기존 값은 수정할 수 없게 된다. 만약 param = tensor_combine(...)으로 리스트를 재선언하면 param을 지역 변수(local vairable)로 선언할 수는 있지만 해당 층의 파라미터 텐서 안의 값은 수정할 수 없게 된다. 하지만 [:]을 사용하면 기존 리스트의 값을 수정할 수 있게 된다.\n",
    "\n",
    "아래는 간단한 예시이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = [[1,2], [3,4]]\n",
    "for row in tensor:\n",
    "    row = [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tensor == [[1,2], [3,4]], \"assignment doesn't update a list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tensor:\n",
    "    row[:] = [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tensor == [[0, 0], [0, 0]], \"but slice assignment does\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 추상화의 장점을 살려 **모맨텀(momentum)** 기반의 경사 하강법을 구현해 보자. 새롭게 계산된 그래디어튼 너무 예민하게 반응하는 것을 ㄹ방지하기 위해 지금까지 계산된 그래디언트의 평균값을 유지한다. 그리고 새 그래디언트 값이 계산될 때마다 평균값을 다시 계산하고 파라미터를 새 평균값만큼 이동시키면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum(Optimizer):\n",
    "    def __init__(self,\n",
    "                learning_rate: float,\n",
    "                 momentum: float = 0.9) -> None:\n",
    "        self.lr = learning_rate\n",
    "        self.mo = momentum\n",
    "        self.updates: List[Tensor] = []  # 이전 모든 그래디언트의 평균\n",
    "    \n",
    "    def step(self, layer: Layer) -> None:\n",
    "        # 파라미터 업데이트가 처음이라면 0부터 시작\n",
    "        if not self.updates:\n",
    "            self.updates = [zeros_like(grad) for grad in layer.grads()]\n",
    "            \n",
    "        for update, param, grad in zip(self.updates,\n",
    "                                      layer.params(),\n",
    "                                      layer.grads()):\n",
    "            \n",
    "            # 모맨텀 적용\n",
    "            update[:] = tensor_combine(\n",
    "            lambda u, g: self.mo * u + (1 - self.mo) * g,\n",
    "            update,\n",
    "            grad)\n",
    "            \n",
    "            # 모맨텀을 적용한 그래디언트만큼 파라미터 업데이트\n",
    "            param[:] = tensor_combine(\n",
    "            lambda p, u: p - self.lr * u,\n",
    "            param, \n",
    "            update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer를 추상화했기 때문에 이제 다양한 최적화 기법을 바꿔가며 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 19.6 예시: XOR 문제 다시 풀어보기\n",
    "위의 지금까지 만든 코드를 사용하면 XOR 문제를 풀어 주는 신경망을 얼마나 간편하게 학습시킬 수 있는지 살펴보자.\n",
    "\n",
    "먼저 학습 데이터를 다시 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터\n",
    "xs = [[0., 0], [0., 1], [1., 0], [1., 1]]\n",
    "ys = [[0.], [1.], [1.], [0.]]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 구조를 정의해 보자. 이제 마지막 시그모이드 층을 명시해 주지 않아도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "net = Sequential([\n",
    "    Linear(input_dim=2, output_dim=2),\n",
    "    Sigmoid(),\n",
    "    Linear(input_dim=3, output_dim=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추상화한 Optimizer와 Loss를 사용하면 간편하게 학습을 위해 반복문을 만들 수 있다. 다양한 종류의 최적화 방법과 손실 함수를 쉽게 적용해 볼 수 있게 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-a9b16c775534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bddecd98cfef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"\"\"순차적으로 각 층의 입력값을 전파\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-13694e0d54be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m입력층과\u001b[0m \u001b[0m출력값의\u001b[0m \u001b[0m타입의\u001b[0m \u001b[0m제한하지\u001b[0m \u001b[0m않을\u001b[0m \u001b[0m것이다\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "optimizer = GradientDescent(learning_rate=0.1)\n",
    "loss = SSE()\n",
    "\n",
    "with tqdm.trange(3000) as t:\n",
    "    for epoch in t:\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for x, y in zip(xs, ys):\n",
    "            predicted = net.forward(x)\n",
    "            epoch_loss += loss.loss(predicted, y)\n",
    "            gradient = loss.gradient(predicted, y)\n",
    "            net.backward(gradient)\n",
    "            \n",
    "            optimizer.step(net)\n",
    "            \n",
    "        t.set_description(f\"xor loss {epoch_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.7 다른 활성화 함수\n",
    "여러 가지 이유로 이제는 시그모이드 함수를 활성화 함수로 자주 사용하지 않는다.\n",
    "\n",
    "첫 번재 이유는 sigmoid(0)의 결괏값이 1/2이기 때문이다. 즉 뉴런에 입력되는 값의합이 0이어도 양수의 결괏값이 계산된다. 또한 매우 크거나 작은 입력값의 경우, 시그모이드의 그래디언트는 0에 수렴한다. 이런 경우, 그래디언트가 포화되었다고(saturated)하며 더는 파라미터를 업데이트할 수 없게 된다. \n",
    "\n",
    "시그모이드의 대안으로 tanh(쌍곡선 탄젠트, hyperbolic tangent)를 자주 사용한다. tanh는 -1부터 1사이의 시그모이드 형태의 함수이다. 만약 입력값이 0이라면 0을 반환해준다. 또한 tanh의 도함수는 1 - tanh(x) ** 2이기 때문에 간편하게 tanh 층을 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def tanh(x: float) -> float:\n",
    "    # x가 매우 크거나 작으면 tanh는 (결국) 1이나 -1을 반환.\n",
    "    # math.exp(1000)는 에러를 반환하기 때문에 x가 매우 크거나 작은 경우를 따로 확인해 줘야 한다.\n",
    "    if x < -100: return -1\n",
    "    elif x > 100: return 1\n",
    "    \n",
    "    em2x = math.exp(-2 * x)\n",
    "    return (1 - em2x) / (1 + em2x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Layer):\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        # 역방향에서 필요한 tanh의 결괏값을 저장\n",
    "        self.tanh = tensor_apply(tanh, input)\n",
    "        return self.tanh\n",
    "    \n",
    "    def backward(self, gradient: Tensor) -> Tensor:\n",
    "        return tensor_combine(\n",
    "        lambda tanh, grad: (1 - tanh ** 2) * grad,\n",
    "        gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "큰 모델의 경우, Relu 또한 자주 사용한다. Relu는 음수인 입력값에 대해서는 0을 반환하지만 양수인 입력값에 대해서는 입력값을 그대로 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Layer):\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        self.input = input\n",
    "        return tensor_combine(lambda x: max(x, 0), input)\n",
    "    \n",
    "    def backward(self, gradient: Tensor) -> Tensor:\n",
    "        return tensor_combine(lambda x, grad: grad if x > 0 else 0,\n",
    "                             self.input, \n",
    "                             gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이외에도 다양한 활성화 함수가 있다. 딥러닝 모델을 만들 때 이러한 대안들을 직접 사용해 보는 것 또한 추천한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.8 예시: Fizz Buzz 다시 풀어 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_encode(x: int) -> Vector:\n",
    "    binary: List[float] = []\n",
    "\n",
    "    for i in range(10):\n",
    "        binary.append(x % 2)\n",
    "        x = x // 2\n",
    "\n",
    "    return binary\n",
    "\n",
    "def fizz_buzz_encode(x: int) -> Vector:\n",
    "    if x % 15 == 0:\n",
    "        return [0, 0, 0, 1]\n",
    "    elif x % 5 == 0:\n",
    "        return [0, 0, 1, 0]\n",
    "    elif x % 3 == 0:\n",
    "        return [0, 1, 0, 0]\n",
    "    else:\n",
    "        return [1, 0, 0, 0]\n",
    "\n",
    "def argmax(xs: list) -> int:\n",
    "    \"\"\"Returns the index of the largest value\"\"\"\n",
    "    return max(range(len(xs)), key=lambda i: xs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [binary_encode(n) for n in range(101, 1024)]\n",
    "ys = [fizz_buzz_encode(n) for n in range(101, 1024)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 만들어 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN = 25\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "net = Sequential([\n",
    "    Linear(input_dim=10, output_dim=NUM_HIDDEN, init='uniform'),\n",
    "    Tanh(),\n",
    "    Linear(input_dim=NUM_HIDDEN, output_dim=4, init='uniform'),\n",
    "    Sigmoid()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 진행하면서 학습데이터 안의 정확도를 기록해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizzbuzz_accuracy(low: int, hi: int, net: Layer) -> float:\n",
    "    num_correct = 0\n",
    "    for n in range(low, hi):\n",
    "        x = binary_encode(n)\n",
    "        predicted = argmax(net.forward(x))\n",
    "        actual = argmax(fizz_buzz_encode(n))\n",
    "        if predicted == actual:\n",
    "            num_correct += 1\n",
    "            \n",
    "            \n",
    "        return num_correct / (hi - low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Momentum(learning_rate=0.1, momentum=0.9)\n",
    "loss = SSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-c0956016a887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bddecd98cfef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"\"\"순차적으로 각 층의 입력값을 전파\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-13694e0d54be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m입력층과\u001b[0m \u001b[0m출력값의\u001b[0m \u001b[0m타입의\u001b[0m \u001b[0m제한하지\u001b[0m \u001b[0m않을\u001b[0m \u001b[0m것이다\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tqdm.trange(1000) as t:\n",
    "    for epoch in t:\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for x, y in zip(xs, ys):\n",
    "            predicted = net.forward(x)\n",
    "            epoch_loss += loss.loss(predicted, y)\n",
    "            gradient = loss.gradient(predicted, y)\n",
    "            net.backward(gradient)\n",
    "            \n",
    "            optimizer.step(net)\n",
    "            \n",
    "        accuracy = fizzbuzz_accuracy(101, 1024, net)\n",
    "        t.set_description(f\"fb loss: {epoch_loss:.2f} acc : {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-ad07723377db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 테스트셋 안의 성능 검증\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test results'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfizzbuzz_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-5d23c91f5006>\u001b[0m in \u001b[0;36mfizzbuzz_accuracy\u001b[0;34m(low, hi, net)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfizz_buzz_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bddecd98cfef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"\"\"순차적으로 각 층의 입력값을 전파\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-13694e0d54be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m입력층과\u001b[0m \u001b[0m출력값의\u001b[0m \u001b[0m타입의\u001b[0m \u001b[0m제한하지\u001b[0m \u001b[0m않을\u001b[0m \u001b[0m것이다\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 테스트셋 안의 성능 검증\n",
    "print('test results', fizzbuzz_accuracy(1, 101, net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 1,000번 반복 후, 데스트셋에서 모델의 정확도는 90%가 되었다. 만약 학습을 더욱 오랫동안 수행한다면 정확도 또한 증가할 것이다. (25개 은닉 뉴런으로는 100%의 정확도를 달성하기 어렵다. 하지만 은닉 뉴런의 수가 50개 정도 되면 충분히 가능하다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.9 Softmax와 Cross-Entropy\n",
    "앞선 다룬 모델의 마지막 층은 시그모이드 층으로 구성되었다. 즉, 이 모델의 결괏값은 0과 1사이의 값으로 구성된 벡터이다. 모든 값이 0 혹은 1로 구성된 벡터가 산출될 수도 있다. 이 모델은 분류를 위한 모델이기 때문에 , 올바르게 분휴된 경우에는 1을, 틀리게 분류된 경우에는 0을 반환하는 것이 이상적일 것이다. 하지만 대부분의 경우 환벽한 결과 예측은 불가능할 것이다. 이런 경우 적어도 클래스 간 확률분포를 계산해 보는 것도 나쁘지 않다.\n",
    "\n",
    "예를 들어 두개의 클래스를 분류하는 경우에 모델의 결괏값이 [0, 0]이라면, 이것이 무엇을 나타내는지 이해하기 매우 힘들 것이다. 과연 결괏값이 어떠한 클래스에도 속하지 않는다는 것을 의미하는 걸까?\n",
    "\n",
    "만약 동일한 모델의 결괏값이 [0.4, 0.6]이라면 첫 번재 클래스에 속할 확률이 0.4 두 번째 클래스에 속할 확률이 0.6이라는 것으로 이해할 수 있다.\n",
    "\n",
    "이렇게 결괏값을 확률적으로 표현하려면 모델의 마지막 층을 시그모이드 층 대신 **소프트맥스(softmax)** 층으로 구성해야 한다. 소프트맥스 함수는 실수로 구성된 벡터를 확률로 구성된 벡터로 변환해 준다. 먼저, 벡터 안의모든 값의 exp(x)를 계산하여 양수로만 구성된 벡터로 변환한다. 그리고 각각의 값을 모든 값의 합으로 나눠준다. 그러면 모든 값의 총합이 1이 되는 확률값으로 구성된 벡터가 생성된다. \n",
    "\n",
    "파이썬에서 exp(1000)처럼 큰 값을 계산하게 되면 에러가 발생하기 때문에 모든 값에서 주어진 값 중 최대값을 뺀 후 exp()을 계산하자. 최종적으로 계산되는 확률값은 동일하며 파이썬에서도 문제없이 작동한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(tensor: Tensor) -> Tensor:\n",
    "    \"\"\"마지막 차원 안의 softmax\"\"\"\n",
    "    if is_1d(tensor):\n",
    "        # 에러를 피하기 위해 최대값을 빼 준다.\n",
    "        largest = max(tensor)\n",
    "        exps = [math.exp(x - largest) for x in tensor]\n",
    "        \n",
    "        sum_of_exps = sum(exps)  # 모든 값의 총합\n",
    "        return [exp_i / sum_of_exps  # 확률값은 개별의 값을\n",
    "                for exp_i in exps]   # 총합으로 나눈 값\n",
    "    \n",
    "    else:\n",
    "        return [softmax(tensor_i0) for tensor_i in tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 결괏값이 확률값인 경우, 대부분 **크로스 엔트로피(cross entropy)** 라는 손실 함수를 사용한다. (가끔은 네거티브 로그 가능도 라고도 부른다)\n",
    "\n",
    "앞서 14.3절 '최대 가능도 추정법'에서 (특정 가정하에) 최소자승법은 관측된 테이터가 발생할 간능도를 최대화하기 때문에 단순 회귀 분석에서 사용된다는 것을 기억해 보자.\n",
    "\n",
    "크로스 엔트로피 또한 비슷하게 이해할 수 있다. 만약 모델의 결괏값이 확률값이라면 크로스 엔트로피 손실 함수는 관측된 데이터의 네거티트 로그 간으도를 나타낸다. 즉, 손실 함수를 최소화하는 것은 학습 데이터의 로그 가능도(그리고 가능도를)최대화하는 것을 의미한다.\n",
    "\n",
    "소프트맥스 함수를 신경망의 일부가 아닌 손실 함수로 따로 구현하면 결괏값은 그래디언트를 쉽게 계산할 수 있게 된다. 신경망의 일부가 아닌 자제적인 손실 함수로 구현해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxCrossEntropy(Loss):\n",
    "    \"\"\"\n",
    "    주어진 딥러닝 모델에서\n",
    "    관측된 데이터의 네거티브 로그 가능도를 계산.\n",
    "    즉, 네거티브 로그 가능도를 최소화시키면 관측된 데이터의 가능도를 최대화하는 것과 동일\n",
    "    \"\"\"\n",
    "    def loss(self, predicted: Tensor, actual: Tensor) -> float:\n",
    "        # 소프트맥스로 확률값 생성\n",
    "        probabilities = softmax(predicted)\n",
    "        \n",
    "        # 올바른 클래스로 분류되는 경우 log p_i를, 아닌 경우 0을 반환\n",
    "        # log(0)을 피하기 위해서 p에 작은 작은 값을 더해 준다.\n",
    "        likelihoods = tensor_combine(lambda p, act: math.log(p + 1e-30) * act,\n",
    "                                    probabilities,\n",
    "                                    actual)\n",
    "        \n",
    "        # 모든 네거티브 가능도를 더한다.\n",
    "        return -tensor_sum(likelihoods)\n",
    "\n",
    "    def gradient(self, predicted: Tensor, actual: Tensor) -> Tensor:\n",
    "        probabilities = softmax(predicted)\n",
    "        \n",
    "        # 굉장히 간편하게 표현되지 않는가?\n",
    "        return tensor_combine(lambda p, actual: p - actual,\n",
    "                             probabilities,\n",
    "                             actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fizz Buzz 예시에서 만든 모델을 SoftmaxCrossEntropy에서 구현한 손실 함수로 학습하면 훨씬 빠르게(더 적은 에폭 내) 학습이 된다. 주어진 분포에서 소프트맥스로 파라미터를 찾는 게 시그모이드로 찾는 것보다 훨씬 쉽기 때문일 것이다.\n",
    "\n",
    "만약, 선형 층 + 시그모이드 층 모델로 0번째 클래스(벡터 내 첫 번째 값이 1이고 나머지는 0인 경우)를 예측하려면 벡터 내 첫 번재 값은 매우 큰 양수이고 나머지 값은 매우 작은 음수여야 가능하다. 하지만 소프트맥스로 예측하는 경우, 첫 번째 값이 나머지 값보다 크기만 하면 된다. 후자의 경우가 훨씬 더 빈번하게 발생하기 때문에 소프트맥스로 파라미터를 학습하는 것이 훨씬 쉽다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-0c092185f9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bddecd98cfef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"\"\"순차적으로 각 층의 입력값을 전파\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-13694e0d54be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m입력층과\u001b[0m \u001b[0m출력값의\u001b[0m \u001b[0m타입의\u001b[0m \u001b[0m제한하지\u001b[0m \u001b[0m않을\u001b[0m \u001b[0m것이다\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "net = Sequential([\n",
    "    Linear(input_dim=10, output_dim=NUM_HIDDEN, init='uniform'),\n",
    "    Tanh(),\n",
    "    Linear(input_dim=NUM_HIDDEN, output_dim=4, init='uniform')\n",
    "    # 마지막에 시그모이드 층을 추가하지 않는다.\n",
    "])\n",
    "\n",
    "optimizer = Momentum(learning_rate=0.1, momentum=0.9)\n",
    "loss = SoftmaxCrossEntropy()\n",
    "\n",
    "with tqdm.trange(100) as f:\n",
    "    for epoch in t:\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for x, y in zip(xs, ys):\n",
    "            predicted = net.forward(x)\n",
    "            epoch_loss += loss.loss(predicted, y)\n",
    "            gradient = loss.gradient(predicted, y)\n",
    "            net.backward(gradient)\n",
    "            \n",
    "            optimizer.step(net)\n",
    "        \n",
    "        accuracy = fizzbuzz_accuracy(101, 1024, net)\n",
    "        t.set_description(f\"fb loss: {epoch_loss:.3f} acc: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-c16d6f5dacde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 다시 테스트셋 안의 성능 검증\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test results\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfizzbuzz_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-5d23c91f5006>\u001b[0m in \u001b[0;36mfizzbuzz_accuracy\u001b[0;34m(low, hi, net)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfizz_buzz_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bddecd98cfef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"\"\"순차적으로 각 층의 입력값을 전파\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-13694e0d54be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m입력층과\u001b[0m \u001b[0m출력값의\u001b[0m \u001b[0m타입의\u001b[0m \u001b[0m제한하지\u001b[0m \u001b[0m않을\u001b[0m \u001b[0m것이다\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 다시 테스트셋 안의 성능 검증\n",
    "print(\"test results\", fizzbuzz_accuracy(1, 101, net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.10 드롭아웃\n",
    "대부분의 기계학습 모델처럼 딥러닝 도한 오버티핑에 취약하다. 이미 15.8절 \"Regularizaiton\"에서 값이 큰 파라미터에 대해 패널티를 주는 regularization으로 오버피팅을 해결하는 것을 살펴보았다.\n",
    "\n",
    "딥러닝에서 주로 **드롭아웃(dropout)** 으로 regularization을 수행한다. **학습 중 특정 확률로 임의의 뉴런을 '끄는 것'을 의미**한다.\n",
    "\n",
    "드롭아웃으로 모델이 특정 뉴런에 의존하는 것을 방지할 수 있으며 오버피팅 또한 해결할 수 있다.\n",
    "\n",
    "모델을 검증할 때는 드롭아우싱 필요 없다. 즉, 드롭아웃 층을 구현할 때는 현재 모델이 학습 중인지 아닌지 알고 있어야 한다. 만약 모델을 학습 중이라면 특정 확률값으로 선택된 임의의 입력값만 반환해 주면 된다. 그리고 모델 검증 시, 드롭아웃의 영향을 반영해 주기 위해 (모든) 출력값을 드롭아웃에 사용한 확률값 만큼 줄여줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(Layer):\n",
    "    def __init__(self, p: float) -> None:\n",
    "        self.p = p\n",
    "        self.train = True\n",
    "        \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        if self.train:\n",
    "            # 주어진 확률값을 사용하여\n",
    "            # 입력값과 동일한 크기이며 0 혹은 1로 구성된 mask를 생성\n",
    "            self.mask = tensor_apply(\n",
    "            lambda _: 0 if random.random() < self.p else 1,\n",
    "            input)\n",
    "            \n",
    "            # 입력값과 mask를 곱한다.\n",
    "            return tensor_combine(operator.mul, input, self.mask)\n",
    "        else:\n",
    "            # 검증 시, 확률값만큼 출력값을 축소\n",
    "            return tensor_apply(lambda x: x * (1 - self.p), input)\n",
    "        \n",
    "    def backward(self, gradient: Tensor) -> Tensor:\n",
    "        if self.train:\n",
    "            # mask의 값이 1인 경우에만 그래디언트를 전파\n",
    "            return tensor_combine(operator.mul, gradient, self.mask)\n",
    "        else:\n",
    "            raise RuntimeError(\"don't call backward when not in train mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞으로 드롭아웃을 사용하여 딥러닝 모델의 오버피팅 문제를 해결할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.11 예시: MNIST\n",
    "MNIST는 손으로 쓴 숫자들로 구성된 데이터셋이며 딥러닝을 처음 배우는 모든 이가 사용하는 예시이다.\n",
    "\n",
    "처리하기 까다로운 바이너리(binary) 형태로 데이터셋이 제공되기 때문에, mnist 라이브러리를 사용할 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mnist\n",
      "  Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: numpy in /home/minsungkim/anaconda3/lib/python3.7/site-packages (from mnist) (1.19.1)\n",
      "Installing collected packages: mnist\n",
      "Successfully installed mnist-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "\n",
    "# 데이터를 지정한 경로에 내려받아 준다.\n",
    "# (인자가 없도록 저의된 라이브러리의 함수이다.)\n",
    "# (절대 이렇게 하지 않을 것이라고 했지만 람다 함수에 변수를 정의할 것이다.)\n",
    "mnist.temporary_dir = lambda: '/tmp'\n",
    "\n",
    "# 각 함수에서 데이터를 내려받고 numpy 행렬로 반환\n",
    "# .tolist()를 사용해서 리스트로 변환\n",
    "train_images = mnist.train_images().tolist()\n",
    "train_labels = mnist.train_labels().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert shape(train_images) == [60000, 28, 28]\n",
    "assert shape(train_labels) == [60000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 100개의 학습 데이터가 어떻게 생겼는지 한번 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(10, 10)\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        # 각 이미지를 흑백으로 그려보고 각 축은 숨겨 주자.\n",
    "        ax[i][j].imshow(train_images[10 * i + j], cmap='Greys')\n",
    "        ax[i][j].xaxis.set_visible(False)\n",
    "        ax[i][j].yaxis.set_visible(False)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그림은 손으로 쓰여진 숫자인 것을 알 수 있다.\n",
    "\n",
    "평가 데이터도 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = mnist.test_images().tolist()\n",
    "test_labels = mnist.test_labels().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert shape(test_images) == [10000, 28, 28]\n",
    "assert shape(test_labels) == [10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 이미지는 28 x 28 픽셀로 구성되어 있다. 하지만 우리가 구현한 선형 층에서는 1차원 입력값만 처리할 수 있기 때문에 이미지를 1차원으로 납작하게(flatten)만들어 줄 것이다. (그리고 각 픽셀은 256으로 나눠 픽셀값을 0과 1사이로 변환해 주자) 추가적으로 입력값의 평균이 0인 경우 학습이 더 수월하기 때문에 각 픽셀값에서 평균 픽셀값을 빼주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 픽셀값 계산\n",
    "avg = tensor_sum(train_images) / 60000 / 28 / 28\n",
    "\n",
    "# 평균 픽셀값을 빼 주고, 정규화하고, 납작하게 만들어 주자.\n",
    "train_images = [[(pixel - avg) / 256 for row in image for pixel in row]\n",
    "               for image in train_images]\n",
    "\n",
    "test_images = [[(pixel - avg) / 256 for row in image for pixel in row]\n",
    "              for image in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert shape(train_images) == [60000, 784], \"images should be flattened\"\n",
    "assert shape(test_images) == [10000, 784], \"images shoud be flattened\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 픽셀값을 배 주면 평균 픽셀값은 0에 가까울 것이다.\n",
    "assert -0.0001 < tensor_sum(train_images) < 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10개의 출력값을 one-hot-encoding 방식으로 표현하자. 먼저 one-hot-encode 함수를 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(i: int, num_labels: int = 10) -> List[float]:\n",
    "    return [1.0 if j == i else 0.0 for j in range(num_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert one_hot_encode(3) == [0,0,0,1,0,0,0,0,0,0]\n",
    "assert one_hot_encode(2, num_labels=5) == [0,0,1,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [one_hot_encode(label) for label in train_labels]\n",
    "test_labels = [one_hot_encode(label) for label in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert shape(train_labels) == [60000, 10]\n",
    "assert shape(test_labels) == [10000, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추상화의 큰 장점 중 하나는 동일한 학습 및 검증 반복문으로 여러 모델을 학습할 수 있다는 점이다. 이런 반복문을 먼저 만들어 보고 모델, 데이터, 손실 함수 그리고 최적화 방식을 전달해 주자.\n",
    "\n",
    "반복하면서 모델의 성능을 추적하며(최적화 방식이 주어졌다면) 파라미터를 업데이트할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def loop(model: Layer,\n",
    "        images: List[Tensor],\n",
    "        labels: List[Tensor],\n",
    "        loss: Loss,\n",
    "        optimizer: Optimizer = None) -> None:\n",
    "    correct = 0  # 올바르게 예측된 결괏값에 개수를 추적\n",
    "    total_loss = 0.0  # 총 손실값을 추적\n",
    "    \n",
    "    with tqdm.trange(len(images)) as t:\n",
    "        for i in t:\n",
    "            predicted = model.forward(images[i])  # 예측\n",
    "            if argmax(predicted) == argmax(labels[i]):  # 그리고\n",
    "                correct += 1  # 결괏값 확인\n",
    "            total_loss += loss.loss(predicted, labels[i])  # 손실값 계산\n",
    "            # 모델이 학습 중이라면 그래디언트를 역전파하고 파라미터를 업데이트\n",
    "            \n",
    "            if optimizer is not None:\n",
    "                gradient = loss.gradient(predicted, labels[i])\n",
    "                model.backward(gradient)\n",
    "                optimizer.step(model)\n",
    "                \n",
    "            # 그리고 출력되는 프로그래스바(progress bar)를 업데이트\n",
    "            avg_loss = total_loss / (i + 1)\n",
    "            acc = correct / (i + 1)\n",
    "            t.set_description(f\"mnist loss: {avg_loss:.3f} acc: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비교를 위해 우리가 구현한 딥러닝 모듈로(다계층) 로지스틱 회귀 모델을 학습해보자. 로지스틱 회귀 모델은 하나의 선형 층 이후 소프트맥스를 추가해 주면 된다. 즉, 이 모델은 10개 선형 함수로 구성되어 있다고 생각하면 된다. 만약 5를 나타내는 손글씨가 입력값으로 들어온다면 5번째 선형 모델의 출력값이 가장 클 것이다.\n",
    "\n",
    "60,000개의 이미지로 구성된 학습 데이터를 한 번만 반복 하면 모델을 충분히 학습시킬 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-db2b3799f1b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 학습 데이터로 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 평가 데이터로 검증(최적화 방식을 명시하지 않으면 검증을 의미)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-a8df407b114c>\u001b[0m in \u001b[0;36mloop\u001b[0;34m(model, images, labels, loss, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 그리고\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# 결괏값 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-13694e0d54be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m입력층과\u001b[0m \u001b[0m출력값의\u001b[0m \u001b[0m타입의\u001b[0m \u001b[0m제한하지\u001b[0m \u001b[0m않을\u001b[0m \u001b[0m것이다\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "# 로지스틱 회귀 모델은 선형 층 이후 소프트맥스를 추가한 것과 동일\n",
    "model = Linear(784, 10)\n",
    "loss = SoftmaxCrossEntropy()\n",
    "\n",
    "# 이 최적화 방식을 사용해도 결과가 잘 나오는 것 같다.\n",
    "optimizer = Momentum(learning_rate=0.01, momentum=0.99)\n",
    "\n",
    "# 학습 데이터로 학습\n",
    "loop(model, train_images, train_labels, loss, optimizer)\n",
    "\n",
    "# 평가 데이터로 검증(최적화 방식을 명시하지 않으면 검증을 의미)\n",
    "loop(model, test_images, test_labels, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대략 89% 정도의 정확도가 계산된다. 딥러닝 모델로 정확도를 높일 수 있는지 살펴보자. 두 개의 은닉층으로 구성된 딥러닝 모델을 만들어 보자. \n",
    "\n",
    "첫 번째 은닉층은 30개, 두 번째 은닉층은 10개의 뉴런으로 구성해 보자. 그리고 Tanh 활성화 함수를 사용할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "# 켜고 끌 수 있도록 이름을 주자.\n",
    "dropout1 = Dropout(0.1)\n",
    "dropout2 = Dropout(0.1)\n",
    "\n",
    "model = Sequential([\n",
    "    Linear(784, 30),  # 첫 번째 은닉층의 크기: 30\n",
    "    dropout1,\n",
    "    Tanh(),\n",
    "    Linear(30, 10),  # 두 번째 은닉층의 크기: 10\n",
    "    dropout2,\n",
    "    Tanh(),\n",
    "    Linear(10, 10)  # 출력층의 크기: 10\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 사용한 학습용 반복문을 그대로 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-3372545a3993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 드랍아웃을 적용하고 학습(노트북에서 20분 이상 걸릴 것이다!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdropout1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 드롭아웃을 제외하고 검증\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-a8df407b114c>\u001b[0m in \u001b[0;36mloop\u001b[0;34m(model, images, labels, loss, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 그리고\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# 결괏값 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bddecd98cfef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"\"\"순차적으로 각 층의 입력값을 전파\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-13694e0d54be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m입력층과\u001b[0m \u001b[0m출력값의\u001b[0m \u001b[0m타입의\u001b[0m \u001b[0m제한하지\u001b[0m \u001b[0m않을\u001b[0m \u001b[0m것이다\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = Momentum(learning_rate=0.01, momentum=0.99)\n",
    "loss = SoftmaxCrossEntropy()\n",
    "\n",
    "# 드랍아웃을 적용하고 학습(노트북에서 20분 이상 걸릴 것이다!)\n",
    "dropout1.train = dropout2.train = True\n",
    "loop(model, train_images, train_labels, loss, optimizer)\n",
    "\n",
    "# 드롭아웃을 제외하고 검증\n",
    "dropout1.train = dropout2.train = False\n",
    "loop(model, test_images, test_labels, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델로 평가 데이터에서 92%의 정확도를 달성할 수 있다. 간단한 로지스틱 회귀 모델보다 확실히 향상되었다.\n",
    "\n",
    "MNIST공식 웹사이트에서 92%보다 더 좋은 성능을 보이는 모델에 대한 설명을 확인할 수 있다. 대부분의 모델은 지금까지 우리가 구현한 코드로 만들 수 있지만 굉장히 오래 걸릴 것이다. **최고의 성능을 보이는 모델은 주로 콘볼루션(convolutional)층을 사용**한다. **매우 중요한 개념**이지만 여기서는 다루지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.12 모델 저장 및 불러오기\n",
    "딥러닝 모델을 학습하기 위해 굉장히 긴 시간이 필요하기 때문에 매번 모델을 학습하지 않고 학습된 모델을 저장할 수 있는 방법이 필요하다. json 모듈로 모델의 파라미터를 파일로 저장할 수 있다.\n",
    "\n",
    "Layer.params로 모델의 모든 파라미터를 불러오고, 리스트로 변환한 뒤 json.dump로 리스트를 파일에 저장하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_weights(model: Layer, filename: str) -> None:\n",
    "    weights = list(model.params())\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(weights, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터를 불러오는 것도 복잡하지 않다. 리스트 슬라이싱으로 모델의 파라미터를 설정할 수 있다.\n",
    "\n",
    "(즉, 모델 자체의 인스턴스를 생성하고 파라미터를 불러와야 한다. 대안으로 모델의 구조를 저장하고 이를 불러오면서 모델의 인스턴스를 생성할 수도 있다. 나쁘지 않은 방법이지만 지금까지 구현한 코드를 많이 수정해야 하니 여기서는 다루지 않겠다.)\n",
    "\n",
    "먼저 불러오는 파라미터의 크기가 모델 안의 파라미터의 크기와 동일한지 확인해야 한다.(가령 저장된 딥러닝 모델 파라미터를 얕은 신경망 모델에 불러오는 상황을 방지할 수 있다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model: Layer, filename: str) -> None:\n",
    "    with open(filename) as f:\n",
    "        weights = json.load(f)\n",
    "        \n",
    "    #크기 비교\n",
    "    assert all(shape(param) == shape(weight)\n",
    "              for param, weight in zip(model.params(), weights))\n",
    "    \n",
    "    # 리스트를 나누는 방식으로 파라미터를 불러온다.\n",
    "    for param, weight in zip(model.params(), weights):\n",
    "        param[:] = weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON은 문자열로 데이터를 저장하기 때문에 매우 비효율적이다. **실제로는 pickle 라이브러리를 사용**하여 데이터를 자장할 것이다.\n",
    "\n",
    "pickle은 바이너리 형태로 데이터를 저장하기 때문에 훨씬 효율적이다. 이 책에서는 사람이 읽을 수 있는 간단한 형태로 데이터를 저장하기 위해 JSON을 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
