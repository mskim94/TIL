{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어 처리\n",
    "자연어 처리(natural language processing, NLP)는 **언어에 대한 계산적 기술을 의미**한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.1 워드 클라우드\n",
    "단어와 그 개수를 시각화하는 한 가지 방법은 단어의 크기를 단어의 개수에 비례하도록 보여주는 워드 클라우드이다.\n",
    "\n",
    "일반적으로 데이터 과학자들은 워드 클라우드를 선호하지 않는데, '이 곳에 단어를 끼워 넣을 공간이 있네' 정도 말고는 단어의 위치가 어떠한 의미도 가지지 않기 때문이다.\n",
    "\n",
    "어쩌다가 워드 클라우드를 만들 상황이 온다면 각 축에 어떻게 의미를 부여할 수 있을지 고민해 보자. e.g. 데이터 과학과 연관된 각 유행어에 0-100 사이의 숫자 두 개가 주어졌다고 해보자. 첫 번째 숫자는 채용공고에 등장한 유행어의 빈도를, 두 번째는 이력서에 등장한 빈도를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ (\"big data\", 100, 15), (\"Hadoop\", 95, 25), (\"Python\", 75, 50),\n",
    "         (\"R\", 50, 40), (\"machine learning\", 80, 20), (\"statistics\", 20, 60),\n",
    "         (\"data science\", 60, 70), (\"analytics\", 90, 3),\n",
    "         (\"team player\", 85, 85), (\"dynamic\", 2, 90), (\"synergies\", 70, 0),\n",
    "         (\"actionable insights\", 40, 30), (\"think out of the box\", 45, 10),\n",
    "         (\"self-starter\", 30, 50), (\"customer focus\", 65, 15),\n",
    "         (\"thought leadership\", 35, 35)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "채용공고에 등장하는 빈도를 가로축으로, 이력서에 등장하는 빈도를 세로축으로 설정한다면, 조금 더 많은 정보를 제공할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def text_size(total: int) -> float:\n",
    "    \"\"\"total이 0이면 8, total이 200이면 28을 반환\"\"\"\n",
    "    return 8 + total / 200 * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for word, job_popularity, resume_popularity in data:\n",
    "    plt.text(job_popularity, resume_popularity, word,\n",
    "            ha='center', va='center',\n",
    "            size=text_size(job_popularity + resume_popularity))\n",
    "\n",
    "plt.xlabel(\"Popularity on Job Postings\")\n",
    "plt.ylabel(\"Popularity on Resumes\")\n",
    "plt.axis([0, 100, 0, 100])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 위의 그림이 단순히 plot, x, y 축 위에 표현되지 않고 그저 빈도수가 높은 순으로 글자의 크기만 크게 그림으로 표현된다면 딱히 어떤 정보를 제공하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.2 n-그램 언어모델\n",
    "누군가 데이터 과학에 관한 수천 개의 웹페이지를 만들어 검색 엔진의 순위를 높이고 싶어한다. 프로그래밍으로 웹사이트를 대량으로 만들어 낼 방법이 없는지 궁금해하고 있다. 어떻게든 언어 모델을 만들 방법을 찾아야 한다.\n",
    "\n",
    "한 가지 방법은 문서가 여러 개 있는 말뭉치(corpus, 코퍼스)를 구해서 언어에 대한 통계적 모델을 만드는 것이다. 여기서는 마이크 루키디스(Mike Loukides)의 에세이 What Is Data Science?를 사용해 보자.\n",
    "\n",
    "9장 '파이썬으로 데이터 수집하기'에서와 같이 requests와 BeautifulSoup 라이브러리를 사용해서 데이터를 수집하자. 이때 신경 쓰면 좋을 몇가지 이슈가 있다.\n",
    "\n",
    "첫째, 텍스트 안의 따옴표가 유니코드 문자 u\\\"u2019\"이다. 이를 일반 아스키 따옴표로 바꾸는 함수를 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_unicode(text: str) -> str:\n",
    "    return text.replace(u\"\\u2019\", \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마침표를 기준으로 웹페이지 안의 텍스트에서 문장들을 봅아보자(마침표는 문장이 어디서 끝나는지를 알게 해주는 신호다.) 이것은 re.findall을 이용하면 간단하게 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-f4e755086c43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://www.oreilly.com/ideas/what-is-data-science\"\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "content = soup.find(\"div\", \"article-body\")  # article-body div를 찾아라.\n",
    "regex = r\"[\\w']+|[\\.]\"  # 단어 또는 마침표를 찾아라.\n",
    "\n",
    "document = []\n",
    "\n",
    "for paragraph in content(\"p\"):\n",
    "    words = re.findall(regex, fix_unicode(paragraph.text))\n",
    "    document.extend(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트를 단어의 열로 만들었으니, 이제 다음과 같은 방법으로 언어를 모델링 할 수 있다. 먼저, 시작 단어를 하나 준다. 여기서는 이 단어를 'book'이라고 해보자. 그리고 문서들을 주욱 훑으면서 'book'이라는 단어 다음에 등장하는 단어들이 무엇인지 확인한다. 이 중 하나를 임의로 선택해서 다음 단어가 되게 하고, 문장 끝을 나타내는 마침표가 등장할 때까지 이 과정을 계속 반복한다. 주어진 문서의 바이그램(bigram, 2-gram) 빈도를 사용하기 때문에, 우리는 이러한 방식을 바이그램 모델(bigram model)이라고 부른다.\n",
    "\n",
    "시작 단어는 어떻게 고를까? 마침표 다음에 등장하는 단어들 중에서 임의로 하나를 선택하는 방법이 있다. 각 단어 뒤에 어떤 단어가 따라오는지 계산해보자. zip은 입력된 리스트 중 하나라도 처리가 끝나면 종료되기 때문에, zip(document, document[1:]을 사용하면 document에서 연속해서 나온 단어들을 딱 맞게 보여줄 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "transitions = defaultdict(list)\n",
    "for prev, current in zip(document, document[1:]):\n",
    "    transitions[prev].append(current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 문장을 생성할 준비가 되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_using_bigrams() -> str:\n",
    "    current = \".\"  # 마침표의 다음 단어가 문장을 새로 시작할 것이다.\n",
    "    result = []\n",
    "    while True:\n",
    "        next_word_candidates = transitions[current]  # (current, _) 바이그램\n",
    "        current = random.choice(next_word_candidates)  # 하나를 랜덤으로 골라라.\n",
    "        result.append(current)  # results에 추가하라.\n",
    "        if current == \".\": return \" \".join(result)  # \".\"가 나오면 종료해라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 생성된 문장은 전혀 말이 되지 않지만, 웹사이트에서 데이터 과학의 느낌은 풍기기는 할 것이다. \n",
    "\n",
    "세 개의 연속된 단어를 보는 **트라이그램(trigram)** 을 사용하면 문장을 조금 더 그럴듯하게 만들 수 있다.(일반적으로는, n개의 연속된 단어를 고려하는 n-그램을 보겠지만, 여기서는 3개만 봐도 충분할 것이다.) 이제 다음 단어는 직전 두 개의 단어에 따라 바뀐다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_transitions = defaultdict(list)\n",
    "starts = []\n",
    "\n",
    "for prev, current, next in zip(document, document[1:], document[2:]):\n",
    "    if prev == \".\":  # 직전 단어가 마침표하면\n",
    "        starts.append(current)  # current는 시작 단어가 될 수 있다.\n",
    "        \n",
    "    trigram_transitions[(prev, current)].append(next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 시작 단어를 따로 관리해야 한다. 문장 생성 자체는 비슷한 방식으로 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_using_trigram() -> str:\n",
    "    current = random.choice(starts)  # 임의의 시작 단어를 정한 후\n",
    "    prev = \".\"  # 마침표를 앞에 덧붙인다.\n",
    "    result = [current]\n",
    "    while True:\n",
    "        next_word_candidates = trigram_transitions[(prev, current)]\n",
    "        next_word = random.choice(next_word_candidates)\n",
    "        \n",
    "        prev, current = current, next_word\n",
    "        result.append(current)\n",
    "        \n",
    "        if current == \".\":\n",
    "            return \" \".join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트라이그램을 사용하면 좀 더 그럴듯한 문자들이 생성된다.\n",
    "\n",
    "트라이그램에서 더 그럴듯한 문장들이 생성되는 이유는 다음 단어를 생성하는 각 단계에서 선택할 수 있는 단어의 수가 바이그램을 사용할 때보다 훨씬 적어지고, 많은 경우 딱 하나의 단어만 선택할 수밖에 없기 때문이다. 원문에 있었던 문장(또는 긴 문구)을 그대로 생성할 가능성도 높다. 데이터 과학 관련 에세이 여러 개 모아서 더 많은 데이터로 n-그램을 계산하면 성능이 더욱 좋아질 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.3 문법 규칙\n",
    "문뻐에 맞는 문장을 생성할 수 있도록 **문법 규칙**을 사용해서 언어를 모델링할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "# 문법 규칙을 나타내는 타입 별칭\n",
    "Grammar = Dict[str, List[str]]\n",
    "\n",
    "grammar = {\n",
    "    \"_S\"  : [\"_NP _VP\"],\n",
    "    \"_NP\" : [\"_N\",\n",
    "             \"_A _NP _P _A _N\"],\n",
    "    \"_VP\" : [\"_V\",\n",
    "             \"_V _NP\"],\n",
    "    \"_N\"  : [\"data science\", \"Python\", \"regression\"],\n",
    "    \"_A\"  : [\"big\", \"linear\", \"logistic\"],\n",
    "    \"_P\"  : [\"about\", \"near\"],\n",
    "    \"_V\"  : [\"learns\", \"trains\", \"tests\", \"is\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 항목 앞에 밑줄이 있으면 더 확장할 수 있는 규칙(rule), 나머지를 **종결어(terminal)** 라고 하자.\n",
    "\n",
    "e.g. \"_S\"는 문장 규칙을 의미하며 \"_NP\"라는 명사구 규칙과 \"_VP\"라는 동사구 규칙을 생성한다.\n",
    "\n",
    "동사규 규칙은 \"_V\"라는 동사 규칙을 생성하거나, 동사와 명사구로 이어지는 규칙을 생성할 수 있다.\n",
    "\n",
    "\"_NP\" 규칙의 경우 자기 자신을 다시 생성할 수 있다는 것에 주목해보자.\n",
    "\n",
    "\n",
    "문법 규칙은 재귀적(recursive)일 수 있기 때문에, 이와 같은 유한 문법(infinite grammars)이라도 무한히 많은 문장을 생성할 수 있다. 이 문법 규칙으로부터 문장을 어떻게 생성할까? 일단 문장 규칙 [\"_S\"]로부터 시작한다고 했을 때, 이를 대체할 수 있는 항목 중에서 임의로 한 가지를 선택하고, 모든 항목이 종결어일 때까지 이 과정을 반복한다.\n",
    "\n",
    "예를 들어 아래와 같은 과정으로 문장이 생성될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['_S']\n",
    "\n",
    "['_NP', '_VP']\n",
    "\n",
    "['_N', '_VP']\n",
    "\n",
    "['Python', '_VP']\n",
    "\n",
    "['Python', '_V', '_NP']\n",
    "\n",
    "['Python', 'trains', '_NP']\n",
    "\n",
    "['Python', 'trains', '_A', '_NP', '_P', '_A', '_N']\n",
    "\n",
    "['Python', 'trains', 'logistic', '_NP', '_P', '_A', '_N']\n",
    "\n",
    "['Python', 'trains', 'logistic', '_N', '_P', '_A', '_N']\n",
    "\n",
    "['Python', 'trains', 'logistic', 'data science', '_P', '_A', '_N']\n",
    "\n",
    "['Python', 'trains', 'logistic', 'data science', 'about', '_A', '_N']\n",
    "\n",
    "['Python', 'trains', 'logistic', 'data science', 'about', 'logistic', '_N']\n",
    "\n",
    "['Python', 'trains', 'logistic', 'data science', 'about', 'logistic', 'Python']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것을 실제 코드로 구현하기 위해 종결어를 인식할 수 있는 함수를 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal(token: str) -> bool:\n",
    "    return token[0] != \"_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 토큰 목록이 주어졌을 때 이를 문장으로 변환하는 함수를 만들자. 이 함수에서는 가장 먼저 등장하는 규칙 항목이 무엇인지를 찾는다. 규칙 항목을 찾을 수 없다면 모든 항목이 종결어로 구성되어 있다는 것을 의미하므로 함수를 종료하면 되고, 규칙 항목을 찾는다면 그것을 대체할 수 있는 여러 항목 중 하나를 임의로 선택한다. 이때 선택된 항목이 종결어, 즉 단어라면 기존 항목을 단순히 대체하기만 하면 된다. 하편 선택된 항목이 종결어가 아니라면, 공백으로 구분된 비종료 토큰들을 split한 후 현재 토큰의 목록에 삽입해야 한다. 어떤 경우든, 새로 얻게 된 코큰의 목록에 대해 동일한 과정을 반복한다.\n",
    "\n",
    "위 과정을 종합하면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(grammar: Grammar, tokens: List[str]) -> List[str]:\n",
    "    for i, token in enumerate(tokens):\n",
    "        # 종결어인 경우, 넘어가라.\n",
    "        if is_terminal(token): continue\n",
    "            \n",
    "        # 종결어가 아닌 경우\n",
    "        # 대체할 토큰을 임의로 정하라.\n",
    "        replacement = random.choice(grammar[token])\n",
    "        \n",
    "        if is_terminal(replacement):\n",
    "            tokens[i] = replacement\n",
    "        else:\n",
    "            # 대체된 구가 예를 들어 \"_NP _VP\"라면\n",
    "            # 공백을 기준으로 나누고 slice해서 넣어라.\n",
    "            tokens = tokens[:i] + replacement.split() + tokens[(i+1):]\n",
    "            \n",
    "        # 새로운 토큰 목록에 expand를 적용해라.\n",
    "        return expand(grammar, tokens)\n",
    "    \n",
    "    # 여기까지 왔다면 리스트는 종결어만으로 구성되어 있고 프로세스는 종료된다.\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 문장을 생성해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(grammar: Grammar) -> List[str]:\n",
    "    return expand(grammar, [\"_S\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 문법 규칙은 역으로 이용하는 게 더 흥미롭다. 즉, 주어진 문장을 문법 기준으로 **파싱(parsing)** 해서 명사와 동사 등을 인식한다면 문장을 더 잘 이해할 수 있다.\n",
    "\n",
    "데이터 과학으로 문서를 생성하는 것도 꽤 멋지지만, 문서를 이해할 수 있는 것은 더욱 근사한 일이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.4 여담: 깁스 샘플링\n",
    "몇몇 확률분포는 쉽게 표본(sample)을 생성할 수 있다. e.g. 균등분포의 확률변수(uniform random variable)는 다음과 같이 얻을 수 있고\n",
    "\n",
    "random.random()\n",
    "\n",
    "정규분포의 확률변수(normal random variables)는 다음과 같이 얻을 수 있다.\n",
    "\n",
    "inverse_normal_cdf(random.random())\n",
    "\n",
    "하지만 다른 일반적인 확률분포로부터 테이터를 샘플링하는 것은 간단하지 않다. 이런 경우 **깁스 샘플링(Gibbs sampling)** 은 다차원 분포 안, 몇 개의 조건부 분포(conditional distribution)를 알고 있다는 가정하에 표본을 생성할 수 있게 해준다.\n",
    "\n",
    "두 개의 주사위를 상상해보자. x가 첫 번째 주사위의 눈이고 y는 주사위 두 개의 눈의 합일 때, (x, y)쌍을 여러 개 생성하려고 한다면 표본을 다음과 같이 직접 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import random\n",
    "\n",
    "def roll_a_die() -> int:\n",
    "    return random.choice([1,2,3,4,5,6])\n",
    "\n",
    "def direct_sample() -> Tuple[int, int]:\n",
    "    d1 = roll_a_die()\n",
    "    d2 = roll_a_die()\n",
    "    return d1, d1 + d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 조건부 확률만 안다고 가정해 보자. x가 주어졌을 때 y의 조건부 확률을 구하는 것도 쉽다. x값을 안다면 y가 x+1, x+2, x+3, x+4, x+5 또는 x+6일 확률은 전부 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_y_given_x(x: int) -> int:\n",
    "    \"\"\"x + 1, x + 2, ... , x + 6일 확률은 전부 동일하다.\"\"\"\n",
    "    return x + roll_a_die()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 반대의 경우는 조금 더 복잡하다. e.g. yrㅏ 2라는 것을 안다면 x는 반드시 1이다(두 주사위 눈의 합이 2가 되는 방법은 두 주사위의 눈이 모두 1일 때 뿐이다). y가 3이라면 x는 동일한 확률로 1 또는 2이다. 같은 방법으로 y가 11이라면 x는 5 또는 6이어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_x_given_y(y: int) -> int:\n",
    "    if y <= 7:\n",
    "        # 총합이 7 이하라면 첫 번째 주사위의 눈은 같은 확률로\n",
    "        # (총합 - 6), (총합 - 5), ..., 6이다.\n",
    "        return random.randrange(y - 6, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "깁스 샘플링은 일단 (유효한) x, y 값으로 시작해서, y에 대한 조건부 확률로 x를 생성하고, x에 대한 조건부 확률로 y를 생성하는 방식으로 동작한다. 이렇게 여러 번 반복하면 x, y는 결합확률분포를 따르는 표본이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sample(num_iters: int  = 100) -> Tuple[int, int]:\n",
    "    x, y = 1, 2  # 초깃값은 별로 상관없다.\n",
    "    for _ in range(num_iters):\n",
    "        x = random_x_given_y(y)\n",
    "        y = random_y_given_x(x)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 값들을 원래 분포에서 직접 샘플링한 것과 비교해 보면 유사한 결과가 나오는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions(num_samples: int = 1000) -> Dict[int, List[int]]:\n",
    "    counts = defaultdict(lambda: [0, 0])\n",
    "    for _ in range(num_samples):\n",
    "        counts[gibbs_sample()][0] += 1\n",
    "        counts[direct_sample()][1] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.5 토픽 모델링\n",
    "사용자들의 관심사를 이해할 수 있는 더 정교한 방법은 관심사의 기반이 되는 주제, 또는 토픽(topic)을 파악하는 것이다. **LDA(Latent Dirichlet Allocation)** 라고 불리는 방법은 문서들의 꾸러미인 말뭉치에서 공통된 토픽을 뽑아내는 데 사용된다. 여기서는 '사용자들의 관심사' 말뭉치에 LDA를 적용해 보자.\n",
    "\n",
    "LDA는 말뭉치에 대한 확률모델을 만든다는 점에서 13장. 나이브 베이즈에서 살펴본 나이브 베이즈 분류기와 공통점이 있다. 모델은 아래의 가정들을 가진다.\n",
    "\n",
    "- 토픽의 수는 K개로 고정되어 있다.\n",
    "- 각 토픽과 단어의 확률분포를 연관 짓는 확률변수가 있다. 특정 토픽 k가 주어졌을 때 단어 w를 볼 확률이라고 생각하면 된다.\n",
    "- 각 문서와 토픽의 확률분포를 연관 짓는 확률변수도 있다. 특정 토픽 d가 주어졌을 때 토픽 k를 볼 확률이라고 생각하면 된다.\n",
    "- 문서 안의 각 단어는 문서의 토픽 분포로부터 먼저 임의의 토픽이 선택된 뒤, 토픽의 단어 분포로부터 생성되었다고 가정한다.\n",
    "\n",
    "먼저, 문서의 집합 documents가 있고, 각 문서는 단어의 목록으로 구성되어 있다고 하자. 그리고 document_topics는 각 문서의 각 단어에 0부터 K-1 사이의 숫자로 된 토픽들을 할당한다.\n",
    "\n",
    "이에 따르면 4번째 문서의 5번째 단어는 다음고 같으며\n",
    "\n",
    "documents[3][4]\n",
    "\n",
    "그 단어를 생성한 토픽은 다음과 같다.\n",
    "\n",
    "document_topics[3][4]\n",
    "\n",
    "이는 각 문서의 토픽 분포를 명시적으로 나타냄과 동시에, 각 토픽의 단어 분포를 암시적으로 나타내 준다.\n",
    "\n",
    "토픽 1이 특정 단어를 생성하는 횟수와 임의의 단어를 생성하는 횟수를 비교하면, 토픽 1이 특정 단어를 생성할 가능도를 계산할 수 있다. (13장. 나이브 베이즈 에서 스팸 필터를 만들 때도 각 단어가 스팸 메일에 등장하는 횟수와 스팸 메일에 등장하는 전체 단어의 수를 비교했다.)\n",
    "\n",
    "여기서 토픽을 단순히 숫자로 표기했지만, 각 토픽에서 큰 영향을 끼치는 단어들을 보고 각 토픽에 의미 있는 이름을 부여할 수도 있다. 이제 어떻게든 document_topics를 생성하기만 하면 되는데, 이런 경우 깁스 샘플링이 유용하게 쓰인다.\n",
    "\n",
    "먼저 모든 문서의 모든 단어에 임의의 토픽을 부여하는 것으로 시작한다. 그리고 각 문서의 단어를 하나씩 살펴보면, 현재의 문서-토픽 분포와 토픽-단어 분포에 따라 각 토픽에 가중치를 할당한다. 그 다음 그 가줓이를 사용해서 해당 단어에 알맞은 새로운 토픽을 할당한다. 이 과정을 여러 번 반복하면 문서-토픽 분포와 토픽-단어 분포의 결합확률분포로부터 나오는 표본을 얻게 된다.\n",
    "\n",
    "이를 구현하기 위해 일단 주어진 가중치의 집합에서 임의의 인덱스를 뽑는 함수가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from(weights: List[float]) -> int:\n",
    "    \"\"\"i를 weights[i] / sum(weights)의 확률로 반환\"\"\"\n",
    "    total = sum(weights)\n",
    "    rnd = total * random.random()  # 0과 total 사이에서 균일하게 선택\n",
    "    for i, w in enumerate(weights):\n",
    "        rnd -= w  # 아래의 식을 만족하는 가장 작은 i를 반환\n",
    "        if rnd <= 0: return i  # weights[0] + ... + weights[i] >= rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. 가중치가 [1,1,3]이라면 1/5의 확률로 0, 1/5의 확률로 1, 3/5의 확률로 2를 반환하게 된다.\n",
    "\n",
    "아래의 코드는 테스트 케이스이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 1000번 뽑아서 수를 세라. \n",
    "draws = Counter(sample_from([0.1, 0.1, 0.8]) for _ in range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 10 < draws[0] < 190  # 대충 만든 테스트이기 때문에 대략 ~10% 일 것이다.\n",
    "assert 10 < draws[1] < 190  # 대충 만든 테스트이기 때문에 대략 ~10% 일 것이다.\n",
    "assert 650 < draws[2] < 950  # 대충 만든 테스트이기 때문에 대략 ~80% 일 것이다.\n",
    "\n",
    "assert draws[0] + draws[1] + draws[2] == 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이\n",
    "\n",
    "K = 4\n",
    "\n",
    "개의 토픽을 찾으려고 해보자. 샘플링 가중치를 계산하기 위해서 몇 가지 숫자를 계산해야 한다. 숫자를 실제로 세기 이전에 숫자를 담을 자료 구조를 만들어 보자.\n",
    "- 각 토픽이 각 문서에 할당되는 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "# 각 문서에 대한 Counter를 리스트로 나타낸다.\n",
    "document_topic_counts = [Counter() for _ in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 단어가 각 토픽에 할당되는 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 토픽에 해당되는 Counter를 리스트로 나타낸다.\n",
    "topic_word_counts = [Counter() for _ in range(K)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 토픽에 할당된 총 단어 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 토픽에 대한 숫자를 리스트로 나타낸다.\n",
    "topic_counts = [0 for _ in range(K)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 문서에 포함된 총 단어 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문서에 대한 숫자를 리스트로 나타낸다.\n",
    "document_lengths = [len(document) for document in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 총 단어의 종류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_words = set(word for document in documents for word in document)\n",
    "W = len(distinct_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 총 문서의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이들을 계산하고 나면, e.g. documents[3] 문서 중에서 토픽 1과 관련 있는 단어의 수를 구할 수 있게 된다.\n",
    "\n",
    "document_topic_counts[3][1]\n",
    "\n",
    "'nlp'라는 단어가 토픽 2와 연관 지어서 나오는 횟수는 다음과 같다.\n",
    "\n",
    "topic_word_counts[2][\"nlp\"]\n",
    "\n",
    "이제 조건부 확률분포들을 정의할 준비가 다 되었다. 13장 나이브 베이즈오 마찬가지로, 각 토픽이 모든 문서에 대해 0 이상 확률을 가질 수 있도록 스무딩(smoothing)도 할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_topic_given_document(topic: int, d: int, alpha: float = 0.1) -> float:\n",
    "    \"\"\"\n",
    "    문서 d의 모든 단어 중에서 topic에 속하는\n",
    "    단어의 비율 (+ smoothing)\n",
    "    \"\"\"\n",
    "    return ((document_topic_counts[d][topic] + alpha) /\n",
    "           (document_lengths[d] + K * alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_word_given_topic(word: str, topic: int, beta: float = 0.1) -> float:\n",
    "    \"\"\"\n",
    "    topic에 속한 단어 중에서\n",
    "    word의 비율 (+ smoothing)\n",
    "    \"\"\"\n",
    "    return ((topic_word_counts[topic][word] + beta) /\n",
    "           (topic_counts[topic] + W * beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 이 함수들은 토픽을 업데이트하기 위한 가중치 생성에 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_weight(d: int, word: str, k: int) -> float:\n",
    "    \"\"\"\n",
    "    문서와 문서의 단어가 주어진 경우\n",
    "    k번째 토픽의 가중치를 반환\n",
    "    \"\"\"\n",
    "    return p_word_given_topic(word, k) * p_topic_given_document(k, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_new_topic(d: int, word: str) -> int:\n",
    "    return sample_from([topic_weight(d, word, k)\n",
    "                       for k in range(K)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic_weight가 위와 같은 현태를 띄는 데는 분명한 수학적인 이유가 있지만, 너무 복잡해 넘어간다. \n",
    "\n",
    "단, 토픽의 가능도는 문서와 단어가 모두 주어졌을 때, 문서-토픽 분포와 토픽-단어 분포의 영향을 받는다는 것을 기억해두자.\n",
    "\n",
    "이제 각 단어를 임의의 토픽에 배정하고 필요한 값들을 뽑아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "document_topics = [[random.randrange(K) for word in document]\n",
    "                  for document in documents]\n",
    "\n",
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] += 1\n",
    "        topic_word_counts[topic][word] += 1\n",
    "        topic_counts[topic] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "목표는 문서-토픽, 토픽-단어의 결합확률분포로부터 표본을 얻는 것이므로, 조건부 확률분포를 이용해서 앞서 살펴본 깁스 샘플링을 실행하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2733.04it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "for iter in tqdm.trange(1000):\n",
    "    for d in range(D):\n",
    "        for i, (word, topic) in enumerate(zip(documents[d],\n",
    "                                             document_topics[d])):\n",
    "            \n",
    "            # 가중치에 영향을 주지 않도록\n",
    "            # word와 topic을 count에서 제거한다.\n",
    "            document_topic_counts[d][topic] -= 1\n",
    "            topic_word_counts[topic][word] -= 1\n",
    "            topic_counts[topic] -= 1\n",
    "            document_lengths[d] -= 1\n",
    "            \n",
    "            # 가중치를 기준으로 새 토픽을 고른다.\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "            \n",
    "            # count에 다시 추가한다.\n",
    "            document_topic_counts[d][new_topic] += 1\n",
    "            topic_word_counts[new_topic][word] += 1\n",
    "            topic_counts[new_topic] += 1\n",
    "            document_lengths[d] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 토픽은 어떤 의미를 가지는가? 아직까지는 그저 0, 1, 2, 3이라는 숫자에 불과한데, 이름을 붙이고 싶으면 직접 해야 한다. 이를 위해 각 토픽에서 가장 빈도가 높은 단어가 무엇인지 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Java 3\n",
      "0 Big Data 3\n",
      "0 Hadoop 2\n",
      "0 HBase 1\n",
      "0 C++ 1\n",
      "0 Spark 1\n",
      "0 Storm 1\n",
      "0 programming languages 1\n",
      "0 MapReduce 1\n",
      "0 Cassandra 1\n",
      "0 deep learning 1\n",
      "1 HBase 2\n",
      "1 neural networks 2\n",
      "1 Postgres 2\n",
      "1 MongoDB 2\n",
      "1 machine learning 2\n",
      "1 Cassandra 1\n",
      "1 numpy 1\n",
      "1 decision trees 1\n",
      "1 deep learning 1\n",
      "1 databases 1\n",
      "1 MySQL 1\n",
      "1 NoSQL 1\n",
      "1 artificial intelligence 1\n",
      "1 scipy 1\n",
      "2 regression 3\n",
      "2 Python 2\n",
      "2 R 2\n",
      "2 libsvm 2\n",
      "2 scikit-learn 2\n",
      "2 mathematics 1\n",
      "2 support vector machines 1\n",
      "2 Haskell 1\n",
      "2 Mahout 1\n",
      "3 statistics 3\n",
      "3 probability 3\n",
      "3 Python 2\n",
      "3 R 2\n",
      "3 pandas 2\n",
      "3 statsmodels 2\n",
      "3 C++ 1\n",
      "3 artificial intelligence 1\n",
      "3 theory 1\n"
     ]
    }
   ],
   "source": [
    "for k, word_counts in enumerate(topic_word_counts):\n",
    "    for word, count in word_counts.most_common():\n",
    "        if count > 0:\n",
    "            print(k, word, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 기반으로 각 토픽의 이름을 다음과 같이 정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = [\"Big Data and programming languages\",\n",
    "              \"Python and statictics\",\n",
    "              \"databases\",\n",
    "              \"machine learning\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 다음과 같은 방식으로 각 사용자의 관심사가 무엇인지 알아볼 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hadoop', 'Big Data', 'HBase', 'Java', 'Spark', 'Storm', 'Cassandra']\n",
      "Big Data and programming languages 7\n",
      "\n",
      "['NoSQL', 'MongoDB', 'Cassandra', 'HBase', 'Postgres']\n",
      "Python and statictics 5\n",
      "\n",
      "['Python', 'scikit-learn', 'scipy', 'numpy', 'statsmodels', 'pandas']\n",
      "Python and statictics 2\n",
      "databases 2\n",
      "machine learning 2\n",
      "\n",
      "['R', 'Python', 'statistics', 'regression', 'probability']\n",
      "machine learning 3\n",
      "databases 2\n",
      "\n",
      "['machine learning', 'regression', 'decision trees', 'libsvm']\n",
      "databases 2\n",
      "Python and statictics 2\n",
      "\n",
      "['Python', 'R', 'Java', 'C++', 'Haskell', 'programming languages']\n",
      "databases 3\n",
      "Big Data and programming languages 3\n",
      "\n",
      "['statistics', 'probability', 'mathematics', 'theory']\n",
      "machine learning 3\n",
      "databases 1\n",
      "\n",
      "['machine learning', 'scikit-learn', 'Mahout', 'neural networks']\n",
      "databases 2\n",
      "Python and statictics 2\n",
      "\n",
      "['neural networks', 'deep learning', 'Big Data', 'artificial intelligence']\n",
      "Python and statictics 3\n",
      "Big Data and programming languages 1\n",
      "\n",
      "['Hadoop', 'Java', 'MapReduce', 'Big Data']\n",
      "Big Data and programming languages 4\n",
      "\n",
      "['statistics', 'R', 'statsmodels']\n",
      "machine learning 3\n",
      "\n",
      "['C++', 'deep learning', 'artificial intelligence', 'probability']\n",
      "machine learning 3\n",
      "Big Data and programming languages 1\n",
      "\n",
      "['pandas', 'R', 'Python']\n",
      "machine learning 3\n",
      "\n",
      "['databases', 'HBase', 'Postgres', 'MySQL', 'MongoDB']\n",
      "Python and statictics 5\n",
      "\n",
      "['libsvm', 'regression', 'support vector machines']\n",
      "databases 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document, topic_counts in zip(documents, document_topic_counts):\n",
    "    print(document)\n",
    "    for topic, count in topic_counts.most_common():\n",
    "        if count > 0:\n",
    "            print(topic_names[topic], count)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토픽의 이름에 'and'를 사용했다는 것은 토픽의 수를 늘려야 한다는 것을 의미한다. 하지만 어차피 제대로 학습하기엔 데이터가 부족하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.6 단어 벡터\n",
    "최근 많은 자연어 처리 기법들은 딥러닝을 사용하여 발전하고 있다. 어번 장의 남은 부분은 19장. 딥러닝에서 구현한 코드를 사용해서 몇 가지 최신 자연어 처리 기법을 살펴볼 것이다.\n",
    "\n",
    "그중 단어를 저차원의 벡터로 표현하는 기법은 굉장히 중요하다. 단어 벡터간 비교를 하거나 더하는 것이 가능해지며, 기계학습 모델의 입력값으로 사용하는 등 다양하게 활용할 수 있다. 그리고 비슷한 단어를 비슷한 벡터로 표현한다는 유용한 성질을 지니고 있다. e.g. 'big'의 단어 벡터와 'large'의 단어 벡터는 인접할 것이다. 즉, 단어 벡터를 사용하는 모델에서는 (어느 정도) 동의어를 저절로 처리할 수 있다는 것을 의미한다.\n",
    "\n",
    "많은 경우, 단어 벡터는 신기한 산술적 성질도 지니고 있다. e.g. 'king'이라는 단어 벡터에서 'man'의 단어 벡터를 빼주고 'woman'의 단어 벡터를 더하면 'queen'의 단어 벡터와 굉장히 비슷한 벡터를 얻을 수 있다. 비록 여기서는 다루지 않겠지만 단어 벡터가 정확히 무엇을 학습하는지 고민해 보는 것도 의미가 있을 것이다.\n",
    "\n",
    "수많은 단어를 벡터로 직접 표현하는 것은 어려운 일이기 때문에 보통 말뭉치를 사용하여 단어 벡터를 학습한다. 여러 학습 방법이 존재하지만, 대부분의 경우 다음과 같은 과정으로 요약할 수 있다.\n",
    "\n",
    "1. 많은 양의 문서를 모은다.\n",
    "2. 한 단어 주변의 단어들로 가운데의 단어를 예측하는 것을 목적으로 하는 데이터셋을 생성한다.(반대로, 가운데 단어로 주변의 단어들을 예측할 수도 있다.)\n",
    "3. 이런 목적을 잘 수행할 수 있는 신경망을 학습시킨다.\n",
    "4. 학습된 신경망의 내부를 단어 벡터로 사용한다.\n",
    "\n",
    "한 단어 주변의 단어들을 기준으로 중간 단어를 예측을 하기 때문에, 문맥이 비슷한 단어끼리는 신경망 상태값과 생성되는 단어 벡터가 유사할 것이다.\n",
    "\n",
    "여기서는 **코사인 유사도(cosine similiarity)** 로 벡터 간 '유사도'를 측정해 보자.\n",
    "\n",
    "코사인 유사도는 -1부터 1사이의 값이며, 두 벡터가 얼마나 비슷한 방향을 가리키는지를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List\n",
    "\n",
    "Vector = List[float]\n",
    "\n",
    "def dot(v: Vector, w: Vector) -> float:\n",
    "    \"\"\"v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    assert len(v) == len(w),  \"vectors must be same length\"\n",
    "    \n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1: Vector, v2: Vector) -> float:\n",
    "    return dot(v1, v2) / math.sqrt(dot(v1, v2) * dot(v2, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "same direction",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-dad8c6a9c040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"same direction\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"opposite direction\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"orthogonal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: same direction"
     ]
    }
   ],
   "source": [
    "assert cosine_similarity([1., 1, 1], [2., 2, 2]) == 1, \"same direction\"\n",
    "assert cosine_similarity([-1., -1], [2., 2]) == -1, \"opposite direction\"\n",
    "assert cosine_similarity([1., 0], [0., 1]) == 0, \"orthogonal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코사인 유사도가 어떻게 동작하는지 보기 위해 먼저 단어 벡터를 학습시켜 보자.\n",
    "\n",
    "보통 단어 벡터는 수백만 개 혹은 수십억 개의 단어에서 학습되어 생성되지만 여기서는 작은 연습용 데이터셋을 사용할 것이다. 우리가 작성할 연습용 코드에서는 그 정도로 많은 데이터를 처리할 수 없기 때문에, 어느 정도 정해진 구조가 있는 연습용 데이터셋을 만드는게 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"green\", \"blue\", \"yellow\", \"black\", \"\"]\n",
    "nouns = [\"bed\", \"car\", \"boat\", \"cat\"]\n",
    "verbs = [\"is\", \"was\", \"seems\"]\n",
    "adverbs = [\"very\", \"quite\", \"extremely\", \"\"]\n",
    "adjectives = [\"slow\", \"fast\", \"soft\", \"hard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentence() -> str:\n",
    "    return \" \".join([\n",
    "        \"The\",\n",
    "        random.choice(colors),\n",
    "        random.choice(nouns),\n",
    "        random.choice(verbs),\n",
    "        random.choice(adverbs),\n",
    "        random.choice(adjectives),\n",
    "        \".\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SENTENCES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "sentences = [make_sentence() for _ in range(NUM_SENTENCES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The yellow cat is extremely hard .',\n",
       " 'The yellow boat was extremely fast .',\n",
       " 'The black car was quite slow .',\n",
       " 'The black boat seems quite soft .',\n",
       " 'The red bed seems extremely hard .',\n",
       " 'The black bed was  soft .',\n",
       " 'The black car seems  hard .',\n",
       " 'The black boat is very slow .',\n",
       " 'The  cat seems very hard .',\n",
       " 'The blue car seems extremely slow .',\n",
       " 'The green car is quite hard .',\n",
       " 'The red bed was  slow .',\n",
       " 'The blue boat seems very soft .',\n",
       " 'The black car seems extremely hard .',\n",
       " 'The red cat was quite soft .',\n",
       " 'The green car is very soft .',\n",
       " 'The yellow bed is quite fast .',\n",
       " 'The red bed seems  soft .',\n",
       " 'The black car is  soft .',\n",
       " 'The yellow cat seems extremely slow .',\n",
       " 'The blue bed was extremely fast .',\n",
       " 'The green bed seems extremely slow .',\n",
       " 'The  car was quite soft .',\n",
       " 'The yellow bed is quite fast .',\n",
       " 'The red bed is very fast .',\n",
       " 'The black bed was very soft .',\n",
       " 'The red bed seems very fast .',\n",
       " 'The green bed was quite slow .',\n",
       " 'The  bed seems  slow .',\n",
       " 'The blue bed is very soft .',\n",
       " 'The blue cat is very hard .',\n",
       " 'The red bed seems  fast .',\n",
       " 'The blue boat seems  fast .',\n",
       " 'The  car is quite fast .',\n",
       " 'The blue boat is  fast .',\n",
       " 'The red cat seems  soft .',\n",
       " 'The  boat was extremely fast .',\n",
       " 'The black bed was very soft .',\n",
       " 'The  bed seems extremely fast .',\n",
       " 'The green cat was extremely soft .',\n",
       " 'The black car seems extremely hard .',\n",
       " 'The  cat seems very slow .',\n",
       " 'The black car seems extremely fast .',\n",
       " 'The green car seems  hard .',\n",
       " 'The  cat is  hard .',\n",
       " 'The  bed is  slow .',\n",
       " 'The blue car was  slow .',\n",
       " 'The red cat was extremely hard .',\n",
       " 'The red cat is very fast .',\n",
       " 'The red cat seems  soft .']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 벡터가 잘 생성된다면 색을 의미하는 단어들은 유사한 단어 벡터들로 표현될 것이다.\n",
    "\n",
    "앞서 언급한 바와 같이 우리는 각 단어를 ID로 변환, 즉 one-hot-encoding 방식으로 표현하고 싶을 것이다. 이런 표현 방식을 저장하기 위해 Vocabulary 클래스를 새로 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = list\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, words: List[str] = None) -> None:\n",
    "        self.w2i: Dict[str, int] = {}  # word -> word_id 맵\n",
    "        self.i2w: Dict[int, str] = {}  # word_id -> word 맵\n",
    "        for word in (words or []):\n",
    "            self.add(word)\n",
    "        \n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        \"\"\"사전에 단어가 몇 개 있는가\"\"\"\n",
    "        return len(self.w2i)\n",
    "    \n",
    "    def add(self, word: str) -> None:\n",
    "        if word not in self.w2i:    # 처음 본 단어라면\n",
    "            word_id = len(self.w2i) # 다음 id를 찾아서\n",
    "            self.w2i[word] = word_id  # word -> word_id 맵에 추가하고\n",
    "            self.i2w[word_id] = word  # word_id -> word 맵에도 추가하자.\n",
    "    \n",
    "    def get_id(self, word: str) -> int:\n",
    "        \"\"\"word가 주어졌을 때 id(또는 None)를 반환\"\"\"\n",
    "        return self.w2i.get(word)\n",
    "    \n",
    "    def get_word(self, word_id: int) -> str:\n",
    "        \"\"\"id가 주어졌을 때 word(또는 None)를 반환\"\"\"\n",
    "        return self.i2w.get(word_id)\n",
    "    \n",
    "    def one_hot_encode(self, word: str) -> Tensor:\n",
    "        word_id = self.get_id(word)\n",
    "        assert word_id is not None, f\"unknown word {word}\"\n",
    "        return [1.0 if i == word_id else 0.0 for i in range(self.size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞의 작업들을 일일이 수작업으로 할 수도 있지만, 클래스에서 처리하면 편할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary([\"a\", \"b\", \"c\"])\n",
    "assert vocab.size == 3,              \"there are 3 words in the vocab\"\n",
    "assert vocab.get_id(\"b\") == 1,       \"b should have word_id 1\"\n",
    "assert vocab.one_hot_encode(\"b\") == [0, 1, 0]\n",
    "assert vocab.get_id(\"z\") is None,    \"z is not in the vocab\"\n",
    "assert vocab.get_word(2) == \"c\",     \"word_id 2 should be c\"\n",
    "vocab.add(\"z\")\n",
    "assert vocab.size == 4,              \"now there are 4 words in the vocab\"\n",
    "assert vocab.get_id(\"z\") == 3,       \"now z should have id 3\"\n",
    "assert vocab.one_hot_encode(\"z\") == [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델에서 했던 것과 같이, 사전을 저장하고 불러오는 함수를 작성하면 좋을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_vocab(vocab: Vocabulary, filename: str) -> None:\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(vocab.w2i, f)  # w2i만 저장하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(filename: str) -> Vocabulary:\n",
    "    vocab = Vocabulary()\n",
    "    with open(filename) as f:\n",
    "        # w2i를 불러와서 i2w를 생성\n",
    "        vocab.w2i = json.load(f)\n",
    "        vocab.i2w = {id: word for word, id in vocab.w2i.items()}\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 단어를 입력받았을 때 주변 단어에 대한 확률을 반환하는 **스킵그램(skip-gram)** 이라는 단어 벡터 모델을 사용해 보자. 단어와 주변부 단어의 쌍을 입력해서 SoftCrossEntropy 손실 함수를 최소화하면 된다.\n",
    "\n",
    "CBOW(Continuous Bag-Of-Words)라는 또 다른 언어 모델은 주변 단어를 입력 받아 원래의 단어를 예측한다.\n",
    "\n",
    "이제 신경망을 설계해 보자. 일단 **임베딩(embedding)** 층에서는 입력 받은 단어 ID를 단어 벡터로 반환해야 하는데, 실제 구현에서는 간단한 룩업 테이블(lookup table)을 사용하면 된다.\n",
    "\n",
    "다음으로는 단어 벡터를 사전에 있는 단어 수만큼의 output을 갖는 **선형(Linear)** 층에 입력하고, 이전과 동일하게 소프트맥스(softmax)를 이용해서 주변 단어에 대한 확률로 변환한다. 경사 하강법을 사용해서 모델을 학습하다 보면 룩업 테이블에 있는 벡터들이 업데이트되고, 학습이 끝나면 이 룩업 테이블에 있는 값들이 곧 단어 벡터가 된다.\n",
    "\n",
    "임베딩 층을 만들어 보자. 실전에서는 단어 외의 다른 것들도 임베딩하고 싶을 수 있으므로, 조금 더 일반화된 Enbedding 클래스로 구현해 보자.(그리고 나서 단어 벡터를 생성하기 위한 TextEmbedding라는 서브클래스를 만들 것이다.)\n",
    "\n",
    "임베딩을 생성할 수 있도록 생성자에는 임베딩 벡터의 수와 차원 수가 명시될 것이고, 벡터의 초깃값으로 정규분포를 따르는 임의의 숫자가 채울 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from typing import Iterable, Tuple\n",
    "Tensor = list\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    딥러닝 신경망은 Layer들로 구성되어 있다.\n",
    "    각 Layer별로 순방향으로 입력값에 어떤 계산을 하고\n",
    "    역방향으로 그래디언트를 전파해야 한다.\n",
    "    \"\"\"\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        타입이 명시되어 있지 않은 것을 유의하자.\n",
    "        입력층과 출력값의 타입의 제한하지 않을 것이다.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "            \n",
    "    def backward(self, gradient):\n",
    "        \"\"\"\n",
    "        역방향에서도 그래디언트의 타입을 제한하지 않을 것이다.\n",
    "        메서드를 호출할 때 유의하자.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def params(self) -> Iterable[Tensor]:\n",
    "        \"\"\"\n",
    "        해당 층의 파라미터를 반환\n",
    "        기본적으로 아무것도 반환하지 않을 것이다.\n",
    "        만약 특정 층에서 반환할 파라미터가 없다면 구현할 필요가 없다.\n",
    "        \"\"\"\n",
    "        return ()\n",
    "    \n",
    "    def grads(self) -> Iterable[Tensor]:\n",
    "        \"\"\"\n",
    "        params()처럼 그래디언트를 반환\n",
    "        \"\"\"\n",
    "        return ()\n",
    "    \n",
    "def random_tensor(*dims: int, init: str = 'normal') -> Tensor:\n",
    "    if init == 'normal':\n",
    "        return random_normal(*dims)\n",
    "    elif init == 'uniform':\n",
    "        return random_uniform(*dims)\n",
    "    elif init == 'xavier':\n",
    "        variance = len(dims) / sum(dims)\n",
    "        return random_normal(*dims, variance=variance)\n",
    "    else:\n",
    "        raise ValueError(f\"unkown init: {init}\")\n",
    "        \n",
    "def zeros_like(tensor: Tensor) -> Tensor:\n",
    "    return tensor_apply(lambda _: 0.0, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(Layer):\n",
    "    def __init__(self, num_embeddings: int, embedding_dim: int) -> None:\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # 임베딩을 하려는 embedding_dim 차원의 벡터 한 개\n",
    "        self.embeddings = random_tensor(num_embeddings, embedding_dim)\n",
    "        self.grad = zeros_like(self.embeddings)\n",
    "        \n",
    "        # 마지막 input id를 저장\n",
    "        self.last_input_id = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델에서는 단어를 하나씩만 임베딩한다. 앞서 언급한 CBOW 모델과 같은 경우, 단어의 열을 입력 받아 단어 벡터의 열을 반환하기도 하기 때문에, 단어 ID의 열을 입력 받도록 설계할 수 있다. 하지만 여기서는 문제를 간단히 풀기 위해 한 번에 단어 한 개씩 임베딩하도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, input_id: int) -> Tensor:\n",
    "    \"\"\"input_id에 해당되는 임베딩 벡터를 선택한다.\"\"\"\n",
    "    self.input_id = input_id  # 역전파에서 사용할 수 있게 값을 저장\n",
    "    return self.embeddings[input_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역방향 계산의 경우, 해당 임베딩 벡터의 그래디언트만 계산할 것이다. 즉, 해당 벡터 외에는 모두 0인 self.embeddings의 그래디언트을 계산할 수 있어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, gradient: Tensor) -> None:\n",
    "    # 직전 input의 그래디언트를 비우자.\n",
    "    # 이게 매번 새로운 0 텐서를 생성하는 것보다 효율적이다.\n",
    "    if self.last_input_id is not None:\n",
    "        zero_row = [0 for _ in range(self.embedding_dim)]\n",
    "        self.grad[self.last_input_id] = zero_row\n",
    "        \n",
    "    self.last_input_id = self.input_id\n",
    "    self.grad[self.input_id] = gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 params와 grads 메서드를 오버라이딩해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params(self) -> Iterable[Tensor]:\n",
    "    return [self.embeddings]\n",
    "\n",
    "def grads(self) -> Iterable[Tensor]:\n",
    "    return [self.grad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 벡터를 생성하기 위한 전용 서브클래스를 만들 것이다. 이 경우, 임베딩 벡터의 개수는 사전의 크기에 따라 달라지므로, 아예 vocab을 입력으로 받자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbedding(Embedding):\n",
    "    def __init__(self, vocab: Vocabulary, embedding_dim: int) -> None:\n",
    "        # superclass의 생성자 호출\n",
    "        super().__init__(vocab.size, embedding_dim)\n",
    "        \n",
    "        # 사전은 유지\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __getitem__(self, word: str) -> Tensor:\n",
    "        word_id = self.vocab.get_id(word)\n",
    "        if word_id is not None:\n",
    "            return self.embeddings[word_id]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 제공되는 메서드들을 그대로 사용하기보다는 텍스트 처리를 위한 몇 가지 메서드를 추가하는 것이 편할 것이다. e.g. 특정 단어에 대한 벡터를 반환받고 싶은 경우가 있을 수 있다. (이것은 Layer 인터페이스의 일부가 아니지만, 언제든 특정 층에 메서드를 추가할 수 있다.)\n",
    "\n",
    "이 dunder 메서드는 인덱싱 없이도 단어 벡터를 검색할 수 있게 해준다.\n",
    "\n",
    "word_vector = embedding[\"black\"]\n",
    "\n",
    "또 임베딩 층을 이용해, 주어진 단어와 가장 가까운 단어가 뭔지 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(self, word: str, n: int = 5) -> List[Tuple[float, str]]:\n",
    "    \"\"\"코사인 유사도를 기반으로 가장 가까운 n개의 단어를 반환한다.\"\"\"\n",
    "    vector = self[word]\n",
    "    \n",
    "    # (유사도, other_word) 쌍을 계산하고 가장 유사한 순으로 정렬\n",
    "    scores = [(cosine_similarity(vector, self.embeddings[i]), other_word)\n",
    "              for other_word, i in self.vocab.w2i.items()]\n",
    "    scores.sort(reverse=True)\n",
    "    \n",
    "    return scores[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩 층에서는 벡터를 반환하기만 한다. 이 벡터를 Linear 층에 입력할 수도 있다.\n",
    "\n",
    "학습 데이터를 준비하자. 각 입력 단어별로 해당 단어의 왼쪽에 있는 단어 2개와 오른쪽에 있는 단어 2개를 출려되는 단어로 선택할 것이다. \n",
    "\n",
    "먼저 문장들을 소문자로 변환하고 단어로 나눠주는 함수로 시작해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 훌륭한 regex는 아니지만 이 데이터서는 적당히 동작한다.\n",
    "tonkenized_sentences = [re.findall(\"[a-z]+|[.]\", sentence.lower())\n",
    "                       for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전을 구축하고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트에 기반한 사전 구축(word -> word_id)\n",
    "vocab = Vocabulary(word for sentence_words in tonkenized_sentences\n",
    "                  for word in sentence_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터를 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = list\n",
    "\n",
    "def one_hot_encode(i: int, num_labels: int = 10) -> List[float]:\n",
    "    return [1.0 if j == i else 0.0 for j in range(num_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs: List[int] = []\n",
    "targets: List[Tensor] = []\n",
    "\n",
    "for sentence in tonkenized_sentences:\n",
    "    for i, word in enumerate(sentence):  # 각 단어에 대해\n",
    "        for j in [i - 2, i - 1, i + 1, i + 2]:  # 주변 단어들을 선택\n",
    "            if 0 <= j < len(sentence):  # 문장 안의 단어인지 확인\n",
    "                nearby_word = sentence[j]  # 주변 단어를 가져온다.\n",
    "                \n",
    "                # 입력 단어의 word_id를 추가한다.\n",
    "                inputs.append(vocab.get_id(word))\n",
    "                \n",
    "                # one-hot-encoding된 출력 단어를 추가한다.\n",
    "                targets.append(vocab.one_hot_encode(nearby_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델은 아주 손쉽게 만들 수 있다.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19장 딥러닝에서 만들 class 호출\n",
    "import random\n",
    "from typing import List\n",
    "from typing import Callable\n",
    "\n",
    "def random_normal(*dims: int, \n",
    "                 mean: float = 0.0,\n",
    "                 variance: float = 1.0) -> Tensor:\n",
    "    if len(dims) == 1:\n",
    "        return [mean + variance * inverse_normal_cdf(random.random())\n",
    "               for _ in range(dims[0])]\n",
    "    else:\n",
    "        return [random_normal(*dims[1:], mean=mean, variance=variance)\n",
    "               for _ in range(dims[0])]\n",
    "\n",
    "def normal_cdf(x: float, mu: float = 0, sigma: float = 1) -> float:\n",
    "    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2\n",
    "\n",
    "def inverse_normal_cdf(p: float,\n",
    "                      mu: float = 0,\n",
    "                      sigma: float = 1,\n",
    "                      tolerance: float = 0.00001) -> float:\n",
    "    \"\"\"이진 검색을 사용해 역함수를 근사\"\"\"\n",
    "    # 표준정규분포가 아니라면 표준정규분포로 변환\n",
    "    if mu != 0 or sigma != 1:\n",
    "        return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)\n",
    "    \n",
    "    low_z = -10.0  # normal_cdf(-10)은 0에 근접\n",
    "    hi_z = 10.0  # normal_cdf(10)은 1에 근접\n",
    "    while hi_z - low_z > tolerance:\n",
    "        mid_z = (low_z + hi_z) / 2  # 중간 값\n",
    "        mid_p = normal_cdf(mid_z)  # 중간 값의 누적분포 값을 계산\n",
    "        if mid_p < p:\n",
    "            low_z = mid_z  # 중간 값이 너무 작다면 더 큰 값들을 검색\n",
    "        else:\n",
    "            hi_z = mid_z  # 중간 값이 너무 크다면 더 작은 값들을 검색\n",
    "    \n",
    "    return mid_z\n",
    "\n",
    "def tensor_apply(f: Callable[[float], float], tensor: Tensor) -> Tensor:\n",
    "    \"\"\"텐서 안의 모든 값에 f를 적용\"\"\"\n",
    "    if is_1d(tensor):\n",
    "        return [f(x) for x in tensor]\n",
    "    else:\n",
    "        return [tensor_apply(f, tensor_i) for tensor_i in tensor]\n",
    "\n",
    "def is_1d(tensor: Tensor) -> bool:\n",
    "    \"\"\"\n",
    "    만약 tensor[0]이 리스트라면 고차원 텐서를 의미\n",
    "    그러지 않으면 1차원 벡터를 의미\n",
    "    \"\"\"\n",
    "    return not isinstance(tensor[0], list)\n",
    "\n",
    "class Sequential(Layer):\n",
    "    \"\"\"\n",
    "    하나의 Layer에는 실제 여러 층이 포함되어 있다. \n",
    "    각 층의 출력값이 \n",
    "    다음 층의 입력값이 된다는 것을 꼭 이해하고 넘어가자\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers: List[Layer]) -> None:\n",
    "        self.layers = layers\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"순차적으로 각 층의 입력값을 전파\"\"\"\n",
    "        for layer in self.layers:\n",
    "            input = layer.forward(input)\n",
    "        return input\n",
    "    \n",
    "    def backward(self, gradient):\n",
    "        \"\"\"역방향으로 각 층의 그래디언트를 전파\"\"\"\n",
    "        for layer in reversed(self.layers):\n",
    "            gradient = layer.backward(gradient)\n",
    "        return gradient\n",
    "    \n",
    "    def params(self) -> Iterable[Tensor]:\n",
    "        \"\"\"각 층별 파라미터를 반환\"\"\"\n",
    "        return (param for layer in self.layers for param in layer.params())\n",
    "    \n",
    "    def grads(self) -> Iterable[Tensor]:\n",
    "        \"\"\"각 층별 그래디언트를 반환\"\"\"\n",
    "        return (grad for layer in self.layers for grad in layer.grads())\n",
    "    \n",
    "class Linear(Layer):\n",
    "    def __init__(self,\n",
    "                input_dim: int,\n",
    "                output_dim: int,\n",
    "                init: str = 'xavier') -> None:\n",
    "        \"\"\"\n",
    "        output_dim개의 뉴런과 각 뉴런별 input_dim개의 파라미터로 (편향 제외)\n",
    "        구성된 층\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # self.w[o]는 o번째 뉴런의 파라미터\n",
    "        self.w = random_tensor(output_dim, input_dim, init=init)\n",
    "        \n",
    "        # self.b[o]는 o번째 뉴런의 편향\n",
    "        self.b = random_tensor(output_dim, init=init)\n",
    "        \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        # 역방향을 위해 input을 저장\n",
    "        self.input = input\n",
    "\n",
    "        # 뉴런의 결괏값을 벡터로 반환\n",
    "        return [dot(input, self.w[o]) + self.b[o]\n",
    "               for o in range(self.output_dim)]\n",
    "    \n",
    "    def backward(self, gradient: Tensor) -> Tensor:\n",
    "        # 각 b[o]는 output[o]에 더해진다.\n",
    "        # 즉, b의 그래디언트는 output의 그래디언트과 동일하다는 것을 의미\n",
    "        self.b_grad = gradient\n",
    "\n",
    "        # 각 w[o][i]를 input[i]에 곱하고 output[o]에다 더해 준다.\n",
    "        # 즉, 그래디언트는 input[i] * gradient[o]\n",
    "        self.w_grad = [[self.input[i] * gradient[o]\n",
    "                       for i in range(self.input_dim)]\n",
    "                       for o in range(self.output_dim)]\n",
    "        # input[i]에 각 w[o][i]를 곱하고\n",
    "        # output[o]에 더해 주기 때문에 그래디언트는 w[o][i] * gradient[o]를\n",
    "        # 모두 더해 준 값\n",
    "        return [sum(self.w[o][i] * gradien[o] for o in range(self.output_dim))\n",
    "               for i in range(self.input_dim)]  \n",
    "    \n",
    "    def params(self) -> Iterable[Tensor]:\n",
    "        return [self.w, self.b]\n",
    "\n",
    "    def grads(self) -> Iterable[Tensor]:\n",
    "        return [self.w_grad, self.b_grad]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "EMBEDDING_DIM = 5  # 이 정도면 충분할 것 같다.\n",
    "\n",
    "# 임베딩 층을 나중에 쓸 수 있게 따로 정의한다.\n",
    "embedding = TextEmbedding(vocab=vocab, embedding_dim=EMBEDDING_DIM)\n",
    "\n",
    "model = Sequential([\n",
    "    # 주어진 (word_ids 벡터로 표현된) 단어의 임베딩 벡터를 반환\n",
    "    embedding,\n",
    "    # 선형층으로 주변 단어를 선별하기 위한 점수를 계산\n",
    "    Linear(input_dim=EMBEDDING_DIM, output_dim=vocab.size)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19장 딥러닝에서 배운 방법론들을 사용하면 모델을 쉽게 학습할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(tensor: Tensor) -> Tensor:\n",
    "    \"\"\"마지막 차원 안의 softmax\"\"\"\n",
    "    if is_1d(tensor):\n",
    "        # 에러를 피하기 위해 최대값을 빼 준다.\n",
    "        largest = max(tensor)\n",
    "        exps = [math.exp(x - largest) for x in tensor]\n",
    "        \n",
    "        sum_of_exps = sum(exps)  # 모든 값의 총합\n",
    "        return [exp_i / sum_of_exps  # 확률값은 개별의 값을\n",
    "                for exp_i in exps]   # 총합으로 나눈 값\n",
    "    \n",
    "    else:\n",
    "        return [softmax(tensor_i0) for tensor_i in tensor]\n",
    "\n",
    "class Loss:\n",
    "    def loss(self, predicted: Tensor, actual: Tensor) -> float:\n",
    "        \"\"\"예측값이 얼마나 정확한가? (손실값이 크면 클수록 좋지 않은 예측값이다.)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def gradient(self, predicted: Tensor, actual: Tensor) -> Tensor:\n",
    "        \"\"\"예측값이 변하면 손실은 얼마나 변하는가?\"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class Optimizer:\n",
    "    \"\"\"\n",
    "    주어진 입력값이나 층에 대한 정보(혹은 둘 다)를 사용하여\n",
    "    해당 층의 파라미터를 업데이트\n",
    "    \"\"\"\n",
    "    def step(self, layer: Layer) -> None:\n",
    "        raise NotImplementedError            \n",
    "            \n",
    "class GradientDescent(Optimizer):\n",
    "    def __init__(self, learning_rate: float = 0.1) -> None:\n",
    "        self.lr = learning_rate\n",
    "    def step(self, layer: Layer) -> None:\n",
    "        for param, grad in zip(layer.params(), layer.grads()):\n",
    "            # 그래디언트만큼 param을 업데이트\n",
    "            param[:] = tensor_combine(\n",
    "            lambda param, grad: param - grad * self.lr,\n",
    "            param,\n",
    "            grad)        \n",
    "        \n",
    "class SoftmaxCrossEntropy(Loss):\n",
    "    \"\"\"\n",
    "    주어진 딥러닝 모델에서\n",
    "    관측된 데이터의 네거티브 로그 가능도를 계산.\n",
    "    즉, 네거티브 로그 가능도를 최소화시키면 관측된 데이터의 가능도를 최대화하는 것과 동일\n",
    "    \"\"\"\n",
    "    def loss(self, predicted: Tensor, actual: Tensor) -> float:\n",
    "        # 소프트맥스로 확률값 생성\n",
    "        probabilities = softmax(predicted)\n",
    "        \n",
    "        # 올바른 클래스로 분류되는 경우 log p_i를, 아닌 경우 0을 반환\n",
    "        # log(0)을 피하기 위해서 p에 작은 작은 값을 더해 준다.\n",
    "        likelihoods = tensor_combine(lambda p, act: math.log(p + 1e-30) * act,\n",
    "                                    probabilities,\n",
    "                                    actual)\n",
    "        \n",
    "        # 모든 네거티브 가능도를 더한다.\n",
    "        return -tensor_sum(likelihoods)\n",
    "\n",
    "    def gradient(self, predicted: Tensor, actual: Tensor) -> Tensor:\n",
    "        probabilities = softmax(predicted)\n",
    "        \n",
    "        # 굉장히 간편하게 표현되지 않는가?\n",
    "        return tensor_combine(lambda p, actual: p - actual,\n",
    "                             probabilities,\n",
    "                             actual)\n",
    "\n",
    "class Momentum(Optimizer):\n",
    "    def __init__(self,\n",
    "                learning_rate: float,\n",
    "                 momentum: float = 0.9) -> None:\n",
    "        self.lr = learning_rate\n",
    "        self.mo = momentum\n",
    "        self.updates: List[Tensor] = []  # 이전 모든 그래디언트의 평균\n",
    "    \n",
    "    def step(self, layer: Layer) -> None:\n",
    "        # 파라미터 업데이트가 처음이라면 0부터 시작\n",
    "        if not self.updates:\n",
    "            self.updates = [zeros_like(grad) for grad in layer.grads()]\n",
    "            \n",
    "        for update, param, grad in zip(self.updates,\n",
    "                                      layer.params(),\n",
    "                                      layer.grads()):\n",
    "            \n",
    "            # 모맨텀 적용\n",
    "            update[:] = tensor_combine(\n",
    "            lambda u, g: self.mo * u + (1 - self.mo) * g,\n",
    "            update,\n",
    "            grad)\n",
    "            \n",
    "            # 모맨텀을 적용한 그래디언트만큼 파라미터 업데이트\n",
    "            param[:] = tensor_combine(\n",
    "            lambda p, u: p - self.lr * u,\n",
    "            param, \n",
    "            update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-b19ed9435a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-36c37f5c482f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;34m\"\"\"순차적으로 각 층의 입력값을 전파\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-135-4233d90211be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0m입력층과\u001b[0m \u001b[0m출력값의\u001b[0m \u001b[0m타입의\u001b[0m \u001b[0m제한하지\u001b[0m \u001b[0m않을\u001b[0m \u001b[0m것이다\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \"\"\"\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss = SoftmaxCrossEntropy()\n",
    "optimizer = GradientDescent(learning_rate=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0.0\n",
    "    for input, target in zip(inputs, targets):\n",
    "        predicted = model.forward(input)\n",
    "        epoch_loss += loss.loss(predicted, target)\n",
    "        gradient = loss.gradient(predicted, target)\n",
    "        model.backward(gradient)\n",
    "        optimizer.step(model)\n",
    "    \n",
    "    print(epoch, epoch_loss)  # 손실을 출력하고\n",
    "    print(embedding.closest(\"black\"))  # 몇 개의 가까운 단어를 출력해서\n",
    "    print(embedding.closest(\"slow\"))  # 무엇이 학습되고 있는지\n",
    "    print(embedding.closest(\"car\"))  # 볼 수 있게 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델이 학습되는 것을 보다 보면, 색을 나타내는 단어들이 서로 가까워지고, 형용사들이 서로 가까워지고, 명사들이 서로 가까워지는 것을 관찰할 수 있을 것이다. 모델이 학습되고 나면 가장 비슷한 단어들이 무엇인지 관찰할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-16e62b5f283f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m pairs = [(cosine_similarity(embedding[w1], embedding[w2]), w1, w2)\n\u001b[0;32m----> 2\u001b[0;31m          \u001b[0;32mfor\u001b[0m \u001b[0mw1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m          \u001b[0;32mfor\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m          if w1 < w2]\n\u001b[1;32m      5\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-150-16e62b5f283f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m          \u001b[0;32mfor\u001b[0m \u001b[0mw1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          \u001b[0;32mfor\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m          if w1 < w2]\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-f6090ed34b9d>\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(v1, v2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "pairs = [(cosine_similarity(embedding[w1], embedding[w2]), w1, w2)\n",
    "         for w1 in vocab.w2i\n",
    "         for w2 in vocab.w2i\n",
    "         if w1 < w2]\n",
    "pairs.sort(reverse=True)\n",
    "print(pairs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 중요한 두 개의 주성분(principal components)을 뽑아서 그림을 그려볼 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scratch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-7e66560ab32b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscratch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworking_with_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 가장 주요한 두 개의 주성분을 찾아 단어 벡터들을 반환하라.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scratch'"
     ]
    }
   ],
   "source": [
    "from scratch.working_with_data import pca, transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 가장 주요한 두 개의 주성분을 찾아 단어 벡터들을 반환하라.\n",
    "components = pca(embedding.embeddings, 2)\n",
    "transformed = transform(embedding.embeddings, components)\n",
    "\n",
    "# 점들을 흩뿌린다(점들을 하얗게 만들어서 \"보이지 않게\"한다.)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(*zip(*transformed), marker='.', color='w')\n",
    "\n",
    "# 각 단어를 알맞은 위치에 표시한다.\n",
    "for word, idx in vocab.w2i.items():\n",
    "    ax.annotate(word, transformed[idx])\n",
    "\n",
    "# 축을 숨긴다.\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 좀 더 관심이 있다면 CBOW 단어 벡터를 학습하는 것도 어렵지 않게 할 수 있다. ID의 열을 입력 받고 임베딩 벡터의 열을 출력하도록 Embedding층을 수정하면 된다. 그리고 벡터 열의 합을 반환하는 새로운 층(Sum?)을 만들면 된다.\n",
    "\n",
    "각 단어는 해당 단어의 주변 단어들의 ID를 입력 받아 해당 단어의 one-hot-encoding을 반환해 주는 형태로 표현할 수 있다.\n",
    "\n",
    "수정된 Embedding 층에서 주변 단어를 벡터의 열로 바꾸고, 새로운 Sum층에서 벡터의 열을 하니의 벡터로 변환하고, Linear 층에서 계산된 점수를 소프트맥스에 통과시키면 '특정 문맥이 주어졌을 때 가장 가능성이 높은 단어'를 예측하는 분포를 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.7 재귀 신경망\n",
    "앞서 만든 단어 벡터는 신경망의 입력값으로 종종 이용되곤 한다. 그런데 단어가 3개인 문장을 [3, embedding_dim] 텐서, 단어가 10개인 문장을 [10, embedding_dim] 텐서로 만든다면 문장의 경우에는 길이가 제각각이 되기 때문에 문제가 조금 어려워진다. Linear 층에 이러한 문장들을 입력시키기 위해서는, 먼저 제각기인 차원 수를 어떻게든 조정해야 한다.\n",
    "\n",
    "한 가지 대안은 Sum 층(혹은 평균을 구하는 층)을 사용하는 것이다. 하지만 단어들의 순서는 문자의 의미에 큰 역할을 하게 마련이다. e.g. 'dog bites man'과 'man bites dog'는 완전히 다른 얘기이다. \n",
    "\n",
    "또 다른 대안은 입력값들 사이에 숨겨진 상태(hidden state)를 유지하는 RNN(Recurrent Neural Networks, 재귀 신경망)을 사용하는 것이다.\n",
    "간단히 말하면, 각 입력값을 현재의 숨겨진 상태와 결합하여 출력값을 만들고, 이 출력값을 다시 새로운 숨겨진 상태로 사용하는 것이다. 이렇게 하면 신경망은 전달받은 입력값들을 '기억'할 수 있게 되고, 모든 입력값과 그들이 순서에 대한 정보가 담겨 있는 출력값을 만들 수 있게 된다.\n",
    "\n",
    "이제 문장 안의 단어 하나 또는 단어의 문자 하나를 입력값으로 전달받아 숨겨진 상태를 보존하는 간단한 RNN층을 만들어 보자.\n",
    "\n",
    "Linear 층에는 가중치(weight) w와 편향(bias) b가 있고 다음과 같이 input 벡터를 입력 받아 output 벡터를 반환한다.\n",
    "\n",
    "output[o] = dot(w[o], input) + b[o]\n",
    "\n",
    "여기에 숨겨진 상태를 추가하려면 입력값 input과 숨겨진 상태 hidden을 위한 두 벌의 가중치가 필요하다.\n",
    "\n",
    "output[o] = dot(w[o], input) + dot(u[o], hidden) + b[o]\n",
    "\n",
    "이제 output 벡터를 hidden의 새 값으로 설정하자. 엄청나게 큰 변화는 아니지만, 이 덕분에 신경망은 아주 멋진 일들을 하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def tensor_apply(f: Callable[[float], float], tensor: Tensor) -> Tensor:\n",
    "    \"\"\"텐서 안의 모든 값에 f를 적용\"\"\"\n",
    "    if is_1d(tensor):\n",
    "        return [f(x) for x in tensor]\n",
    "    else:\n",
    "        return [tensor_apply(f, tensor_i) for tensor_i in tensor]\n",
    "    \n",
    "import math\n",
    "\n",
    "def tanh(x: float) -> float:\n",
    "    # x가 매우 크거나 작으면 tanh는 (결국) 1이나 -1을 반환.\n",
    "    # math.exp(1000)는 에러를 반환하기 때문에 x가 매우 크거나 작은 경우를 따로 확인해 줘야 한다.\n",
    "    if x < -100: return -1\n",
    "    elif x > 100: return 1\n",
    "    \n",
    "    em2x = math.exp(-2 * x)\n",
    "    return (1 - em2x) / (1 + em2x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRnn(Layer):\n",
    "    \"\"\"아마도 가장 간단한 순환층\"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dim: int) -> None:\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.w = random_tensor(hidden_dim, input_dim, init='xavier')\n",
    "        self.u = random_tensor(hidden_dim, hidden_dim, init='xavier')\n",
    "        self.b = random_tensor(hidden_dim)\n",
    "        self.reset_hidden_state()\n",
    "        \n",
    "    def reset_hidden_state(self) -> None:\n",
    "        self.hidden = [0 for _ in range(self.hidden_dim)]\n",
    "        \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        self.input = input  # 입력값과 직전 숨겨진 상태를 기억해서\n",
    "        self.prev_hidden = self.hidden  # 역전파에서 사용한다.\n",
    "    \n",
    "        a = [(dot(self.w[h], input) +  # 입력값 가중치\n",
    "             dot(self.u[h], self.hidden) + # 숨김 상태 가중치\n",
    "             self.b[h])  # 편향\n",
    "            for h in range(self.hidden_dim)]\n",
    "        \n",
    "        self.hidden = tensor_apply(tanh, a)  # tanh 활성화 함수를 적용하고\n",
    "        return self.hidden  # 결과를 반환한다.\n",
    "    \n",
    "    def backward(self, gradient: Tensor):\n",
    "        # tanh로 역전파한다.\n",
    "        a_grad = [gradient[h] * (1 - self.hidden[h] ** 2)\n",
    "                  for h in range(self.hidden_dim)]\n",
    "\n",
    "        # b는 a와 동일한 그래디언트를 가진다.\n",
    "        self.b_grad = a_grad\n",
    "\n",
    "        # 각 w[h][i]에 input[i]을 곱하고 a[h]를 더한다\n",
    "        # 즉, w_grad[h][i] = a_grad[h] * input[i]\n",
    "        self.w_grad = [[a_grad[h] * self.input[i]\n",
    "                        for i in range(self.input_dim)]\n",
    "                       for h in range(self.hidden_dim)]\n",
    "\n",
    "        # 각 u[h][h2]에 hidden[h2]를 곱하고 a[h]를 더한다.\n",
    "        # 즉, u_grad[h][h2] = a_grad[h] * prev_hidden[h2]\n",
    "        self.u_grad = [[a_grad[h] * self.prev_hidden[h2]\n",
    "                        for h2 in range(self.hidden_dim)]\n",
    "                       for h in range(self.hidden_dim)]\n",
    "\n",
    "        # 각 input[i]은 모든 w[h][i]와 곱해지고 a[h]를 더한다.\n",
    "        # 즉, input_grad[i] = sum(a_grad[h] * w[h][i] for h in ...)\n",
    "        return [sum(a_grad[h] * self.w[h][i] for h in range(self.hidden_dim))\n",
    "                for i in range(self.input_dim)]\n",
    "\n",
    "    def params(self) -> Iterable[Tensor]:\n",
    "        return [self.w, self.u, self.b]\n",
    "\n",
    "    def grads(self) -> Iterable[Tensor]:\n",
    "        return [self.w_grad, self.u_grad, self.b_grad]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleRnn은 몇 가지 한계점이 있다. 매번 호출될 때마다 모든 숨겨진 상태를 사용하여 입력값을 업데이트한다. 그리고 숨겨진 상태를 호출할 때마다 모든 숨겨진 상태가 덮어싀워진다. 이런 한계점 때문에 학습이 힘들뿐더러, 특히 긴 범위의 종속성(long-range dependencies)에 대한 학습이 어려워진다.\n",
    "\n",
    "그렇기 때문에 이렇게 간단한 RNN은 거의 아무도 사용하지 않는다. 대신, LSTM(long short-term momory) 또는 GRU(gated recurrent unit)와 같은 파라미터 수가 훨씬 많고, 모든 파라미터가 업데이트 되는 것을 막는 '게이트(gate)'가 있는 변형된 RNN을 사용한다.\n",
    "\n",
    "이 변형들이 딱히 복잡한 것은 아니다. 하지만 훨씬 많은 코드가 필요하고, 개인적으로는 단순히 코드를 읽는 것은 딱히 도움이 되지 않는다고 생각한다. 깃허브에 LSTM 구현체ㅐ를 하나 추가해놨다. 한번 살펴보는 것도 좋다. \n",
    "\n",
    "위 구현체의 또 다른 특성은 한 번에 하나의 '스탭(step)'만 가고, 우리가 직접 숨겨진 상태를 초기화해야 하는 점이다. 좀 더 실용적인 RNN 구현체는 열로 구성된 입력값을 입력 받고, 각 열이 시작될 때마다 숨겨진 상태를 0으로 설정한 상태로 출력값 열을 생성하는 것이다. 우리의 구현체도 이렇게 동작하도록 바꿀 수 있다. 단, 이 경우에도 코드만 더 복잡해질 뿐, 더 이해하는 데 도움이 되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.8 예시: 문자 단위의 RNN 사용하기\n",
    "RNN의 한 가지 재밌는 응용은 단어가 아닌 문자를 입력으로 해서, 특정 데이터셋의 언어 패턴을 학습하여 가짜 예시를 생성하게 하는 것이다.\n",
    "\n",
    "e.g. 여러 밴드의 이름을 가지고 RNN을 학습시켜 새로운 가짜 이름을 여러 개 생성 후 가장 웃긴 것을 몇개 골라 공유해 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = \"https://www.ycombinator.com/topcompanies/\"\n",
    "soup = BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "\n",
    "# 회사 이름이 두 번씩 들어와서, 중복을 없애기 위해 집합 컴프리헨션(set comprehension)을 사용한다. \n",
    "companies = list({b.text\n",
    "                 for b in soup(\"b\")\n",
    "                 if \"h4\" in b.get(\"class\", ())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(companies) == 102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자에 대한 확률분포를 예측해서 SoftmaxCrossEntropy 손실 함수를 최소화하는 방향으로 모델을 학습할 것이다.\n",
    "\n",
    "모델이 학습되고 나면 확률에 기반하여 문자를 생성하고, 이 문자를 다음 입력값으로 사용할 수 있다. 이런 방법으로 학습된 가중치를 이용해서 회사 이름을 생성할 수 있다.\n",
    "\n",
    "아래는 문자로 구성된 Vocabulary를 만드는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacab = Vocabulary([c for company in companies for c in company])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "회사명의 시작과 끝을 나타내는 특수 문자를 사용할 것이다. 이렇게 하면 모델은 회사명을 시작하거나 끝내는 문자가 무엇인지 학습하게 된다.\n",
    "\n",
    "시작과 끝을 나타내기 위한 문자로 regex에서 일반적으로 사용하는 문자를 사용할 텐데, 바라건대 이 문자들이 회사 이름에 직접적으로 등장하지 않을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = \"^\"\n",
    "STOP = \"$\"\n",
    "\n",
    "# 이들도 사전에 추가해야 한다.\n",
    "vocab.add(START)\n",
    "vocab.add(STOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 one-hot-encoding으로 표현된 각 문자를 두 개의 SimpleRnn에 통과시키고, Linear 층을 사용해서 다음 문자에 대한 점수를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 32  # 다양한 차원으로 테스트해 보자!\n",
    "\n",
    "rnn1 =  SimpleRnn(input_dim=vocab.size, hidden_dim=HIDDEN_DIM)\n",
    "rnn2 =  SimpleRnn(input_dim=HIDDEN_DIM, hidden_dim=HIDDEN_DIM)\n",
    "linear = Linear(input_dim=HIDDEN_DIM, output_dim=vocab.size)\n",
    "\n",
    "model = Sequential([\n",
    "    rnn1,\n",
    "    rnn2,\n",
    "    linear\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델을 학습했다고 가정하고, 21.5절 토픽 모델링에서 사용했던 sample_from을 이용해서 새 회사명을 생성해 주는 함수를 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def softmax(tensor: Tensor) -> Tensor:\n",
    "    \"\"\"마지막 차원 안의 softmax\"\"\"\n",
    "    if is_1d(tensor):\n",
    "        # 에러를 피하기 위해 최대값을 빼 준다.\n",
    "        largest = max(tensor)\n",
    "        exps = [math.exp(x - largest) for x in tensor]\n",
    "        \n",
    "        sum_of_exps = sum(exps)  # 모든 값의 총합\n",
    "        return [exp_i / sum_of_exps  # 확률값은 개별의 값을\n",
    "                for exp_i in exps]   # 총합으로 나눈 값\n",
    "    \n",
    "    else:\n",
    "        return [softmax(tensor_i0) for tensor_i in tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(seed: str = START, max_len: int = 50) -> str:\n",
    "    rnn1.reset_hidden_state()  # 두 숨겨진 상태를 모두 초기화한다.\n",
    "    rnn2.reset_hidden_state()\n",
    "    output = [seed]  # 특정 seed로 출력값을 시작한다.\n",
    "    \n",
    "    # STOP 문자를 생성하거나 최대 길이에 도달할 때까지 계속한다.\n",
    "    while output[-1] != STOP and len(output) < max_len:\n",
    "        # 마지막 문자를 입력값으로 사용한다.\n",
    "        input = vocab.one_hot_encode(output[-1])\n",
    "        \n",
    "        # 모델을 이용해서 score를 생성한다.\n",
    "        predicted = model.forward(input)\n",
    "        \n",
    "        # 확률값으로 바꾼 후 임의의 char_id를 뽑는다.\n",
    "        probabilities = softmax(predicted)\n",
    "        next_char_id = sample_from(probabilities)\n",
    "        \n",
    "        # 출력값에 해당 문자를 추가한다.\n",
    "        output.append(vocab.get_word(next_char_id))\n",
    "    \n",
    "    # START, END를 제거한 후 출력값을 반환한다.\n",
    "    return ''.join(output[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "unknown word C",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-40e24c858bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompany\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-131-5aa5d8cffb4a>\u001b[0m in \u001b[0;36mone_hot_encode\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mword_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mword_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"unknown word {word}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mword_id\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: unknown word C"
     ]
    }
   ],
   "source": [
    "loss = SoftmaxCrossEntropy()\n",
    "optimizer = Momentum(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(300):\n",
    "    random.shuffle(companies)  # 각 에폭별 학습 순서를 변경\n",
    "    epoch_loss = 0             # 손실을 저장\n",
    "    for company in tqdm.tqdm(companies):\n",
    "        rnn1.reset_hidden_state()  # 두 숨겨진 상태를 초기화\n",
    "        rnn2.reset_hidden_state()\n",
    "        company = START + company + STOP   # 시작과 끝을 나타내는 문자를 추가\n",
    "\n",
    "        # 나머지는 지금까지 봐온 학습용 for문과 동일\n",
    "        # 다만, 입력값과 출력값이 각각 one-hot-encoding으로 표현된 이전 문자와 다음 문자라는 것이 다르다.\n",
    "        for prev, next in zip(company, company[1:]):\n",
    "            input = vocab.one_hot_encode(prev)\n",
    "            target = vocab.one_hot_encode(next)\n",
    "            predicted = model.forward(input)\n",
    "            epoch_loss += loss.loss(predicted, target)\n",
    "            gradient = loss.gradient(predicted, target)\n",
    "            model.backward(gradient)\n",
    "            optimizer.step(model)\n",
    "\n",
    "    # 각 에폭별 손실을 출력하고 이름을 생성\n",
    "    print(epoch, epoch_loss, generate())\n",
    "\n",
    "    # 마지막 100 에폭부터는 이동 거리를 줄이기\n",
    "    # 딱히 이유는 없지만, 성능에 도움을 주는 것 같다.\n",
    "    if epoch == 200:\n",
    "        optimizer.lr *= 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 후, 모델은 원래 데이터에 있던 이름을 몇 개 생성하기도 하고 조금만 변형된 이름을 생성하기도 한다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
