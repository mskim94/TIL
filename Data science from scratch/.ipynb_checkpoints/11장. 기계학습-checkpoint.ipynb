{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기계학습\n",
    "많은 사람들이 데이터 과학은 결국 기계학습이며, 데이터 과학자는 하루 종일 기계학습 모델을 학습시키고 수정한다고 생각한다. \\\n",
    "데이터 과학의 핵심은 비즈니스 문제를 데이터 문제로 변환시킨 뒤 관련 데이터를 수집하고, 이해하고, 전처리하고, 형식을 바꾸는 것이다. 기계 학습은 이러한 과정 이후에 생각해야 한다.\n",
    "\n",
    "## 11.1 모델링\n",
    "모델(model)이란? \\\n",
    "다양한 변수 간의 수학적(혹은 확률적) 관계를 표현한 것이다. \n",
    "e.g) \\\n",
    "소셜 네트워킹 사이트를 통해 수익을 창출하고자 할때, '사용자의 수'나 '사용자당 광고 수익', '직원 수' 같은 입력 변수로 차후 몇 년 동안의 연간 수익을 예측하는 비지니스 코델을 만들곤 한다. \\\n",
    "비지니스 모델은 간단한 수학적인 관계에 기반을 둔다. 이익은 매출에서 비용을 뺀 값이며, 매출은 평균 가격에 판매량을 곱한 것이다. \n",
    "\n",
    "## 11.2 기계학습이란?\n",
    "기계학습(machine learnninga): 데이터를 통해 모델을 만들고 사용하하는 것, 다른 맥락에서 예측 모델링(predictive modeling) or 데이터마이닝(data mining)으로도 불린다. \\\n",
    "기계학습의 종류에는 정답이 포함되어 있는 **지도 핛습(supervised learning)** 과 정답이 포함되지 않은 **비지도 학습(unsupervised learning)**, 데이터의 일부에만 정답이 포함되어 있는 **준 지도 학습(semi-supervised learning)**, 새로들어오는 데이터를 통해 모델을 끊임없이 조정하는 **온라인 학습(online learning)**, 연속된 예측 뒤 모델이 얼마나 잘 예측했는지 파악하는 **강화 학습(reinforcemnet learning)** 있다. \\\n",
    "아주 단순한 상항에서도 우리가 사용할 수 있는 모델은 무수히 많다. 일반적으로 파라미터가 있는 **파라메트릭(parametric)** 모델을 고른 후, 데이터를 통해 파라미터의 최적값을 찾으려고 한다. \\\n",
    "e.g) \\\n",
    "사람의 키를 몸무게에 대한 선형 함수로 구할 수 있다고 **가정**하면 주어진 데이터로 선형 함수를 학습시킬 수 있다.\n",
    "\n",
    "## 11.3 오버피팅과 언더피팅\n",
    "기계학습의 일반적인 문제점은 **오버피팅(overfitting)**이다. \\\n",
    "오버피팅(overfitting): 만들어진 모델의 성능이 학습 데이터에서는 좋지만, 기존에 관측한 적이 없는 새로운 데이터에서는 좋지 않은 경우를 의미. \\\n",
    "오버피팅은 데이터의 잡음(noise)까지 모델에 학습되거나, 원하는 결과를 예측해주는 요소가 아닌 다른 요소들이 학습되기 때문에 발생. \\\n",
    "언더피팅(underfitting): 모델의 성능이 학습 데이터에서도 좋지 않은 경우 발생. \\\n",
    "보통 언더피팅이 발생하면 해당 모델은 문제에 적합하지 않다는 것을 의미, 새로운 모델을 찾아봐야 한다. \\\n",
    "모델이 너무 복잡하면 오버피팅이 발생하고, 학습 데이터 이외의 데이터에서는 일반적으로 적용할 수 없다는 것을 알 수 있다. \\\n",
    "그렇다면 복잡하지 않은 모델은 어떻게 만들까? \\\n",
    "각각 다른 데이터로 모델을 학습 시키고 평가하는 방법이 있다. 가장 간단한 방법은 주어진 데이터를 나누는 것 \\\n",
    "e.g) 전체 데이터의 2/3로 모델을 학습시키고, 나머지 1/3로 모델의 성능을 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import TypeVar, List, Tuple\n",
    "X = TypeVar('X')  # 데이터를 표현하기 위한 일반적인 타입\n",
    "\n",
    "def split_data(data: List[X], prob: float) -> Tuple[List[X], List[X]]:\n",
    "    \"\"\"데이터를 [prob, 1 - prob]의 비율로 나눈다.\"\"\"\n",
    "    data = data[:]  # 얕은 복사본을 만든다.\n",
    "    random.shuffle(data)  # shuffle이 리스트 내용을 바꾸기 때문\n",
    "    cut = int(len(data) * prob)  # prob을 사용하여 자를 위치를 선택하고\n",
    "    return data[:cut], data[cut:]  # 섞인 리스트를 자른다.\n",
    "\n",
    "data = [n for n in range(1000)]\n",
    "train, test = split_data(data, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비율이 맞는지 확인\n",
    "assert len(train) == 750\n",
    "assert len(test) == 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존의 비율이 유지되어야 한다.\n",
    "assert sorted(train + test) == data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분의 경우 입력 변수로 행렬 X, 출력 변수로 벡터 y가 주어질 것이다. 이때 학습 데이터(training data)나 평가 데이터(test set)에 x와 y가 제대로 쌍을 이뤄서 들어갈 수 있도록 해야 한댜."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = TypeVar('Y')  # 출력 변수를 표현하기 위한 일반적인 타입\n",
    "\n",
    "def train_test_split(xs: List[X],\n",
    "                    ys: List[Y],\n",
    "                    test_pct: float) -> Tuple[List[X], List[X], List[Y], List[Y]]:\n",
    "    # 인덱스를 생성하여 분할\n",
    "    idxs = [i for i in range(len(xs))]\n",
    "    train_idxs, test_idxs = split_data(idxs, 1 - test_pct)\n",
    "    \n",
    "    return ([xs[i] for i in train_idxs],  # x_train\n",
    "           [xs[i] for i in test_idxs],  # x_test\n",
    "           [ys[i] for i in train_idxs],  # y_train\n",
    "           [ys[i] for i in test_idxs])  # y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [x for x in range(1000)]  # xs는 1....1000\n",
    "ys = [2 * x for x in xs]  # y_i = 2 x x_i\n",
    "x_train, x_test, y_train, y_test = train_test_split(xs, ys, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비율이 맞는지 확인\n",
    "assert len(x_train) == len(y_train) == 750\n",
    "assert len(x_test) == len(y_test) == 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대응되는 데이터들이 잘 짝지어졌는지 확인\n",
    "assert all(y == 2 * x for x, y in zip(x_train, y_train))\n",
    "assert all(y == 2 * x for x, y in zip(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SomeKindModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9bc0d1b41f2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 다음과 같이 모델을 학습하고 성능을 평가할 수 있다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSomeKindModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SomeKindModel' is not defined"
     ]
    }
   ],
   "source": [
    "# 다음과 같이 모델을 학습하고 성능을 평가할 수 있다.\n",
    "model = SomeKindModel()\n",
    "x_train, x_test, y_train, y_test = train_test_split(xs, ys, 0.33)\n",
    "model.train(x_train, y_train)\n",
    "performance = model.test(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 모델이 학습 데이터에 오버피팅됐다면 평가 데이터에서 모델의 성능이 좋지 않을 것이다. 바꿔 말하면 평가 데이터에 대한 성능 좋은 모델은 오버피팅되지 않았다고 볼 수 있다. \\\n",
    "하지만 이런 방식에도 몇 가지 문제점이 나타날 수 있다. \\\n",
    "그중 한 가지 가능성은, 더 큰 데이터에는 존재하지 않을 패턴이 학습 데이터와 평가 데이터에 공통적으로 존재하는 것이다. \\\n",
    "더 큰 문제는 학습 데이터와 평가 데이터로 하나의 모델을 평가할 때가 아니라 여러 모델 중에서 하나의 모델을 선택할 때 발생한다. \\\n",
    "이 경우 각각의 모델은 오버피팅되지 않겠지만, 평가 데이터에서 성능이 제일 좋은 모델을 선택한다면 이는 평가 데이터에서 성능이 제일 좋은 모델을 선택한다면 이는 평가 데이터를 일종의 두 번째 학습 데이터로 사용하는 **메타 학습**의 문제가 발생한다. 평가 데이터에서 성능이 제일 좋았던 모델을 동일한 평가 데이터로 평가한다면 당연히 좋은 성능이 나올 수 밖에 없다. \\\n",
    "이런 경우, 데이터를 세 종류로 나눠서 사용할 수 있다. 학습 데이터로 모델을 만들고, **검증 데이터(validation set)**을 통해 학습된 여러 모델 중 하나를 선택하고, 평가 데이터로 최종 모델의 성능을 평가할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 정확도\n",
    "두 가지 결론 중 하나를 선택하는 이진 분류 문제에 대한 모델을 만든다 가정하면 '이 이메일은 과연 스팸 메일인가?', '과연 이 지원자를 채용해야 하는가?', '이 여행객은 테러리스트인가?' 같은 문제에 대한 모델을 만드는 것이다. 답안이 정해진 데이터와 예측 모델이 주어졌다면 모든 데이터는 다음 **네 가지 분류** 중 하나에 속할 것이다. \\\n",
    "1. True positve(TP, 진양성): '이 이메일은 실제로 스팸 메일이며 정확하게 스팸으롭 분류'\n",
    "2. False positive(FP, 가양성, 제1종 오류): '이 이메일은은 사실 스팸 메일이 아니지만 스팸으로 분류'\n",
    "3. False negative(FN, 가음성, 제2종 오류): '이 이메일은 실제로 스팸 메일이지만 스팸이 아닌 것으로 분류'\n",
    "4. True negative(TN, 진음상): '이 이메일은 실제로 스팸 메일이 아니며 정확하게 스팸이 아닌 것으로 분류' \\\n",
    "이러한 정보는 보통 **혼동 행렬(confusion matrix)**을 사용해서 표현 \\\n",
    "+) \\\n",
    "True, False: 실제 값이 1 이나 0이고 True: 실제와 예측이 일치, False: 실제와 예측이 불일치 \\\n",
    "Positive, Negative: 예측값이 1(Positive), 0(Negative) \\\n",
    "TP: 예측값이 1이고 실제도 1 (정답) \\\n",
    "TN: 예측값이 0이고 실제도 0 (정답) \\\n",
    "FP: 예측값이 1이고 실제는 0 (제1종 오류) \\\n",
    "FN: 예측값이 0이고 실제는 1 (제2종 오류)\n",
    "\n",
    "||실제로 스팸 메일인 경우|실제로 스팸 메일이 아닌 경우|\n",
    "|------|---|---|\n",
    "|스팸 메일로 분류|True positive|False positive|\n",
    "|스팸 메일이 아닌 것으로 분류|False negative|True negative|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백혈형 판독 방법을 예로 들면, \\\n",
    "최근 동향을 보면 1,000명의 신생아 중 5명에게 루크라는 이름을 지어 준다. 그리고 사림이 살면서 백혈병에 걸릴 확률은 대략 1.4%로 1,000명 중 14명이 백혈병에 걸린다. 만약 이 두 가지의 요소가 독립적이라고 가정(서로 영향을 주지 않는다.)하고 '루크라는 이름을 가진 사람은 백혈병에 걸린다.'라는 판독 방법을 100만 명에게 검증했다면, 다음과 같은 혼동 행렬로 결과를 확인할 수 있다. \\\n",
    "\n",
    "||실제 백혈병에 걸린 경우(명)|실제로 백혈병에 걸리지 않은 경우(명)|합계(명)|\n",
    "|------|---|---|---|\n",
    "|이름이 루크인 경우|70|4,930|5,000|\n",
    "|이름이 루크가 아닌 경우|13,930|981,070|995,000|\n",
    "|합계|14,000|986,000|1,000,000|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 혼동행렬을 사용해 모델의 성능데 대한 다양한 지표를 계산할 수 있다. 예를 들어 정확한 예측의 비율을 의미하는 **정확도(accuracy)**를 다음과 같이 계산할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    correct = tp + tn\n",
    "    total = tp + fp + fn + tn\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert accuracy(70, 4930, 13930, 981070) == 0.98114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.98114로 높은 정확도로 계산이 되었다. 하지만 이 판독 방법은 확실히 좋은 방법이 아니기 때문에 계산된 결과에 신경 쓸 필요가 없다. \\\n",
    "보통 모델의 성능을 평가하기 위해 **정밀도(precision)와 재현율(recall)**을 사용한다. \\\n",
    "**정밀도(precision)는 양성(positive)으로 예측된 결과의 정확도를 의미**한다. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return  tp / (tp + fp)  # positive인 것들중 진짜 positive인 것의 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert precision(70, 4930, 13930, 981070) == 0.014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**재현율(recall)은 실제 양성 중 모델이 정확하게 양성으로 예측한 비율을 의미**한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert recall(70, 4930, 13930, 981070) == 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정밀도와 재현율이 각각 0.014, 0.005로 수치가 굉장치 낮다. 이 결과로 판독 방법이 형편없다는 것을 알 수 있다. \\\n",
    "때로는 정밀도와 재현율을 결합해서 다음과 같이 정의된 **F1 점수(F1 score)** 를 사용하기도 한다. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    p = precision(tp, fp, fn, tn)\n",
    "    r = recall(tp , fp, fn, tn)\n",
    "    \n",
    "    return 2 * p * r / (p + r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 점수는 정밀도와 재현율의 **조화평균(harmonic mean)** 이며, 항상 정밀도와 재현율 사이의 값을 갖는다. \\\n",
    "조화 평균(調和平均)은 주어진 수들의 역수의 산술 평균의 역수를 말한다. 평균적인 변화율을 구할 때에 주로 사용 \\\n",
    "$ H={\\frac {n}{{\\frac {1}{a_{1}}}+{\\frac {1}{a_{2}}}+\\cdots +{\\frac {1}{a_{n}}}}} $\n",
    "\n",
    "두 수가 주어졌을 때, 두 수의 조화 평균은 다음 식으로 간단히 정리된다.\n",
    "\n",
    "$H={\\frac {{2}{a_{1}}{a_{2}}}{{a_{1}}+{a_{2}}}}$ \\\n",
    "이때, 산술 평균 \\\n",
    "$A={\\frac {{a_{1}}+{a_{2}}}{2}}$ \\\n",
    "과 기하 평균\n",
    "$G={\\sqrt {{a_{1}}\\cdot {a_{2}}}}$ \\\n",
    "에 대해 조화 평균은\n",
    "$H={\\frac {G^{2}}{A}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통 모델을 선택하기 위해서는 정밀도와 재현율의 트레이드오프(trade-off)를 고려해야 한다. \\\n",
    "특정 데이터 포인트가 조금이라도 양성일 것 같은 때 모델이 데이터 포인트를 양성이라고 판단한다면, 재현율은 높겠지만 정밀도는 낮을 것이다. \\\n",
    "반면 모델이 데이터가 확실히 양성일 때만 해당 데이터를 양성이라고 판단한다면 재현율은 낮겠지만 정밀도는 높을 것이다. \n",
    "\n",
    "다르게 생각하면 false positive와 false negative의 트레이드 오프로 볼수도 있다. 너무 자주 양성이라고 판단하면 false positive가 증가, 너무 자주 음성이라고 판단하면 false negative가 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 Bias-variance 트레이드 오프\n",
    "오버피팅의 문제는 bias(편향)와 variance(분산)의 트레이드오프로 볼 수 있다. 두 수치는 모두 모델을 더 큰 모집단에서 추출한, 다양한 학습 데이터로 다시 학습시키면 어떠한 변화가 발생하는지 설명해준다. \\\n",
    "상수 함수는 거의 모든 학습 데이터에서 큰 오류를 번할 것이다. 즉, 상수는 큰 편향을 가졌다고 볼 수 있다. \\\n",
    "편향이 크고 분산이 작다면 언더피팅 \\\n",
    "편향이 작고 분산이 커지면 오버피팅 \\\n",
    "(편향이 작다 = 두 학습 데이터에서 만들어진 모델이 매우 다르다. = 분산이 커진다.) \\\n",
    "(편향(치우침)이 작으면 당연히 분산이 크다(퍼져있다), 둘은 트레이드오프의 관계)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 성능이 좋지 않을 때 이러한 접근법으로 모델을 분석해 보면 해결책이 보일 것이다.\\\n",
    "만약, 모델의 편향이 매우 크다(언더 피팅, 모델의 성능이 좋지 않다)면 새로운 변수를 추가하는 것도 하나의 해결책이다. \\\n",
    "모델의 분산이 크다(오버피팅)면 모델의 변수를 줄이거나 더 많은 데이터 를 구해서 모델을 다시 학습시키면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.6 특성 추출 및 선택\n",
    "데이터를 설명할 때 데이터의 특성을 나타내는 모델의 변수가 부족하다면 언더피팅이 발생, 변수가 너무 많다면 오버피팅이 발생 \\\n",
    "**데이터의 특징(featrue): 모델의 모든 입력 변수** \\\n",
    "예를 들어 사람의 경력으로 연봉을 예측하고 싶다면 경력은 특징이 될 것이다. 더 좋은 모델이 만들어 진다면 특징이 결력을 제곱한 값이나 세제곱한 값을 변수로 사용할 수도 있다. \\\n",
    "데이터가 복잡해질수록 신기한 일이 일어난다. 예를 들어 이메일이 스팸메일인지 아닌지를 예측해 주는 필터를 만들고 있다고 해보자. \\\n",
    "필터를 만들기 위해 다음고 같은 특징을 추출해야 할 것이다.\n",
    "\n",
    "- 이메일에 '비아그라'라는 단어가 포함되어 있는가?\n",
    "\n",
    "    - 예(1), 아니오(0)을 사용해 답을 표현 $\\rightarrow$ 13장 나이브 베이즈 분류기는 예, 아니오로 표현되는 특징에 적합하다.\n",
    "\n",
    "- 문자 'd'가 몇 번 나왔는가?\n",
    "\n",
    "    - 숫자로 표현된다. $\\rightarrow$ 14장과 16장에서 회귀 분석 모델은 숫자로 표현되는 특징에 적합하다.\n",
    "\n",
    "- 보낸 사람의 이메일 도메인은 무엇인가?\n",
    "\n",
    "    - 별개의 범주에서 선택 가능 $\\rightarrow$ 17장에서 의사결정나무는 숫자, 범위로 표현되는 데이터에 적용 가능하다.\n",
    "\n",
    "특성은 어떻게 추출할까? 데이터의 특성을 추출하기 위해서는 경험과 현장 지식이 중요하다! \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
